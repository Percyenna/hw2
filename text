needs without having to wait for additional hardware, or being required to over-invest to
provision enough capacity. For mission-critical applications on a more traditional
infrastructure, system designers have no choice but to over-provision, because a surge
in additional data due to an increase in business need must be something the system
can handle. By contrast, on AWS you can provision more capacity and compute in a
matter of minutes, meaning that your big data applications grow and shrink as demand
dictates, and your system runs as close to optimal efficiency as possible. In addition, you
get flexible computing on a world-class infrastructure with access to the many different
geographic regions that AWS offers 1 , along with the ability to utilize other scalable
services that Amazon offers such as Amazon Simple Storage Service (S3) 2 and AWS
Data Pipeline. 3 These capabilities of the AWS platform make it an extremely good fit for
solving big data problems. You can read about many customers that have implemented
successful big data analytics workloads on AWS on the AWS case studies web page. 4
Amazon Redshift
Amazon Redshift is a fast, fully-managed, petabyte-scale data warehouse service that
makes it simple and cost-effective to efficiently analyze all your data using your existing
business intelligence tools. 5 It is optimized for datasets ranging from a few hundred
gigabytes to a petabyte or more, and is designed to cost less than a tenth of the cost of
most traditional data warehousing solutions. Amazon Redshift delivers fast query and
I/O performance for virtually any size dataset by using columnar storage technology
while parallelizing and distributing queries across multiple nodes. As a managed service,
automation is provided for most of the common administrative tasks associated with
provisioning, configuring, monitoring, backing up, and securing a data warehouse,
making it very easy and inexpensive to manage and maintain. This automation allows
you to build a petabyte-scale data warehouse in minutes, a task that has traditionally
taken weeks, or months, to complete in an on-premises implementation.
Ideal Usage Pattern
Amazon Redshift is ideal for online analytical processing (OLAP) using your existing
business intelligence tools. Organizations are using Amazon Redshift to do the following:
needs without having to wait for additional hardware, or being required to over-invest to
provision enough capacity. For mission-critical applications on a more traditional
infrastructure, system designers have no choice but to over-provision, because a surge
in additional data due to an increase in business need must be something the system
can handle. By contrast, on AWS you can provision more capacity and compute in a
matter of minutes, meaning that your big data applications grow and shrink as demand
dictates, and your system runs as close to optimal efficiency as possible. In addition, you
get flexible computing on a world-class infrastructure with access to the many different
geographic regions that AWS offers 1 , along with the ability to utilize other scalable
services that Amazon offers such as Amazon Simple Storage Service (S3) 2 and AWS
Data Pipeline. 3 These capabilities of the AWS platform make it an extremely good fit for
solving big data problems. You can read about many customers that have implemented
successful big data analytics workloads on AWS on the AWS case studies web page. 4
Amazon Redshift
Amazon Redshift is a fast, fully-managed, petabyte-scale data warehouse service that
makes it simple and cost-effective to efficiently analyze all your data using your existing
business intelligence tools. 5 It is optimized for datasets ranging from a few hundred
gigabytes to a petabyte or more, and is designed to cost less than a tenth of the cost of
most traditional data warehousing solutions. Amazon Redshift delivers fast query and
I/O performance for virtually any size dataset by using columnar storage technology
while parallelizing and distributing queries across multiple nodes. As a managed service,
automation is provided for most of the common administrative tasks associated with
provisioning, configuring, monitoring, backing up, and securing a data warehouse,
making it very easy and inexpensive to manage and maintain. This automation allows
you to build a petabyte-scale data warehouse in minutes, a task that has traditionally
taken weeks, or months, to complete in an on-premises implementation.
Ideal Usage Pattern
Amazon Redshift is ideal for online analytical processing (OLAP) using your existing
business intelligence tools. Organizations are using Amazon Redshift to do the following:

Page 4 of 29
Analyze global sales data for multiple products
Store historical stock trade data
Analyze ad impressions and clicks
Aggregate gaming data
Analyze social trends
1 http://aws.amazon.com/about-aws/globalinfrastructure/
2 http://aws.amazon.com/s3/
3 http://aws.amazon.com/datapipeline/
4 http://aws.amazon.com/solutions/case-studies/big-data/

Page 4 of 29
Analyze global sales data for multiple products
Store historical stock trade data
Analyze ad impressions and clicks
Aggregate gaming data
Analyze social trends
1 http://aws.amazon.com/about-aws/globalinfrastructure/
2 http://aws.amazon.com/s3/
3 http://aws.amazon.com/datapipeline/
4 http://aws.amazon.com/solutions/case-studies/big-data/
needs without having to wait for additional hardware, or being required to over-invest to
provision enough capacity. For mission-critical applications on a more traditional
infrastructure, system designers have no choice but to over-provision, because a surge
in additional data due to an increase in business need must be something the system
can handle. By contrast, on AWS you can provision more capacity and compute in a
matter of minutes, meaning that your big data applications grow and shrink as demand
dictates, and your system runs as close to optimal efficiency as possible. In addition, you
get flexible computing on a world-class infrastructure with access to the many different
geographic regions that AWS offers 1 , along with the ability to utilize other scalable
services that Amazon offers such as Amazon Simple Storage Service (S3) 2 and AWS
Data Pipeline. 3 These capabilities of the AWS platform make it an extremely good fit for
solving big data problems. You can read about many customers that have implemented
successful big data analytics workloads on AWS on the AWS case studies web page. 4
Amazon Redshift
Amazon Redshift is a fast, fully-managed, petabyte-scale data warehouse service that
makes it simple and cost-effective to efficiently analyze all your data using your existing
business intelligence tools. 5 It is optimized for datasets ranging from a few hundred
gigabytes to a petabyte or more, and is designed to cost less than a tenth of the cost of
most traditional data warehousing solutions. Amazon Redshift delivers fast query and
I/O performance for virtually any size dataset by using columnar storage technology
while parallelizing and distributing queries across multiple nodes. As a managed service,
automation is provided for most of the common administrative tasks associated with
provisioning, configuring, monitoring, backing up, and securing a data warehouse,
making it very easy and inexpensive to manage and maintain. This automation allows
you to build a petabyte-scale data warehouse in minutes, a task that has traditionally
taken weeks, or months, to complete in an on-premises implementation.
Ideal Usage Pattern
Amazon Redshift is ideal for online analytical processing (OLAP) using your existing
business intelligence tools. Organizations are using Amazon Redshift to do the following:
needs without having to wait for additional hardware, or being required to over-invest to
provision enough capacity. For mission-critical applications on a more traditional
infrastructure, system designers have no choice but to over-provision, because a surge
in additional data due to an increase in business need must be something the system
can handle. By contrast, on AWS you can provision more capacity and compute in a
matter of minutes, meaning that your big data applications grow and shrink as demand
dictates, and your system runs as close to optimal efficiency as possible. In addition, you
get flexible computing on a world-class infrastructure with access to the many different
geographic regions that AWS offers 1 , along with the ability to utilize other scalable
services that Amazon offers such as Amazon Simple Storage Service (S3) 2 and AWS
Data Pipeline. 3 These capabilities of the AWS platform make it an extremely good fit for
solving big data problems. You can read about many customers that have implemented
successful big data analytics workloads on AWS on the AWS case studies web page. 4
Amazon Redshift
Amazon Redshift is a fast, fully-managed, petabyte-scale data warehouse service that
makes it simple and cost-effective to efficiently analyze all your data using your existing
business intelligence tools. 5 It is optimized for datasets ranging from a few hundred
gigabytes to a petabyte or more, and is designed to cost less than a tenth of the cost of
most traditional data warehousing solutions. Amazon Redshift delivers fast query and
I/O performance for virtually any size dataset by using columnar storage technology
while parallelizing and distributing queries across multiple nodes. As a managed service,
automation is provided for most of the common administrative tasks associated with
provisioning, configuring, monitoring, backing up, and securing a data warehouse,
making it very easy and inexpensive to manage and maintain. This automation allows
you to build a petabyte-scale data warehouse in minutes, a task that has traditionally
taken weeks, or months, to complete in an on-premises implementation.
Ideal Usage Pattern
Amazon Redshift is ideal for online analytical processing (OLAP) using your existing
business intelligence tools. Organizations are using Amazon Redshift to do the following:

Page 4 of 29
Analyze global sales data for multiple products
Store historical stock trade data
Analyze ad impressions and clicks
Aggregate gaming data
Analyze social trends
1 http://aws.amazon.com/about-aws/globalinfrastructure/
2 http://aws.amazon.com/s3/
3 http://aws.amazon.com/datapipeline/
4 http://aws.amazon.com/solutions/case-studies/big-data/

Page 4 of 29
Analyze global sales data for multiple products
Store historical stock trade data
Analyze ad impressions and clicks
Aggregate gaming data
Analyze social trends
1 http://aws.amazon.com/about-aws/globalinfrastructure/
2 http://aws.amazon.com/s3/
3 http://aws.amazon.com/datapipeline/
4 http://aws.amazon.com/solutions/case-studies/big-data/

needs without having to wait for additional hardware, or being required to over-invest to
provision enough capacity. For mission-critical applications on a more traditional
infrastructure, system designers have no choice but to over-provision, because a surge
in additional data due to an increase in business need must be something the system
can handle. By contrast, on AWS you can provision more capacity and compute in a
matter of minutes, meaning that your big data applications grow and shrink as demand
dictates, and your system runs as close to optimal efficiency as possible. In addition, you
get flexible computing on a world-class infrastructure with access to the many different
geographic regions that AWS offers 1 , along with the ability to utilize other scalable
services that Amazon offers such as Amazon Simple Storage Service (S3) 2 and AWS
Data Pipeline. 3 These capabilities of the AWS platform make it an extremely good fit for
solving big data problems. You can read about many customers that have implemented
successful big data analytics workloads on AWS on the AWS case studies web page. 4
Amazon Redshift
Amazon Redshift is a fast, fully-managed, petabyte-scale data warehouse service that
makes it simple and cost-effective to efficiently analyze all your data using your existing
business intelligence tools. 5 It is optimized for datasets ranging from a few hundred
gigabytes to a petabyte or more, and is designed to cost less than a tenth of the cost of
most traditional data warehousing solutions. Amazon Redshift delivers fast query and
I/O performance for virtually any size dataset by using columnar storage technology
while parallelizing and distributing queries across multiple nodes. As a managed service,
automation is provided for most of the common administrative tasks associated with
provisioning, configuring, monitoring, backing up, and securing a data warehouse,
making it very easy and inexpensive to manage and maintain. This automation allows
you to build a petabyte-scale data warehouse in minutes, a task that has traditionally
taken weeks, or months, to complete in an on-premises implementation.
Ideal Usage Pattern
Amazon Redshift is ideal for online analytical processing (OLAP) using your existing
business intelligence tools. Organizations are using Amazon Redshift to do the following:
needs without having to wait for additional hardware, or being required to over-invest to
provision enough capacity. For mission-critical applications on a more traditional
infrastructure, system designers have no choice but to over-provision, because a surge
in additional data due to an increase in business need must be something the system
can handle. By contrast, on AWS you can provision more capacity and compute in a
matter of minutes, meaning that your big data applications grow and shrink as demand
dictates, and your system runs as close to optimal efficiency as possible. In addition, you
get flexible computing on a world-class infrastructure with access to the many different
geographic regions that AWS offers 1 , along with the ability to utilize other scalable
services that Amazon offers such as Amazon Simple Storage Service (S3) 2 and AWS
Data Pipeline. 3 These capabilities of the AWS platform make it an extremely good fit for
solving big data problems. You can read about many customers that have implemented
successful big data analytics workloads on AWS on the AWS case studies web page. 4
Amazon Redshift
Amazon Redshift is a fast, fully-managed, petabyte-scale data warehouse service that
makes it simple and cost-effective to efficiently analyze all your data using your existing
business intelligence tools. 5 It is optimized for datasets ranging from a few hundred
gigabytes to a petabyte or more, and is designed to cost less than a tenth of the cost of
most traditional data warehousing solutions. Amazon Redshift delivers fast query and
I/O performance for virtually any size dataset by using columnar storage technology
while parallelizing and distributing queries across multiple nodes. As a managed service,
automation is provided for most of the common administrative tasks associated with
provisioning, configuring, monitoring, backing up, and securing a data warehouse,
making it very easy and inexpensive to manage and maintain. This automation allows
you to build a petabyte-scale data warehouse in minutes, a task that has traditionally
taken weeks, or months, to complete in an on-premises implementation.
Ideal Usage Pattern
Amazon Redshift is ideal for online analytical processing (OLAP) using your existing
business intelligence tools. Organizations are using Amazon Redshift to do the following:

Page 4 of 29
Analyze global sales data for multiple products
Store historical stock trade data
Analyze ad impressions and clicks
Aggregate gaming data
Analyze social trends
1 http://aws.amazon.com/about-aws/globalinfrastructure/
2 http://aws.amazon.com/s3/
3 http://aws.amazon.com/datapipeline/
4 http://aws.amazon.com/solutions/case-studies/big-data/

Page 4 of 29
Analyze global sales data for multiple products
Store historical stock trade data
Analyze ad impressions and clicks
Aggregate gaming data
Analyze social trends
1 http://aws.amazon.com/about-aws/globalinfrastructure/
2 http://aws.amazon.com/s3/
3 http://aws.amazon.com/datapipeline/
4 http://aws.amazon.com/solutions/case-studies/big-data/

needs without having to wait for additional hardware, or being required to over-invest to
provision enough capacity. For mission-critical applications on a more traditional
infrastructure, system designers have no choice but to over-provision, because a surge
in additional data due to an increase in business need must be something the system
can handle. By contrast, on AWS you can provision more capacity and compute in a
matter of minutes, meaning that your big data applications grow and shrink as demand
dictates, and your system runs as close to optimal efficiency as possible. In addition, you
get flexible computing on a world-class infrastructure with access to the many different
geographic regions that AWS offers 1 , along with the ability to utilize other scalable
services that Amazon offers such as Amazon Simple Storage Service (S3) 2 and AWS
Data Pipeline. 3 These capabilities of the AWS platform make it an extremely good fit for
solving big data problems. You can read about many customers that have implemented
successful big data analytics workloads on AWS on the AWS case studies web page. 4
Amazon Redshift
Amazon Redshift is a fast, fully-managed, petabyte-scale data warehouse service that
makes it simple and cost-effective to efficiently analyze all your data using your existing
business intelligence tools. 5 It is optimized for datasets ranging from a few hundred
gigabytes to a petabyte or more, and is designed to cost less than a tenth of the cost of
most traditional data warehousing solutions. Amazon Redshift delivers fast query and
I/O performance for virtually any size dataset by using columnar storage technology
while parallelizing and distributing queries across multiple nodes. As a managed service,
automation is provided for most of the common administrative tasks associated with
provisioning, configuring, monitoring, backing up, and securing a data warehouse,
making it very easy and inexpensive to manage and maintain. This automation allows
you to build a petabyte-scale data warehouse in minutes, a task that has traditionally
taken weeks, or months, to complete in an on-premises implementation.
Ideal Usage Pattern
Amazon Redshift is ideal for online analytical processing (OLAP) using your existing
business intelligence tools. Organizations are using Amazon Redshift to do the following:
needs without having to wait for additional hardware, or being required to over-invest to
provision enough capacity. For mission-critical applications on a more traditional
infrastructure, system designers have no choice but to over-provision, because a surge
in additional data due to an increase in business need must be something the system
can handle. By contrast, on AWS you can provision more capacity and compute in a
matter of minutes, meaning that your big data applications grow and shrink as demand
dictates, and your system runs as close to optimal efficiency as possible. In addition, you
get flexible computing on a world-class infrastructure with access to the many different
geographic regions that AWS offers 1 , along with the ability to utilize other scalable
services that Amazon offers such as Amazon Simple Storage Service (S3) 2 and AWS
Data Pipeline. 3 These capabilities of the AWS platform make it an extremely good fit for
solving big data problems. You can read about many customers that have implemented
successful big data analytics workloads on AWS on the AWS case studies web page. 4
Amazon Redshift
Amazon Redshift is a fast, fully-managed, petabyte-scale data warehouse service that
makes it simple and cost-effective to efficiently analyze all your data using your existing
business intelligence tools. 5 It is optimized for datasets ranging from a few hundred
gigabytes to a petabyte or more, and is designed to cost less than a tenth of the cost of
most traditional data warehousing solutions. Amazon Redshift delivers fast query and
I/O performance for virtually any size dataset by using columnar storage technology
while parallelizing and distributing queries across multiple nodes. As a managed service,
automation is provided for most of the common administrative tasks associated with
provisioning, configuring, monitoring, backing up, and securing a data warehouse,
making it very easy and inexpensive to manage and maintain. This automation allows
you to build a petabyte-scale data warehouse in minutes, a task that has traditionally
taken weeks, or months, to complete in an on-premises implementation.
Ideal Usage Pattern
Amazon Redshift is ideal for online analytical processing (OLAP) using your existing
business intelligence tools. Organizations are using Amazon Redshift to do the following:

Page 4 of 29
Analyze global sales data for multiple products
Store historical stock trade data
Analyze ad impressions and clicks
Aggregate gaming data
Analyze social trends
1 http://aws.amazon.com/about-aws/globalinfrastructure/
2 http://aws.amazon.com/s3/
3 http://aws.amazon.com/datapipeline/
4 http://aws.amazon.com/solutions/case-studies/big-data/

Page 4 of 29
Analyze global sales data for multiple products
Store historical stock trade data
Analyze ad impressions and clicks
Aggregate gaming data
Analyze social trends
1 http://aws.amazon.com/about-aws/globalinfrastructure/
2 http://aws.amazon.com/s3/
3 http://aws.amazon.com/datapipeline/
4 http://aws.amazon.com/solutions/case-studies/big-data/

needs without having to wait for additional hardware, or being required to over-invest to
provision enough capacity. For mission-critical applications on a more traditional
infrastructure, system designers have no choice but to over-provision, because a surge
in additional data due to an increase in business need must be something the system
can handle. By contrast, on AWS you can provision more capacity and compute in a
matter of minutes, meaning that your big data applications grow and shrink as demand
dictates, and your system runs as close to optimal efficiency as possible. In addition, you
get flexible computing on a world-class infrastructure with access to the many different
geographic regions that AWS offers 1 , along with the ability to utilize other scalable
services that Amazon offers such as Amazon Simple Storage Service (S3) 2 and AWS
Data Pipeline. 3 These capabilities of the AWS platform make it an extremely good fit for
solving big data problems. You can read about many customers that have implemented
successful big data analytics workloads on AWS on the AWS case studies web page. 4
Amazon Redshift
Amazon Redshift is a fast, fully-managed, petabyte-scale data warehouse service that
makes it simple and cost-effective to efficiently analyze all your data using your existing
business intelligence tools. 5 It is optimized for datasets ranging from a few hundred
gigabytes to a petabyte or more, and is designed to cost less than a tenth of the cost of
most traditional data warehousing solutions. Amazon Redshift delivers fast query and
I/O performance for virtually any size dataset by using columnar storage technology
while parallelizing and distributing queries across multiple nodes. As a managed service,
automation is provided for most of the common administrative tasks associated with
provisioning, configuring, monitoring, backing up, and securing a data warehouse,
making it very easy and inexpensive to manage and maintain. This automation allows
you to build a petabyte-scale data warehouse in minutes, a task that has traditionally
taken weeks, or months, to complete in an on-premises implementation.
Ideal Usage Pattern
Amazon Redshift is ideal for online analytical processing (OLAP) using your existing
business intelligence tools. Organizations are using Amazon Redshift to do the following:
needs without having to wait for additional hardware, or being required to over-invest to
provision enough capacity. For mission-critical applications on a more traditional
infrastructure, system designers have no choice but to over-provision, because a surge
in additional data due to an increase in business need must be something the system
can handle. By contrast, on AWS you can provision more capacity and compute in a
matter of minutes, meaning that your big data applications grow and shrink as demand
dictates, and your system runs as close to optimal efficiency as possible. In addition, you
get flexible computing on a world-class infrastructure with access to the many different
geographic regions that AWS offers 1 , along with the ability to utilize other scalable
services that Amazon offers such as Amazon Simple Storage Service (S3) 2 and AWS
Data Pipeline. 3 These capabilities of the AWS platform make it an extremely good fit for
solving big data problems. You can read about many customers that have implemented
successful big data analytics workloads on AWS on the AWS case studies web page. 4
Amazon Redshift
Amazon Redshift is a fast, fully-managed, petabyte-scale data warehouse service that
makes it simple and cost-effective to efficiently analyze all your data using your existing
business intelligence tools. 5 It is optimized for datasets ranging from a few hundred
gigabytes to a petabyte or more, and is designed to cost less than a tenth of the cost of
most traditional data warehousing solutions. Amazon Redshift delivers fast query and
I/O performance for virtually any size dataset by using columnar storage technology
while parallelizing and distributing queries across multiple nodes. As a managed service,
automation is provided for most of the common administrative tasks associated with
provisioning, configuring, monitoring, backing up, and securing a data warehouse,
making it very easy and inexpensive to manage and maintain. This automation allows
you to build a petabyte-scale data warehouse in minutes, a task that has traditionally
taken weeks, or months, to complete in an on-premises implementation.
Ideal Usage Pattern
Amazon Redshift is ideal for online analytical processing (OLAP) using your existing
business intelligence tools. Organizations are using Amazon Redshift to do the following:

Page 4 of 29
Analyze global sales data for multiple products
Store historical stock trade data
Analyze ad impressions and clicks
Aggregate gaming data
Analyze social trends
1 http://aws.amazon.com/about-aws/globalinfrastructure/
2 http://aws.amazon.com/s3/
3 http://aws.amazon.com/datapipeline/
4 http://aws.amazon.com/solutions/case-studies/big-data/

Page 4 of 29
Analyze global sales data for multiple products
Store historical stock trade data
Analyze ad impressions and clicks
Aggregate gaming data
Analyze social trends
1 http://aws.amazon.com/about-aws/globalinfrastructure/
2 http://aws.amazon.com/s3/
3 http://aws.amazon.com/datapipeline/
4 http://aws.amazon.com/solutions/case-studies/big-data/

needs without having to wait for additional hardware, or being required to over-invest to
provision enough capacity. For mission-critical applications on a more traditional
infrastructure, system designers have no choice but to over-provision, because a surge
in additional data due to an increase in business need must be something the system
can handle. By contrast, on AWS you can provision more capacity and compute in a
matter of minutes, meaning that your big data applications grow and shrink as demand
dictates, and your system runs as close to optimal efficiency as possible. In addition, you
get flexible computing on a world-class infrastructure with access to the many different
geographic regions that AWS offers 1 , along with the ability to utilize other scalable
services that Amazon offers such as Amazon Simple Storage Service (S3) 2 and AWS
Data Pipeline. 3 These capabilities of the AWS platform make it an extremely good fit for
solving big data problems. You can read about many customers that have implemented
successful big data analytics workloads on AWS on the AWS case studies web page. 4
Amazon Redshift
Amazon Redshift is a fast, fully-managed, petabyte-scale data warehouse service that
makes it simple and cost-effective to efficiently analyze all your data using your existing
business intelligence tools. 5 It is optimized for datasets ranging from a few hundred
gigabytes to a petabyte or more, and is designed to cost less than a tenth of the cost of
most traditional data warehousing solutions. Amazon Redshift delivers fast query and
I/O performance for virtually any size dataset by using columnar storage technology
while parallelizing and distributing queries across multiple nodes. As a managed service,
automation is provided for most of the common administrative tasks associated with
provisioning, configuring, monitoring, backing up, and securing a data warehouse,
making it very easy and inexpensive to manage and maintain. This automation allows
you to build a petabyte-scale data warehouse in minutes, a task that has traditionally
taken weeks, or months, to complete in an on-premises implementation.
Ideal Usage Pattern
Amazon Redshift is ideal for online analytical processing (OLAP) using your existing
business intelligence tools. Organizations are using Amazon Redshift to do the following:
needs without having to wait for additional hardware, or being required to over-invest to
provision enough capacity. For mission-critical applications on a more traditional
infrastructure, system designers have no choice but to over-provision, because a surge
in additional data due to an increase in business need must be something the system
can handle. By contrast, on AWS you can provision more capacity and compute in a
matter of minutes, meaning that your big data applications grow and shrink as demand
dictates, and your system runs as close to optimal efficiency as possible. In addition, you
get flexible computing on a world-class infrastructure with access to the many different
geographic regions that AWS offers 1 , along with the ability to utilize other scalable
services that Amazon offers such as Amazon Simple Storage Service (S3) 2 and AWS
Data Pipeline. 3 These capabilities of the AWS platform make it an extremely good fit for
solving big data problems. You can read about many customers that have implemented
successful big data analytics workloads on AWS on the AWS case studies web page. 4
Amazon Redshift
Amazon Redshift is a fast, fully-managed, petabyte-scale data warehouse service that
makes it simple and cost-effective to efficiently analyze all your data using your existing
business intelligence tools. 5 It is optimized for datasets ranging from a few hundred
gigabytes to a petabyte or more, and is designed to cost less than a tenth of the cost of
most traditional data warehousing solutions. Amazon Redshift delivers fast query and
I/O performance for virtually any size dataset by using columnar storage technology
while parallelizing and distributing queries across multiple nodes. As a managed service,
automation is provided for most of the common administrative tasks associated with
provisioning, configuring, monitoring, backing up, and securing a data warehouse,
making it very easy and inexpensive to manage and maintain. This automation allows
you to build a petabyte-scale data warehouse in minutes, a task that has traditionally
taken weeks, or months, to complete in an on-premises implementation.
Ideal Usage Pattern
Amazon Redshift is ideal for online analytical processing (OLAP) using your existing
business intelligence tools. Organizations are using Amazon Redshift to do the following:

Page 4 of 29
Analyze global sales data for multiple products
Store historical stock trade data
Analyze ad impressions and clicks
Aggregate gaming data
Analyze social trends
1 http://aws.amazon.com/about-aws/globalinfrastructure/
2 http://aws.amazon.com/s3/
3 http://aws.amazon.com/datapipeline/
4 http://aws.amazon.com/solutions/case-studies/big-data/

Page 4 of 29
Analyze global sales data for multiple products
Store historical stock trade data
Analyze ad impressions and clicks
Aggregate gaming data
Analyze social trends
1 http://aws.amazon.com/about-aws/globalinfrastructure/
2 http://aws.amazon.com/s3/
3 http://aws.amazon.com/datapipeline/
4 http://aws.amazon.com/solutions/case-studies/big-data/

needs without having to wait for additional hardware, or being required to over-invest to
provision enough capacity. For mission-critical applications on a more traditional
infrastructure, system designers have no choice but to over-provision, because a surge
in additional data due to an increase in business need must be something the system
can handle. By contrast, on AWS you can provision more capacity and compute in a
matter of minutes, meaning that your big data applications grow and shrink as demand
dictates, and your system runs as close to optimal efficiency as possible. In addition, you
get flexible computing on a world-class infrastructure with access to the many different
geographic regions that AWS offers 1 , along with the ability to utilize other scalable
services that Amazon offers such as Amazon Simple Storage Service (S3) 2 and AWS
Data Pipeline. 3 These capabilities of the AWS platform make it an extremely good fit for
solving big data problems. You can read about many customers that have implemented
successful big data analytics workloads on AWS on the AWS case studies web page. 4
Amazon Redshift
Amazon Redshift is a fast, fully-managed, petabyte-scale data warehouse service that
makes it simple and cost-effective to efficiently analyze all your data using your existing
business intelligence tools. 5 It is optimized for datasets ranging from a few hundred
gigabytes to a petabyte or more, and is designed to cost less than a tenth of the cost of
most traditional data warehousing solutions. Amazon Redshift delivers fast query and
I/O performance for virtually any size dataset by using columnar storage technology
while parallelizing and distributing queries across multiple nodes. As a managed service,
automation is provided for most of the common administrative tasks associated with
provisioning, configuring, monitoring, backing up, and securing a data warehouse,
making it very easy and inexpensive to manage and maintain. This automation allows
you to build a petabyte-scale data warehouse in minutes, a task that has traditionally
taken weeks, or months, to complete in an on-premises implementation.
Ideal Usage Pattern
Amazon Redshift is ideal for online analytical processing (OLAP) using your existing
business intelligence tools. Organizations are using Amazon Redshift to do the following:
needs without having to wait for additional hardware, or being required to over-invest to
provision enough capacity. For mission-critical applications on a more traditional
infrastructure, system designers have no choice but to over-provision, because a surge
in additional data due to an increase in business need must be something the system
can handle. By contrast, on AWS you can provision more capacity and compute in a
matter of minutes, meaning that your big data applications grow and shrink as demand
dictates, and your system runs as close to optimal efficiency as possible. In addition, you
get flexible computing on a world-class infrastructure with access to the many different
geographic regions that AWS offers 1 , along with the ability to utilize other scalable
services that Amazon offers such as Amazon Simple Storage Service (S3) 2 and AWS
Data Pipeline. 3 These capabilities of the AWS platform make it an extremely good fit for
solving big data problems. You can read about many customers that have implemented
successful big data analytics workloads on AWS on the AWS case studies web page. 4
Amazon Redshift
Amazon Redshift is a fast, fully-managed, petabyte-scale data warehouse service that
makes it simple and cost-effective to efficiently analyze all your data using your existing
business intelligence tools. 5 It is optimized for datasets ranging from a few hundred
gigabytes to a petabyte or more, and is designed to cost less than a tenth of the cost of
most traditional data warehousing solutions. Amazon Redshift delivers fast query and
I/O performance for virtually any size dataset by using columnar storage technology
while parallelizing and distributing queries across multiple nodes. As a managed service,
automation is provided for most of the common administrative tasks associated with
provisioning, configuring, monitoring, backing up, and securing a data warehouse,
making it very easy and inexpensive to manage and maintain. This automation allows
you to build a petabyte-scale data warehouse in minutes, a task that has traditionally
taken weeks, or months, to complete in an on-premises implementation.
Ideal Usage Pattern
Amazon Redshift is ideal for online analytical processing (OLAP) using your existing
business intelligence tools. Organizations are using Amazon Redshift to do the following:

Page 4 of 29
Analyze global sales data for multiple products
Store historical stock trade data
Analyze ad impressions and clicks
Aggregate gaming data
Analyze social trends
1 http://aws.amazon.com/about-aws/globalinfrastructure/
2 http://aws.amazon.com/s3/
3 http://aws.amazon.com/datapipeline/
4 http://aws.amazon.com/solutions/case-studies/big-data/

Page 4 of 29
Analyze global sales data for multiple products
Store historical stock trade data
Analyze ad impressions and clicks
Aggregate gaming data
Analyze social trends
1 http://aws.amazon.com/about-aws/globalinfrastructure/
2 http://aws.amazon.com/s3/
3 http://aws.amazon.com/datapipeline/
4 http://aws.amazon.com/solutions/case-studies/big-data/

needs without having to wait for additional hardware, or being required to over-invest to
provision enough capacity. For mission-critical applications on a more traditional
infrastructure, system designers have no choice but to over-provision, because a surge
in additional data due to an increase in business need must be something the system
can handle. By contrast, on AWS you can provision more capacity and compute in a
matter of minutes, meaning that your big data applications grow and shrink as demand
dictates, and your system runs as close to optimal efficiency as possible. In addition, you
get flexible computing on a world-class infrastructure with access to the many different
geographic regions that AWS offers 1 , along with the ability to utilize other scalable
services that Amazon offers such as Amazon Simple Storage Service (S3) 2 and AWS
Data Pipeline. 3 These capabilities of the AWS platform make it an extremely good fit for
solving big data problems. You can read about many customers that have implemented
successful big data analytics workloads on AWS on the AWS case studies web page. 4
Amazon Redshift
Amazon Redshift is a fast, fully-managed, petabyte-scale data warehouse service that
makes it simple and cost-effective to efficiently analyze all your data using your existing
business intelligence tools. 5 It is optimized for datasets ranging from a few hundred
gigabytes to a petabyte or more, and is designed to cost less than a tenth of the cost of
most traditional data warehousing solutions. Amazon Redshift delivers fast query and
I/O performance for virtually any size dataset by using columnar storage technology
while parallelizing and distributing queries across multiple nodes. As a managed service,
automation is provided for most of the common administrative tasks associated with
provisioning, configuring, monitoring, backing up, and securing a data warehouse,
making it very easy and inexpensive to manage and maintain. This automation allows
you to build a petabyte-scale data warehouse in minutes, a task that has traditionally
taken weeks, or months, to complete in an on-premises implementation.
Ideal Usage Pattern
Amazon Redshift is ideal for online analytical processing (OLAP) using your existing
business intelligence tools. Organizations are using Amazon Redshift to do the following:
needs without having to wait for additional hardware, or being required to over-invest to
provision enough capacity. For mission-critical applications on a more traditional
infrastructure, system designers have no choice but to over-provision, because a surge
in additional data due to an increase in business need must be something the system
can handle. By contrast, on AWS you can provision more capacity and compute in a
matter of minutes, meaning that your big data applications grow and shrink as demand
dictates, and your system runs as close to optimal efficiency as possible. In addition, you
get flexible computing on a world-class infrastructure with access to the many different
geographic regions that AWS offers 1 , along with the ability to utilize other scalable
services that Amazon offers such as Amazon Simple Storage Service (S3) 2 and AWS
Data Pipeline. 3 These capabilities of the AWS platform make it an extremely good fit for
solving big data problems. You can read about many customers that have implemented
successful big data analytics workloads on AWS on the AWS case studies web page. 4
Amazon Redshift
Amazon Redshift is a fast, fully-managed, petabyte-scale data warehouse service that
makes it simple and cost-effective to efficiently analyze all your data using your existing
business intelligence tools. 5 It is optimized for datasets ranging from a few hundred
gigabytes to a petabyte or more, and is designed to cost less than a tenth of the cost of
most traditional data warehousing solutions. Amazon Redshift delivers fast query and
I/O performance for virtually any size dataset by using columnar storage technology
while parallelizing and distributing queries across multiple nodes. As a managed service,
automation is provided for most of the common administrative tasks associated with
provisioning, configuring, monitoring, backing up, and securing a data warehouse,
making it very easy and inexpensive to manage and maintain. This automation allows
you to build a petabyte-scale data warehouse in minutes, a task that has traditionally
taken weeks, or months, to complete in an on-premises implementation.
Ideal Usage Pattern
Amazon Redshift is ideal for online analytical processing (OLAP) using your existing
business intelligence tools. Organizations are using Amazon Redshift to do the following:

Page 4 of 29
Analyze global sales data for multiple products
Store historical stock trade data
Analyze ad impressions and clicks
Aggregate gaming data
Analyze social trends
1 http://aws.amazon.com/about-aws/globalinfrastructure/
2 http://aws.amazon.com/s3/
3 http://aws.amazon.com/datapipeline/
4 http://aws.amazon.com/solutions/case-studies/big-data/

Page 4 of 29
Analyze global sales data for multiple products
Store historical stock trade data
Analyze ad impressions and clicks
Aggregate gaming data
Analyze social trends
1 http://aws.amazon.com/about-aws/globalinfrastructure/
2 http://aws.amazon.com/s3/
3 http://aws.amazon.com/datapipeline/
4 http://aws.amazon.com/solutions/case-studies/big-data/

needs without having to wait for additional hardware, or being required to over-invest to
provision enough capacity. For mission-critical applications on a more traditional
infrastructure, system designers have no choice but to over-provision, because a surge
in additional data due to an increase in business need must be something the system
can handle. By contrast, on AWS you can provision more capacity and compute in a
matter of minutes, meaning that your big data applications grow and shrink as demand
dictates, and your system runs as close to optimal efficiency as possible. In addition, you
get flexible computing on a world-class infrastructure with access to the many different
geographic regions that AWS offers 1 , along with the ability to utilize other scalable
services that Amazon offers such as Amazon Simple Storage Service (S3) 2 and AWS
Data Pipeline. 3 These capabilities of the AWS platform make it an extremely good fit for
solving big data problems. You can read about many customers that have implemented
successful big data analytics workloads on AWS on the AWS case studies web page. 4
Amazon Redshift
Amazon Redshift is a fast, fully-managed, petabyte-scale data warehouse service that
makes it simple and cost-effective to efficiently analyze all your data using your existing
business intelligence tools. 5 It is optimized for datasets ranging from a few hundred
gigabytes to a petabyte or more, and is designed to cost less than a tenth of the cost of
most traditional data warehousing solutions. Amazon Redshift delivers fast query and
I/O performance for virtually any size dataset by using columnar storage technology
while parallelizing and distributing queries across multiple nodes. As a managed service,
automation is provided for most of the common administrative tasks associated with
provisioning, configuring, monitoring, backing up, and securing a data warehouse,
making it very easy and inexpensive to manage and maintain. This automation allows
you to build a petabyte-scale data warehouse in minutes, a task that has traditionally
taken weeks, or months, to complete in an on-premises implementation.
Ideal Usage Pattern
Amazon Redshift is ideal for online analytical processing (OLAP) using your existing
business intelligence tools. Organizations are using Amazon Redshift to do the following:
needs without having to wait for additional hardware, or being required to over-invest to
provision enough capacity. For mission-critical applications on a more traditional
infrastructure, system designers have no choice but to over-provision, because a surge
in additional data due to an increase in business need must be something the system
can handle. By contrast, on AWS you can provision more capacity and compute in a
matter of minutes, meaning that your big data applications grow and shrink as demand
dictates, and your system runs as close to optimal efficiency as possible. In addition, you
get flexible computing on a world-class infrastructure with access to the many different
geographic regions that AWS offers 1 , along with the ability to utilize other scalable
services that Amazon offers such as Amazon Simple Storage Service (S3) 2 and AWS
Data Pipeline. 3 These capabilities of the AWS platform make it an extremely good fit for
solving big data problems. You can read about many customers that have implemented
successful big data analytics workloads on AWS on the AWS case studies web page. 4
Amazon Redshift
Amazon Redshift is a fast, fully-managed, petabyte-scale data warehouse service that
makes it simple and cost-effective to efficiently analyze all your data using your existing
business intelligence tools. 5 It is optimized for datasets ranging from a few hundred
gigabytes to a petabyte or more, and is designed to cost less than a tenth of the cost of
most traditional data warehousing solutions. Amazon Redshift delivers fast query and
I/O performance for virtually any size dataset by using columnar storage technology
while parallelizing and distributing queries across multiple nodes. As a managed service,
automation is provided for most of the common administrative tasks associated with
provisioning, configuring, monitoring, backing up, and securing a data warehouse,
making it very easy and inexpensive to manage and maintain. This automation allows
you to build a petabyte-scale data warehouse in minutes, a task that has traditionally
taken weeks, or months, to complete in an on-premises implementation.
Ideal Usage Pattern
Amazon Redshift is ideal for online analytical processing (OLAP) using your existing
business intelligence tools. Organizations are using Amazon Redshift to do the following:

Page 4 of 29
Analyze global sales data for multiple products
Store historical stock trade data
Analyze ad impressions and clicks
Aggregate gaming data
Analyze social trends
1 http://aws.amazon.com/about-aws/globalinfrastructure/
2 http://aws.amazon.com/s3/
3 http://aws.amazon.com/datapipeline/
4 http://aws.amazon.com/solutions/case-studies/big-data/

Page 4 of 29
Analyze global sales data for multiple products
Store historical stock trade data
Analyze ad impressions and clicks
Aggregate gaming data
Analyze social trends
1 http://aws.amazon.com/about-aws/globalinfrastructure/
2 http://aws.amazon.com/s3/
3 http://aws.amazon.com/datapipeline/
4 http://aws.amazon.com/solutions/case-studies/big-data/
needs without having to wait for additional hardware, or being required to over-invest to
provision enough capacity. For mission-critical applications on a more traditional
infrastructure, system designers have no choice but to over-provision, because a surge
in additional data due to an increase in business need must be something the system
can handle. By contrast, on AWS you can provision more capacity and compute in a
matter of minutes, meaning that your big data applications grow and shrink as demand
dictates, and your system runs as close to optimal efficiency as possible. In addition, you
get flexible computing on a world-class infrastructure with access to the many different
geographic regions that AWS offers 1 , along with the ability to utilize other scalable
services that Amazon offers such as Amazon Simple Storage Service (S3) 2 and AWS
Data Pipeline. 3 These capabilities of the AWS platform make it an extremely good fit for
solving big data problems. You can read about many customers that have implemented
successful big data analytics workloads on AWS on the AWS case studies web page. 4
Amazon Redshift
Amazon Redshift is a fast, fully-managed, petabyte-scale data warehouse service that
makes it simple and cost-effective to efficiently analyze all your data using your existing
business intelligence tools. 5 It is optimized for datasets ranging from a few hundred
gigabytes to a petabyte or more, and is designed to cost less than a tenth of the cost of
most traditional data warehousing solutions. Amazon Redshift delivers fast query and
I/O performance for virtually any size dataset by using columnar storage technology
while parallelizing and distributing queries across multiple nodes. As a managed service,
automation is provided for most of the common administrative tasks associated with
provisioning, configuring, monitoring, backing up, and securing a data warehouse,
making it very easy and inexpensive to manage and maintain. This automation allows
you to build a petabyte-scale data warehouse in minutes, a task that has traditionally
taken weeks, or months, to complete in an on-premises implementation.
Ideal Usage Pattern
Amazon Redshift is ideal for online analytical processing (OLAP) using your existing
business intelligence tools. Organizations are using Amazon Redshift to do the following:
needs without having to wait for additional hardware, or being required to over-invest to
provision enough capacity. For mission-critical applications on a more traditional
infrastructure, system designers have no choice but to over-provision, because a surge
in additional data due to an increase in business need must be something the system
can handle. By contrast, on AWS you can provision more capacity and compute in a
matter of minutes, meaning that your big data applications grow and shrink as demand
dictates, and your system runs as close to optimal efficiency as possible. In addition, you
get flexible computing on a world-class infrastructure with access to the many different
geographic regions that AWS offers 1 , along with the ability to utilize other scalable
services that Amazon offers such as Amazon Simple Storage Service (S3) 2 and AWS
Data Pipeline. 3 These capabilities of the AWS platform make it an extremely good fit for
solving big data problems. You can read about many customers that have implemented
successful big data analytics workloads on AWS on the AWS case studies web page. 4
Amazon Redshift
Amazon Redshift is a fast, fully-managed, petabyte-scale data warehouse service that
makes it simple and cost-effective to efficiently analyze all your data using your existing
business intelligence tools. 5 It is optimized for datasets ranging from a few hundred
gigabytes to a petabyte or more, and is designed to cost less than a tenth of the cost of
most traditional data warehousing solutions. Amazon Redshift delivers fast query and
I/O performance for virtually any size dataset by using columnar storage technology
while parallelizing and distributing queries across multiple nodes. As a managed service,
automation is provided for most of the common administrative tasks associated with
provisioning, configuring, monitoring, backing up, and securing a data warehouse,
making it very easy and inexpensive to manage and maintain. This automation allows
you to build a petabyte-scale data warehouse in minutes, a task that has traditionally
taken weeks, or months, to complete in an on-premises implementation.
Ideal Usage Pattern
Amazon Redshift is ideal for online analytical processing (OLAP) using your existing
business intelligence tools. Organizations are using Amazon Redshift to do the following:

Page 4 of 29
Analyze global sales data for multiple products
Store historical stock trade data
Analyze ad impressions and clicks
Aggregate gaming data
Analyze social trends
1 http://aws.amazon.com/about-aws/globalinfrastructure/
2 http://aws.amazon.com/s3/
3 http://aws.amazon.com/datapipeline/
4 http://aws.amazon.com/solutions/case-studies/big-data/

Page 4 of 29
Analyze global sales data for multiple products
Store historical stock trade data
Analyze ad impressions and clicks
Aggregate gaming data
Analyze social trends
1 http://aws.amazon.com/about-aws/globalinfrastructure/
2 http://aws.amazon.com/s3/
3 http://aws.amazon.com/datapipeline/
4 http://aws.amazon.com/solutions/case-studies/big-data/
needs without having to wait for additional hardware, or being required to over-invest to
provision enough capacity. For mission-critical applications on a more traditional
infrastructure, system designers have no choice but to over-provision, because a surge
in additional data due to an increase in business need must be something the system
can handle. By contrast, on AWS you can provision more capacity and compute in a
matter of minutes, meaning that your big data applications grow and shrink as demand
dictates, and your system runs as close to optimal efficiency as possible. In addition, you
get flexible computing on a world-class infrastructure with access to the many different
geographic regions that AWS offers 1 , along with the ability to utilize other scalable
services that Amazon offers such as Amazon Simple Storage Service (S3) 2 and AWS
Data Pipeline. 3 These capabilities of the AWS platform make it an extremely good fit for
solving big data problems. You can read about many customers that have implemented
successful big data analytics workloads on AWS on the AWS case studies web page. 4
Amazon Redshift
Amazon Redshift is a fast, fully-managed, petabyte-scale data warehouse service that
makes it simple and cost-effective to efficiently analyze all your data using your existing
business intelligence tools. 5 It is optimized for datasets ranging from a few hundred
gigabytes to a petabyte or more, and is designed to cost less than a tenth of the cost of
most traditional data warehousing solutions. Amazon Redshift delivers fast query and
I/O performance for virtually any size dataset by using columnar storage technology
while parallelizing and distributing queries across multiple nodes. As a managed service,
automation is provided for most of the common administrative tasks associated with
provisioning, configuring, monitoring, backing up, and securing a data warehouse,
making it very easy and inexpensive to manage and maintain. This automation allows
you to build a petabyte-scale data warehouse in minutes, a task that has traditionally
taken weeks, or months, to complete in an on-premises implementation.
Ideal Usage Pattern
Amazon Redshift is ideal for online analytical processing (OLAP) using your existing
business intelligence tools. Organizations are using Amazon Redshift to do the following:
needs without having to wait for additional hardware, or being required to over-invest to
provision enough capacity. For mission-critical applications on a more traditional
infrastructure, system designers have no choice but to over-provision, because a surge
in additional data due to an increase in business need must be something the system
can handle. By contrast, on AWS you can provision more capacity and compute in a
matter of minutes, meaning that your big data applications grow and shrink as demand
dictates, and your system runs as close to optimal efficiency as possible. In addition, you
get flexible computing on a world-class infrastructure with access to the many different
geographic regions that AWS offers 1 , along with the ability to utilize other scalable
services that Amazon offers such as Amazon Simple Storage Service (S3) 2 and AWS
Data Pipeline. 3 These capabilities of the AWS platform make it an extremely good fit for
solving big data problems. You can read about many customers that have implemented
successful big data analytics workloads on AWS on the AWS case studies web page. 4
Amazon Redshift
Amazon Redshift is a fast, fully-managed, petabyte-scale data warehouse service that
makes it simple and cost-effective to efficiently analyze all your data using your existing
business intelligence tools. 5 It is optimized for datasets ranging from a few hundred
gigabytes to a petabyte or more, and is designed to cost less than a tenth of the cost of
most traditional data warehousing solutions. Amazon Redshift delivers fast query and
I/O performance for virtually any size dataset by using columnar storage technology
while parallelizing and distributing queries across multiple nodes. As a managed service,
automation is provided for most of the common administrative tasks associated with
provisioning, configuring, monitoring, backing up, and securing a data warehouse,
making it very easy and inexpensive to manage and maintain. This automation allows
you to build a petabyte-scale data warehouse in minutes, a task that has traditionally
taken weeks, or months, to complete in an on-premises implementation.
Ideal Usage Pattern
Amazon Redshift is ideal for online analytical processing (OLAP) using your existing
business intelligence tools. Organizations are using Amazon Redshift to do the following:

Page 4 of 29
Analyze global sales data for multiple products
Store historical stock trade data
Analyze ad impressions and clicks
Aggregate gaming data
Analyze social trends
1 http://aws.amazon.com/about-aws/globalinfrastructure/
2 http://aws.amazon.com/s3/
3 http://aws.amazon.com/datapipeline/
4 http://aws.amazon.com/solutions/case-studies/big-data/

Page 4 of 29
Analyze global sales data for multiple products
Store historical stock trade data
Analyze ad impressions and clicks
Aggregate gaming data
Analyze social trends
1 http://aws.amazon.com/about-aws/globalinfrastructure/
2 http://aws.amazon.com/s3/
3 http://aws.amazon.com/datapipeline/
4 http://aws.amazon.com/solutions/case-studies/big-data/

needs without having to wait for additional hardware, or being required to over-invest to
provision enough capacity. For mission-critical applications on a more traditional
infrastructure, system designers have no choice but to over-provision, because a surge
in additional data due to an increase in business need must be something the system
can handle. By contrast, on AWS you can provision more capacity and compute in a
matter of minutes, meaning that your big data applications grow and shrink as demand
dictates, and your system runs as close to optimal efficiency as possible. In addition, you
get flexible computing on a world-class infrastructure with access to the many different
geographic regions that AWS offers 1 , along with the ability to utilize other scalable
services that Amazon offers such as Amazon Simple Storage Service (S3) 2 and AWS
Data Pipeline. 3 These capabilities of the AWS platform make it an extremely good fit for
solving big data problems. You can read about many customers that have implemented
successful big data analytics workloads on AWS on the AWS case studies web page. 4
Amazon Redshift
Amazon Redshift is a fast, fully-managed, petabyte-scale data warehouse service that
makes it simple and cost-effective to efficiently analyze all your data using your existing
business intelligence tools. 5 It is optimized for datasets ranging from a few hundred
gigabytes to a petabyte or more, and is designed to cost less than a tenth of the cost of
most traditional data warehousing solutions. Amazon Redshift delivers fast query and
I/O performance for virtually any size dataset by using columnar storage technology
while parallelizing and distributing queries across multiple nodes. As a managed service,
automation is provided for most of the common administrative tasks associated with
provisioning, configuring, monitoring, backing up, and securing a data warehouse,
making it very easy and inexpensive to manage and maintain. This automation allows
you to build a petabyte-scale data warehouse in minutes, a task that has traditionally
taken weeks, or months, to complete in an on-premises implementation.
Ideal Usage Pattern
Amazon Redshift is ideal for online analytical processing (OLAP) using your existing
business intelligence tools. Organizations are using Amazon Redshift to do the following:
needs without having to wait for additional hardware, or being required to over-invest to
provision enough capacity. For mission-critical applications on a more traditional
infrastructure, system designers have no choice but to over-provision, because a surge
in additional data due to an increase in business need must be something the system
can handle. By contrast, on AWS you can provision more capacity and compute in a
matter of minutes, meaning that your big data applications grow and shrink as demand
dictates, and your system runs as close to optimal efficiency as possible. In addition, you
get flexible computing on a world-class infrastructure with access to the many different
geographic regions that AWS offers 1 , along with the ability to utilize other scalable
services that Amazon offers such as Amazon Simple Storage Service (S3) 2 and AWS
Data Pipeline. 3 These capabilities of the AWS platform make it an extremely good fit for
solving big data problems. You can read about many customers that have implemented
successful big data analytics workloads on AWS on the AWS case studies web page. 4
Amazon Redshift
Amazon Redshift is a fast, fully-managed, petabyte-scale data warehouse service that
makes it simple and cost-effective to efficiently analyze all your data using your existing
business intelligence tools. 5 It is optimized for datasets ranging from a few hundred
gigabytes to a petabyte or more, and is designed to cost less than a tenth of the cost of
most traditional data warehousing solutions. Amazon Redshift delivers fast query and
I/O performance for virtually any size dataset by using columnar storage technology
while parallelizing and distributing queries across multiple nodes. As a managed service,
automation is provided for most of the common administrative tasks associated with
provisioning, configuring, monitoring, backing up, and securing a data warehouse,
making it very easy and inexpensive to manage and maintain. This automation allows
you to build a petabyte-scale data warehouse in minutes, a task that has traditionally
taken weeks, or months, to complete in an on-premises implementation.
Ideal Usage Pattern
Amazon Redshift is ideal for online analytical processing (OLAP) using your existing
business intelligence tools. Organizations are using Amazon Redshift to do the following:

Page 4 of 29
Analyze global sales data for multiple products
Store historical stock trade data
Analyze ad impressions and clicks
Aggregate gaming data
Analyze social trends
1 http://aws.amazon.com/about-aws/globalinfrastructure/
2 http://aws.amazon.com/s3/
3 http://aws.amazon.com/datapipeline/
4 http://aws.amazon.com/solutions/case-studies/big-data/

Page 4 of 29
Analyze global sales data for multiple products
Store historical stock trade data
Analyze ad impressions and clicks
Aggregate gaming data
Analyze social trends
1 http://aws.amazon.com/about-aws/globalinfrastructure/
2 http://aws.amazon.com/s3/
3 http://aws.amazon.com/datapipeline/
4 http://aws.amazon.com/solutions/case-studies/big-data/

needs without having to wait for additional hardware, or being required to over-invest to
provision enough capacity. For mission-critical applications on a more traditional
infrastructure, system designers have no choice but to over-provision, because a surge
in additional data due to an increase in business need must be something the system
can handle. By contrast, on AWS you can provision more capacity and compute in a
matter of minutes, meaning that your big data applications grow and shrink as demand
dictates, and your system runs as close to optimal efficiency as possible. In addition, you
get flexible computing on a world-class infrastructure with access to the many different
geographic regions that AWS offers 1 , along with the ability to utilize other scalable
services that Amazon offers such as Amazon Simple Storage Service (S3) 2 and AWS
Data Pipeline. 3 These capabilities of the AWS platform make it an extremely good fit for
solving big data problems. You can read about many customers that have implemented
successful big data analytics workloads on AWS on the AWS case studies web page. 4
Amazon Redshift
Amazon Redshift is a fast, fully-managed, petabyte-scale data warehouse service that
makes it simple and cost-effective to efficiently analyze all your data using your existing
business intelligence tools. 5 It is optimized for datasets ranging from a few hundred
gigabytes to a petabyte or more, and is designed to cost less than a tenth of the cost of
most traditional data warehousing solutions. Amazon Redshift delivers fast query and
I/O performance for virtually any size dataset by using columnar storage technology
while parallelizing and distributing queries across multiple nodes. As a managed service,
automation is provided for most of the common administrative tasks associated with
provisioning, configuring, monitoring, backing up, and securing a data warehouse,
making it very easy and inexpensive to manage and maintain. This automation allows
you to build a petabyte-scale data warehouse in minutes, a task that has traditionally
taken weeks, or months, to complete in an on-premises implementation.
Ideal Usage Pattern
Amazon Redshift is ideal for online analytical processing (OLAP) using your existing
business intelligence tools. Organizations are using Amazon Redshift to do the following:
needs without having to wait for additional hardware, or being required to over-invest to
provision enough capacity. For mission-critical applications on a more traditional
infrastructure, system designers have no choice but to over-provision, because a surge
in additional data due to an increase in business need must be something the system
can handle. By contrast, on AWS you can provision more capacity and compute in a
matter of minutes, meaning that your big data applications grow and shrink as demand
dictates, and your system runs as close to optimal efficiency as possible. In addition, you
get flexible computing on a world-class infrastructure with access to the many different
geographic regions that AWS offers 1 , along with the ability to utilize other scalable
services that Amazon offers such as Amazon Simple Storage Service (S3) 2 and AWS
Data Pipeline. 3 These capabilities of the AWS platform make it an extremely good fit for
solving big data problems. You can read about many customers that have implemented
successful big data analytics workloads on AWS on the AWS case studies web page. 4
Amazon Redshift
Amazon Redshift is a fast, fully-managed, petabyte-scale data warehouse service that
makes it simple and cost-effective to efficiently analyze all your data using your existing
business intelligence tools. 5 It is optimized for datasets ranging from a few hundred
gigabytes to a petabyte or more, and is designed to cost less than a tenth of the cost of
most traditional data warehousing solutions. Amazon Redshift delivers fast query and
I/O performance for virtually any size dataset by using columnar storage technology
while parallelizing and distributing queries across multiple nodes. As a managed service,
automation is provided for most of the common administrative tasks associated with
provisioning, configuring, monitoring, backing up, and securing a data warehouse,
making it very easy and inexpensive to manage and maintain. This automation allows
you to build a petabyte-scale data warehouse in minutes, a task that has traditionally
taken weeks, or months, to complete in an on-premises implementation.
Ideal Usage Pattern
Amazon Redshift is ideal for online analytical processing (OLAP) using your existing
business intelligence tools. Organizations are using Amazon Redshift to do the following:

Page 4 of 29
Analyze global sales data for multiple products
Store historical stock trade data
Analyze ad impressions and clicks
Aggregate gaming data
Analyze social trends
1 http://aws.amazon.com/about-aws/globalinfrastructure/
2 http://aws.amazon.com/s3/
3 http://aws.amazon.com/datapipeline/
4 http://aws.amazon.com/solutions/case-studies/big-data/

Page 4 of 29
Analyze global sales data for multiple products
Store historical stock trade data
Analyze ad impressions and clicks
Aggregate gaming data
Analyze social trends
1 http://aws.amazon.com/about-aws/globalinfrastructure/
2 http://aws.amazon.com/s3/
3 http://aws.amazon.com/datapipeline/
4 http://aws.amazon.com/solutions/case-studies/big-data/

needs without having to wait for additional hardware, or being required to over-invest to
provision enough capacity. For mission-critical applications on a more traditional
infrastructure, system designers have no choice but to over-provision, because a surge
in additional data due to an increase in business need must be something the system
can handle. By contrast, on AWS you can provision more capacity and compute in a
matter of minutes, meaning that your big data applications grow and shrink as demand
dictates, and your system runs as close to optimal efficiency as possible. In addition, you
get flexible computing on a world-class infrastructure with access to the many different
geographic regions that AWS offers 1 , along with the ability to utilize other scalable
services that Amazon offers such as Amazon Simple Storage Service (S3) 2 and AWS
Data Pipeline. 3 These capabilities of the AWS platform make it an extremely good fit for
solving big data problems. You can read about many customers that have implemented
successful big data analytics workloads on AWS on the AWS case studies web page. 4
Amazon Redshift
Amazon Redshift is a fast, fully-managed, petabyte-scale data warehouse service that
makes it simple and cost-effective to efficiently analyze all your data using your existing
business intelligence tools. 5 It is optimized for datasets ranging from a few hundred
gigabytes to a petabyte or more, and is designed to cost less than a tenth of the cost of
most traditional data warehousing solutions. Amazon Redshift delivers fast query and
I/O performance for virtually any size dataset by using columnar storage technology
while parallelizing and distributing queries across multiple nodes. As a managed service,
automation is provided for most of the common administrative tasks associated with
provisioning, configuring, monitoring, backing up, and securing a data warehouse,
making it very easy and inexpensive to manage and maintain. This automation allows
you to build a petabyte-scale data warehouse in minutes, a task that has traditionally
taken weeks, or months, to complete in an on-premises implementation.
Ideal Usage Pattern
Amazon Redshift is ideal for online analytical processing (OLAP) using your existing
business intelligence tools. Organizations are using Amazon Redshift to do the following:
needs without having to wait for additional hardware, or being required to over-invest to
provision enough capacity. For mission-critical applications on a more traditional
infrastructure, system designers have no choice but to over-provision, because a surge
in additional data due to an increase in business need must be something the system
can handle. By contrast, on AWS you can provision more capacity and compute in a
matter of minutes, meaning that your big data applications grow and shrink as demand
dictates, and your system runs as close to optimal efficiency as possible. In addition, you
get flexible computing on a world-class infrastructure with access to the many different
geographic regions that AWS offers 1 , along with the ability to utilize other scalable
services that Amazon offers such as Amazon Simple Storage Service (S3) 2 and AWS
Data Pipeline. 3 These capabilities of the AWS platform make it an extremely good fit for
solving big data problems. You can read about many customers that have implemented
successful big data analytics workloads on AWS on the AWS case studies web page. 4
Amazon Redshift
Amazon Redshift is a fast, fully-managed, petabyte-scale data warehouse service that
makes it simple and cost-effective to efficiently analyze all your data using your existing
business intelligence tools. 5 It is optimized for datasets ranging from a few hundred
gigabytes to a petabyte or more, and is designed to cost less than a tenth of the cost of
most traditional data warehousing solutions. Amazon Redshift delivers fast query and
I/O performance for virtually any size dataset by using columnar storage technology
while parallelizing and distributing queries across multiple nodes. As a managed service,
automation is provided for most of the common administrative tasks associated with
provisioning, configuring, monitoring, backing up, and securing a data warehouse,
making it very easy and inexpensive to manage and maintain. This automation allows
you to build a petabyte-scale data warehouse in minutes, a task that has traditionally
taken weeks, or months, to complete in an on-premises implementation.
Ideal Usage Pattern
Amazon Redshift is ideal for online analytical processing (OLAP) using your existing
business intelligence tools. Organizations are using Amazon Redshift to do the following:

Page 4 of 29
Analyze global sales data for multiple products
Store historical stock trade data
Analyze ad impressions and clicks
Aggregate gaming data
Analyze social trends
1 http://aws.amazon.com/about-aws/globalinfrastructure/
2 http://aws.amazon.com/s3/
3 http://aws.amazon.com/datapipeline/
4 http://aws.amazon.com/solutions/case-studies/big-data/

Page 4 of 29
Analyze global sales data for multiple products
Store historical stock trade data
Analyze ad impressions and clicks
Aggregate gaming data
Analyze social trends
1 http://aws.amazon.com/about-aws/globalinfrastructure/
2 http://aws.amazon.com/s3/
3 http://aws.amazon.com/datapipeline/
4 http://aws.amazon.com/solutions/case-studies/big-data/

needs without having to wait for additional hardware, or being required to over-invest to
provision enough capacity. For mission-critical applications on a more traditional
infrastructure, system designers have no choice but to over-provision, because a surge
in additional data due to an increase in business need must be something the system
can handle. By contrast, on AWS you can provision more capacity and compute in a
matter of minutes, meaning that your big data applications grow and shrink as demand
dictates, and your system runs as close to optimal efficiency as possible. In addition, you
get flexible computing on a world-class infrastructure with access to the many different
geographic regions that AWS offers 1 , along with the ability to utilize other scalable
services that Amazon offers such as Amazon Simple Storage Service (S3) 2 and AWS
Data Pipeline. 3 These capabilities of the AWS platform make it an extremely good fit for
solving big data problems. You can read about many customers that have implemented
successful big data analytics workloads on AWS on the AWS case studies web page. 4
Amazon Redshift
Amazon Redshift is a fast, fully-managed, petabyte-scale data warehouse service that
makes it simple and cost-effective to efficiently analyze all your data using your existing
business intelligence tools. 5 It is optimized for datasets ranging from a few hundred
gigabytes to a petabyte or more, and is designed to cost less than a tenth of the cost of
most traditional data warehousing solutions. Amazon Redshift delivers fast query and
I/O performance for virtually any size dataset by using columnar storage technology
while parallelizing and distributing queries across multiple nodes. As a managed service,
automation is provided for most of the common administrative tasks associated with
provisioning, configuring, monitoring, backing up, and securing a data warehouse,
making it very easy and inexpensive to manage and maintain. This automation allows
you to build a petabyte-scale data warehouse in minutes, a task that has traditionally
taken weeks, or months, to complete in an on-premises implementation.
Ideal Usage Pattern
Amazon Redshift is ideal for online analytical processing (OLAP) using your existing
business intelligence tools. Organizations are using Amazon Redshift to do the following:
needs without having to wait for additional hardware, or being required to over-invest to
provision enough capacity. For mission-critical applications on a more traditional
infrastructure, system designers have no choice but to over-provision, because a surge
in additional data due to an increase in business need must be something the system
can handle. By contrast, on AWS you can provision more capacity and compute in a
matter of minutes, meaning that your big data applications grow and shrink as demand
dictates, and your system runs as close to optimal efficiency as possible. In addition, you
get flexible computing on a world-class infrastructure with access to the many different
geographic regions that AWS offers 1 , along with the ability to utilize other scalable
services that Amazon offers such as Amazon Simple Storage Service (S3) 2 and AWS
Data Pipeline. 3 These capabilities of the AWS platform make it an extremely good fit for
solving big data problems. You can read about many customers that have implemented
successful big data analytics workloads on AWS on the AWS case studies web page. 4
Amazon Redshift
Amazon Redshift is a fast, fully-managed, petabyte-scale data warehouse service that
makes it simple and cost-effective to efficiently analyze all your data using your existing
business intelligence tools. 5 It is optimized for datasets ranging from a few hundred
gigabytes to a petabyte or more, and is designed to cost less than a tenth of the cost of
most traditional data warehousing solutions. Amazon Redshift delivers fast query and
I/O performance for virtually any size dataset by using columnar storage technology
while parallelizing and distributing queries across multiple nodes. As a managed service,
automation is provided for most of the common administrative tasks associated with
provisioning, configuring, monitoring, backing up, and securing a data warehouse,
making it very easy and inexpensive to manage and maintain. This automation allows
you to build a petabyte-scale data warehouse in minutes, a task that has traditionally
taken weeks, or months, to complete in an on-premises implementation.
Ideal Usage Pattern
Amazon Redshift is ideal for online analytical processing (OLAP) using your existing
business intelligence tools. Organizations are using Amazon Redshift to do the following:

Page 4 of 29
Analyze global sales data for multiple products
Store historical stock trade data
Analyze ad impressions and clicks
Aggregate gaming data
Analyze social trends
1 http://aws.amazon.com/about-aws/globalinfrastructure/
2 http://aws.amazon.com/s3/
3 http://aws.amazon.com/datapipeline/
4 http://aws.amazon.com/solutions/case-studies/big-data/

Page 4 of 29
Analyze global sales data for multiple products
Store historical stock trade data
Analyze ad impressions and clicks
Aggregate gaming data
Analyze social trends
1 http://aws.amazon.com/about-aws/globalinfrastructure/
2 http://aws.amazon.com/s3/
3 http://aws.amazon.com/datapipeline/
4 http://aws.amazon.com/solutions/case-studies/big-data/

needs without having to wait for additional hardware, or being required to over-invest to
provision enough capacity. For mission-critical applications on a more traditional
infrastructure, system designers have no choice but to over-provision, because a surge
in additional data due to an increase in business need must be something the system
can handle. By contrast, on AWS you can provision more capacity and compute in a
matter of minutes, meaning that your big data applications grow and shrink as demand
dictates, and your system runs as close to optimal efficiency as possible. In addition, you
get flexible computing on a world-class infrastructure with access to the many different
geographic regions that AWS offers 1 , along with the ability to utilize other scalable
services that Amazon offers such as Amazon Simple Storage Service (S3) 2 and AWS
Data Pipeline. 3 These capabilities of the AWS platform make it an extremely good fit for
solving big data problems. You can read about many customers that have implemented
successful big data analytics workloads on AWS on the AWS case studies web page. 4
Amazon Redshift
Amazon Redshift is a fast, fully-managed, petabyte-scale data warehouse service that
makes it simple and cost-effective to efficiently analyze all your data using your existing
business intelligence tools. 5 It is optimized for datasets ranging from a few hundred
gigabytes to a petabyte or more, and is designed to cost less than a tenth of the cost of
most traditional data warehousing solutions. Amazon Redshift delivers fast query and
I/O performance for virtually any size dataset by using columnar storage technology
while parallelizing and distributing queries across multiple nodes. As a managed service,
automation is provided for most of the common administrative tasks associated with
provisioning, configuring, monitoring, backing up, and securing a data warehouse,
making it very easy and inexpensive to manage and maintain. This automation allows
you to build a petabyte-scale data warehouse in minutes, a task that has traditionally
taken weeks, or months, to complete in an on-premises implementation.
Ideal Usage Pattern
Amazon Redshift is ideal for online analytical processing (OLAP) using your existing
business intelligence tools. Organizations are using Amazon Redshift to do the following:
needs without having to wait for additional hardware, or being required to over-invest to
provision enough capacity. For mission-critical applications on a more traditional
infrastructure, system designers have no choice but to over-provision, because a surge
in additional data due to an increase in business need must be something the system
can handle. By contrast, on AWS you can provision more capacity and compute in a
matter of minutes, meaning that your big data applications grow and shrink as demand
dictates, and your system runs as close to optimal efficiency as possible. In addition, you
get flexible computing on a world-class infrastructure with access to the many different
geographic regions that AWS offers 1 , along with the ability to utilize other scalable
services that Amazon offers such as Amazon Simple Storage Service (S3) 2 and AWS
Data Pipeline. 3 These capabilities of the AWS platform make it an extremely good fit for
solving big data problems. You can read about many customers that have implemented
successful big data analytics workloads on AWS on the AWS case studies web page. 4
Amazon Redshift
Amazon Redshift is a fast, fully-managed, petabyte-scale data warehouse service that
makes it simple and cost-effective to efficiently analyze all your data using your existing
business intelligence tools. 5 It is optimized for datasets ranging from a few hundred
gigabytes to a petabyte or more, and is designed to cost less than a tenth of the cost of
most traditional data warehousing solutions. Amazon Redshift delivers fast query and
I/O performance for virtually any size dataset by using columnar storage technology
while parallelizing and distributing queries across multiple nodes. As a managed service,
automation is provided for most of the common administrative tasks associated with
provisioning, configuring, monitoring, backing up, and securing a data warehouse,
making it very easy and inexpensive to manage and maintain. This automation allows
you to build a petabyte-scale data warehouse in minutes, a task that has traditionally
taken weeks, or months, to complete in an on-premises implementation.
Ideal Usage Pattern
Amazon Redshift is ideal for online analytical processing (OLAP) using your existing
business intelligence tools. Organizations are using Amazon Redshift to do the following:

Page 4 of 29
Analyze global sales data for multiple products
Store historical stock trade data
Analyze ad impressions and clicks
Aggregate gaming data
Analyze social trends
1 http://aws.amazon.com/about-aws/globalinfrastructure/
2 http://aws.amazon.com/s3/
3 http://aws.amazon.com/datapipeline/
4 http://aws.amazon.com/solutions/case-studies/big-data/

Page 4 of 29
Analyze global sales data for multiple products
Store historical stock trade data
Analyze ad impressions and clicks
Aggregate gaming data
Analyze social trends
1 http://aws.amazon.com/about-aws/globalinfrastructure/
2 http://aws.amazon.com/s3/
3 http://aws.amazon.com/datapipeline/
4 http://aws.amazon.com/solutions/case-studies/big-data/

needs without having to wait for additional hardware, or being required to over-invest to
provision enough capacity. For mission-critical applications on a more traditional
infrastructure, system designers have no choice but to over-provision, because a surge
in additional data due to an increase in business need must be something the system
can handle. By contrast, on AWS you can provision more capacity and compute in a
matter of minutes, meaning that your big data applications grow and shrink as demand
dictates, and your system runs as close to optimal efficiency as possible. In addition, you
get flexible computing on a world-class infrastructure with access to the many different
geographic regions that AWS offers 1 , along with the ability to utilize other scalable
services that Amazon offers such as Amazon Simple Storage Service (S3) 2 and AWS
Data Pipeline. 3 These capabilities of the AWS platform make it an extremely good fit for
solving big data problems. You can read about many customers that have implemented
successful big data analytics workloads on AWS on the AWS case studies web page. 4
Amazon Redshift
Amazon Redshift is a fast, fully-managed, petabyte-scale data warehouse service that
makes it simple and cost-effective to efficiently analyze all your data using your existing
business intelligence tools. 5 It is optimized for datasets ranging from a few hundred
gigabytes to a petabyte or more, and is designed to cost less than a tenth of the cost of
most traditional data warehousing solutions. Amazon Redshift delivers fast query and
I/O performance for virtually any size dataset by using columnar storage technology
while parallelizing and distributing queries across multiple nodes. As a managed service,
automation is provided for most of the common administrative tasks associated with
provisioning, configuring, monitoring, backing up, and securing a data warehouse,
making it very easy and inexpensive to manage and maintain. This automation allows
you to build a petabyte-scale data warehouse in minutes, a task that has traditionally
taken weeks, or months, to complete in an on-premises implementation.
Ideal Usage Pattern
Amazon Redshift is ideal for online analytical processing (OLAP) using your existing
business intelligence tools. Organizations are using Amazon Redshift to do the following:
needs without having to wait for additional hardware, or being required to over-invest to
provision enough capacity. For mission-critical applications on a more traditional
infrastructure, system designers have no choice but to over-provision, because a surge
in additional data due to an increase in business need must be something the system
can handle. By contrast, on AWS you can provision more capacity and compute in a
matter of minutes, meaning that your big data applications grow and shrink as demand
dictates, and your system runs as close to optimal efficiency as possible. In addition, you
get flexible computing on a world-class infrastructure with access to the many different
geographic regions that AWS offers 1 , along with the ability to utilize other scalable
services that Amazon offers such as Amazon Simple Storage Service (S3) 2 and AWS
Data Pipeline. 3 These capabilities of the AWS platform make it an extremely good fit for
solving big data problems. You can read about many customers that have implemented
successful big data analytics workloads on AWS on the AWS case studies web page. 4
Amazon Redshift
Amazon Redshift is a fast, fully-managed, petabyte-scale data warehouse service that
makes it simple and cost-effective to efficiently analyze all your data using your existing
business intelligence tools. 5 It is optimized for datasets ranging from a few hundred
gigabytes to a petabyte or more, and is designed to cost less than a tenth of the cost of
most traditional data warehousing solutions. Amazon Redshift delivers fast query and
I/O performance for virtually any size dataset by using columnar storage technology
while parallelizing and distributing queries across multiple nodes. As a managed service,
automation is provided for most of the common administrative tasks associated with
provisioning, configuring, monitoring, backing up, and securing a data warehouse,
making it very easy and inexpensive to manage and maintain. This automation allows
you to build a petabyte-scale data warehouse in minutes, a task that has traditionally
taken weeks, or months, to complete in an on-premises implementation.
Ideal Usage Pattern
Amazon Redshift is ideal for online analytical processing (OLAP) using your existing
business intelligence tools. Organizations are using Amazon Redshift to do the following:

Page 4 of 29
Analyze global sales data for multiple products
Store historical stock trade data
Analyze ad impressions and clicks
Aggregate gaming data
Analyze social trends
1 http://aws.amazon.com/about-aws/globalinfrastructure/
2 http://aws.amazon.com/s3/
3 http://aws.amazon.com/datapipeline/
4 http://aws.amazon.com/solutions/case-studies/big-data/

Page 4 of 29
Analyze global sales data for multiple products
Store historical stock trade data
Analyze ad impressions and clicks
Aggregate gaming data
Analyze social trends
1 http://aws.amazon.com/about-aws/globalinfrastructure/
2 http://aws.amazon.com/s3/
3 http://aws.amazon.com/datapipeline/
4 http://aws.amazon.com/solutions/case-studies/big-data/

needs without having to wait for additional hardware, or being required to over-invest to
provision enough capacity. For mission-critical applications on a more traditional
infrastructure, system designers have no choice but to over-provision, because a surge
in additional data due to an increase in business need must be something the system
can handle. By contrast, on AWS you can provision more capacity and compute in a
matter of minutes, meaning that your big data applications grow and shrink as demand
dictates, and your system runs as close to optimal efficiency as possible. In addition, you
get flexible computing on a world-class infrastructure with access to the many different
geographic regions that AWS offers 1 , along with the ability to utilize other scalable
services that Amazon offers such as Amazon Simple Storage Service (S3) 2 and AWS
Data Pipeline. 3 These capabilities of the AWS platform make it an extremely good fit for
solving big data problems. You can read about many customers that have implemented
successful big data analytics workloads on AWS on the AWS case studies web page. 4
Amazon Redshift
Amazon Redshift is a fast, fully-managed, petabyte-scale data warehouse service that
makes it simple and cost-effective to efficiently analyze all your data using your existing
business intelligence tools. 5 It is optimized for datasets ranging from a few hundred
gigabytes to a petabyte or more, and is designed to cost less than a tenth of the cost of
most traditional data warehousing solutions. Amazon Redshift delivers fast query and
I/O performance for virtually any size dataset by using columnar storage technology
while parallelizing and distributing queries across multiple nodes. As a managed service,
automation is provided for most of the common administrative tasks associated with
provisioning, configuring, monitoring, backing up, and securing a data warehouse,
making it very easy and inexpensive to manage and maintain. This automation allows
you to build a petabyte-scale data warehouse in minutes, a task that has traditionally
taken weeks, or months, to complete in an on-premises implementation.
Ideal Usage Pattern
Amazon Redshift is ideal for online analytical processing (OLAP) using your existing
business intelligence tools. Organizations are using Amazon Redshift to do the following:
needs without having to wait for additional hardware, or being required to over-invest to
provision enough capacity. For mission-critical applications on a more traditional
infrastructure, system designers have no choice but to over-provision, because a surge
in additional data due to an increase in business need must be something the system
can handle. By contrast, on AWS you can provision more capacity and compute in a
matter of minutes, meaning that your big data applications grow and shrink as demand
dictates, and your system runs as close to optimal efficiency as possible. In addition, you
get flexible computing on a world-class infrastructure with access to the many different
geographic regions that AWS offers 1 , along with the ability to utilize other scalable
services that Amazon offers such as Amazon Simple Storage Service (S3) 2 and AWS
Data Pipeline. 3 These capabilities of the AWS platform make it an extremely good fit for
solving big data problems. You can read about many customers that have implemented
successful big data analytics workloads on AWS on the AWS case studies web page. 4
Amazon Redshift
Amazon Redshift is a fast, fully-managed, petabyte-scale data warehouse service that
makes it simple and cost-effective to efficiently analyze all your data using your existing
business intelligence tools. 5 It is optimized for datasets ranging from a few hundred
gigabytes to a petabyte or more, and is designed to cost less than a tenth of the cost of
most traditional data warehousing solutions. Amazon Redshift delivers fast query and
I/O performance for virtually any size dataset by using columnar storage technology
while parallelizing and distributing queries across multiple nodes. As a managed service,
automation is provided for most of the common administrative tasks associated with
provisioning, configuring, monitoring, backing up, and securing a data warehouse,
making it very easy and inexpensive to manage and maintain. This automation allows
you to build a petabyte-scale data warehouse in minutes, a task that has traditionally
taken weeks, or months, to complete in an on-premises implementation.
Ideal Usage Pattern
Amazon Redshift is ideal for online analytical processing (OLAP) using your existing
business intelligence tools. Organizations are using Amazon Redshift to do the following:

Page 4 of 29
Analyze global sales data for multiple products
Store historical stock trade data
Analyze ad impressions and clicks
Aggregate gaming data
Analyze social trends
1 http://aws.amazon.com/about-aws/globalinfrastructure/
2 http://aws.amazon.com/s3/
3 http://aws.amazon.com/datapipeline/
4 http://aws.amazon.com/solutions/case-studies/big-data/

Page 4 of 29
Analyze global sales data for multiple products
Store historical stock trade data
Analyze ad impressions and clicks
Aggregate gaming data
Analyze social trends
1 http://aws.amazon.com/about-aws/globalinfrastructure/
2 http://aws.amazon.com/s3/
3 http://aws.amazon.com/datapipeline/
4 http://aws.amazon.com/solutions/case-studies/big-data/
needs without having to wait for additional hardware, or being required to over-invest to
provision enough capacity. For mission-critical applications on a more traditional
infrastructure, system designers have no choice but to over-provision, because a surge
in additional data due to an increase in business need must be something the system
can handle. By contrast, on AWS you can provision more capacity and compute in a
matter of minutes, meaning that your big data applications grow and shrink as demand
dictates, and your system runs as close to optimal efficiency as possible. In addition, you
get flexible computing on a world-class infrastructure with access to the many different
geographic regions that AWS offers 1 , along with the ability to utilize other scalable
services that Amazon offers such as Amazon Simple Storage Service (S3) 2 and AWS
Data Pipeline. 3 These capabilities of the AWS platform make it an extremely good fit for
solving big data problems. You can read about many customers that have implemented
successful big data analytics workloads on AWS on the AWS case studies web page. 4
Amazon Redshift
Amazon Redshift is a fast, fully-managed, petabyte-scale data warehouse service that
makes it simple and cost-effective to efficiently analyze all your data using your existing
business intelligence tools. 5 It is optimized for datasets ranging from a few hundred
gigabytes to a petabyte or more, and is designed to cost less than a tenth of the cost of
most traditional data warehousing solutions. Amazon Redshift delivers fast query and
I/O performance for virtually any size dataset by using columnar storage technology
while parallelizing and distributing queries across multiple nodes. As a managed service,
automation is provided for most of the common administrative tasks associated with
provisioning, configuring, monitoring, backing up, and securing a data warehouse,
making it very easy and inexpensive to manage and maintain. This automation allows
you to build a petabyte-scale data warehouse in minutes, a task that has traditionally
taken weeks, or months, to complete in an on-premises implementation.
Ideal Usage Pattern
Amazon Redshift is ideal for online analytical processing (OLAP) using your existing
business intelligence tools. Organizations are using Amazon Redshift to do the following:
needs without having to wait for additional hardware, or being required to over-invest to
provision enough capacity. For mission-critical applications on a more traditional
infrastructure, system designers have no choice but to over-provision, because a surge
in additional data due to an increase in business need must be something the system
can handle. By contrast, on AWS you can provision more capacity and compute in a
matter of minutes, meaning that your big data applications grow and shrink as demand
dictates, and your system runs as close to optimal efficiency as possible. In addition, you
get flexible computing on a world-class infrastructure with access to the many different
geographic regions that AWS offers 1 , along with the ability to utilize other scalable
services that Amazon offers such as Amazon Simple Storage Service (S3) 2 and AWS
Data Pipeline. 3 These capabilities of the AWS platform make it an extremely good fit for
solving big data problems. You can read about many customers that have implemented
successful big data analytics workloads on AWS on the AWS case studies web page. 4
Amazon Redshift
Amazon Redshift is a fast, fully-managed, petabyte-scale data warehouse service that
makes it simple and cost-effective to efficiently analyze all your data using your existing
business intelligence tools. 5 It is optimized for datasets ranging from a few hundred
gigabytes to a petabyte or more, and is designed to cost less than a tenth of the cost of
most traditional data warehousing solutions. Amazon Redshift delivers fast query and
I/O performance for virtually any size dataset by using columnar storage technology
while parallelizing and distributing queries across multiple nodes. As a managed service,
automation is provided for most of the common administrative tasks associated with
provisioning, configuring, monitoring, backing up, and securing a data warehouse,
making it very easy and inexpensive to manage and maintain. This automation allows
you to build a petabyte-scale data warehouse in minutes, a task that has traditionally
taken weeks, or months, to complete in an on-premises implementation.
Ideal Usage Pattern
Amazon Redshift is ideal for online analytical processing (OLAP) using your existing
business intelligence tools. Organizations are using Amazon Redshift to do the following:

Page 4 of 29
Analyze global sales data for multiple products
Store historical stock trade data
Analyze ad impressions and clicks
Aggregate gaming data
Analyze social trends
1 http://aws.amazon.com/about-aws/globalinfrastructure/
2 http://aws.amazon.com/s3/
3 http://aws.amazon.com/datapipeline/
4 http://aws.amazon.com/solutions/case-studies/big-data/

Page 4 of 29
Analyze global sales data for multiple products
Store historical stock trade data
Analyze ad impressions and clicks
Aggregate gaming data
Analyze social trends
1 http://aws.amazon.com/about-aws/globalinfrastructure/
2 http://aws.amazon.com/s3/
3 http://aws.amazon.com/datapipeline/
4 http://aws.amazon.com/solutions/case-studies/big-data/
needs without having to wait for additional hardware, or being required to over-invest to
provision enough capacity. For mission-critical applications on a more traditional
infrastructure, system designers have no choice but to over-provision, because a surge
in additional data due to an increase in business need must be something the system
can handle. By contrast, on AWS you can provision more capacity and compute in a
matter of minutes, meaning that your big data applications grow and shrink as demand
dictates, and your system runs as close to optimal efficiency as possible. In addition, you
get flexible computing on a world-class infrastructure with access to the many different
geographic regions that AWS offers 1 , along with the ability to utilize other scalable
services that Amazon offers such as Amazon Simple Storage Service (S3) 2 and AWS
Data Pipeline. 3 These capabilities of the AWS platform make it an extremely good fit for
solving big data problems. You can read about many customers that have implemented
successful big data analytics workloads on AWS on the AWS case studies web page. 4
Amazon Redshift
Amazon Redshift is a fast, fully-managed, petabyte-scale data warehouse service that
makes it simple and cost-effective to efficiently analyze all your data using your existing
business intelligence tools. 5 It is optimized for datasets ranging from a few hundred
gigabytes to a petabyte or more, and is designed to cost less than a tenth of the cost of
most traditional data warehousing solutions. Amazon Redshift delivers fast query and
I/O performance for virtually any size dataset by using columnar storage technology
while parallelizing and distributing queries across multiple nodes. As a managed service,
automation is provided for most of the common administrative tasks associated with
provisioning, configuring, monitoring, backing up, and securing a data warehouse,
making it very easy and inexpensive to manage and maintain. This automation allows
you to build a petabyte-scale data warehouse in minutes, a task that has traditionally
taken weeks, or months, to complete in an on-premises implementation.
Ideal Usage Pattern
Amazon Redshift is ideal for online analytical processing (OLAP) using your existing
business intelligence tools. Organizations are using Amazon Redshift to do the following:
needs without having to wait for additional hardware, or being required to over-invest to
provision enough capacity. For mission-critical applications on a more traditional
infrastructure, system designers have no choice but to over-provision, because a surge
in additional data due to an increase in business need must be something the system
can handle. By contrast, on AWS you can provision more capacity and compute in a
matter of minutes, meaning that your big data applications grow and shrink as demand
dictates, and your system runs as close to optimal efficiency as possible. In addition, you
get flexible computing on a world-class infrastructure with access to the many different
geographic regions that AWS offers 1 , along with the ability to utilize other scalable
services that Amazon offers such as Amazon Simple Storage Service (S3) 2 and AWS
Data Pipeline. 3 These capabilities of the AWS platform make it an extremely good fit for
solving big data problems. You can read about many customers that have implemented
successful big data analytics workloads on AWS on the AWS case studies web page. 4
Amazon Redshift
Amazon Redshift is a fast, fully-managed, petabyte-scale data warehouse service that
makes it simple and cost-effective to efficiently analyze all your data using your existing
business intelligence tools. 5 It is optimized for datasets ranging from a few hundred
gigabytes to a petabyte or more, and is designed to cost less than a tenth of the cost of
most traditional data warehousing solutions. Amazon Redshift delivers fast query and
I/O performance for virtually any size dataset by using columnar storage technology
while parallelizing and distributing queries across multiple nodes. As a managed service,
automation is provided for most of the common administrative tasks associated with
provisioning, configuring, monitoring, backing up, and securing a data warehouse,
making it very easy and inexpensive to manage and maintain. This automation allows
you to build a petabyte-scale data warehouse in minutes, a task that has traditionally
taken weeks, or months, to complete in an on-premises implementation.
Ideal Usage Pattern
Amazon Redshift is ideal for online analytical processing (OLAP) using your existing
business intelligence tools. Organizations are using Amazon Redshift to do the following:

Page 4 of 29
Analyze global sales data for multiple products
Store historical stock trade data
Analyze ad impressions and clicks
Aggregate gaming data
Analyze social trends
1 http://aws.amazon.com/about-aws/globalinfrastructure/
2 http://aws.amazon.com/s3/
3 http://aws.amazon.com/datapipeline/
4 http://aws.amazon.com/solutions/case-studies/big-data/

Page 4 of 29
Analyze global sales data for multiple products
Store historical stock trade data
Analyze ad impressions and clicks
Aggregate gaming data
Analyze social trends
1 http://aws.amazon.com/about-aws/globalinfrastructure/
2 http://aws.amazon.com/s3/
3 http://aws.amazon.com/datapipeline/
4 http://aws.amazon.com/solutions/case-studies/big-data/

needs without having to wait for additional hardware, or being required to over-invest to
provision enough capacity. For mission-critical applications on a more traditional
infrastructure, system designers have no choice but to over-provision, because a surge
in additional data due to an increase in business need must be something the system
can handle. By contrast, on AWS you can provision more capacity and compute in a
matter of minutes, meaning that your big data applications grow and shrink as demand
dictates, and your system runs as close to optimal efficiency as possible. In addition, you
get flexible computing on a world-class infrastructure with access to the many different
geographic regions that AWS offers 1 , along with the ability to utilize other scalable
services that Amazon offers such as Amazon Simple Storage Service (S3) 2 and AWS
Data Pipeline. 3 These capabilities of the AWS platform make it an extremely good fit for
solving big data problems. You can read about many customers that have implemented
successful big data analytics workloads on AWS on the AWS case studies web page. 4
Amazon Redshift
Amazon Redshift is a fast, fully-managed, petabyte-scale data warehouse service that
makes it simple and cost-effective to efficiently analyze all your data using your existing
business intelligence tools. 5 It is optimized for datasets ranging from a few hundred
gigabytes to a petabyte or more, and is designed to cost less than a tenth of the cost of
most traditional data warehousing solutions. Amazon Redshift delivers fast query and
I/O performance for virtually any size dataset by using columnar storage technology
while parallelizing and distributing queries across multiple nodes. As a managed service,
automation is provided for most of the common administrative tasks associated with
provisioning, configuring, monitoring, backing up, and securing a data warehouse,
making it very easy and inexpensive to manage and maintain. This automation allows
you to build a petabyte-scale data warehouse in minutes, a task that has traditionally
taken weeks, or months, to complete in an on-premises implementation.
Ideal Usage Pattern
Amazon Redshift is ideal for online analytical processing (OLAP) using your existing
business intelligence tools. Organizations are using Amazon Redshift to do the following:
needs without having to wait for additional hardware, or being required to over-invest to
provision enough capacity. For mission-critical applications on a more traditional
infrastructure, system designers have no choice but to over-provision, because a surge
in additional data due to an increase in business need must be something the system
can handle. By contrast, on AWS you can provision more capacity and compute in a
matter of minutes, meaning that your big data applications grow and shrink as demand
dictates, and your system runs as close to optimal efficiency as possible. In addition, you
get flexible computing on a world-class infrastructure with access to the many different
geographic regions that AWS offers 1 , along with the ability to utilize other scalable
services that Amazon offers such as Amazon Simple Storage Service (S3) 2 and AWS
Data Pipeline. 3 These capabilities of the AWS platform make it an extremely good fit for
solving big data problems. You can read about many customers that have implemented
successful big data analytics workloads on AWS on the AWS case studies web page. 4
Amazon Redshift
Amazon Redshift is a fast, fully-managed, petabyte-scale data warehouse service that
makes it simple and cost-effective to efficiently analyze all your data using your existing
business intelligence tools. 5 It is optimized for datasets ranging from a few hundred
gigabytes to a petabyte or more, and is designed to cost less than a tenth of the cost of
most traditional data warehousing solutions. Amazon Redshift delivers fast query and
I/O performance for virtually any size dataset by using columnar storage technology
while parallelizing and distributing queries across multiple nodes. As a managed service,
automation is provided for most of the common administrative tasks associated with
provisioning, configuring, monitoring, backing up, and securing a data warehouse,
making it very easy and inexpensive to manage and maintain. This automation allows
you to build a petabyte-scale data warehouse in minutes, a task that has traditionally
taken weeks, or months, to complete in an on-premises implementation.
Ideal Usage Pattern
Amazon Redshift is ideal for online analytical processing (OLAP) using your existing
business intelligence tools. Organizations are using Amazon Redshift to do the following:

Page 4 of 29
Analyze global sales data for multiple products
Store historical stock trade data
Analyze ad impressions and clicks
Aggregate gaming data
Analyze social trends
1 http://aws.amazon.com/about-aws/globalinfrastructure/
2 http://aws.amazon.com/s3/
3 http://aws.amazon.com/datapipeline/
4 http://aws.amazon.com/solutions/case-studies/big-data/

Page 4 of 29
Analyze global sales data for multiple products
Store historical stock trade data
Analyze ad impressions and clicks
Aggregate gaming data
Analyze social trends
1 http://aws.amazon.com/about-aws/globalinfrastructure/
2 http://aws.amazon.com/s3/
3 http://aws.amazon.com/datapipeline/
4 http://aws.amazon.com/solutions/case-studies/big-data/

needs without having to wait for additional hardware, or being required to over-invest to
provision enough capacity. For mission-critical applications on a more traditional
infrastructure, system designers have no choice but to over-provision, because a surge
in additional data due to an increase in business need must be something the system
can handle. By contrast, on AWS you can provision more capacity and compute in a
matter of minutes, meaning that your big data applications grow and shrink as demand
dictates, and your system runs as close to optimal efficiency as possible. In addition, you
get flexible computing on a world-class infrastructure with access to the many different
geographic regions that AWS offers 1 , along with the ability to utilize other scalable
services that Amazon offers such as Amazon Simple Storage Service (S3) 2 and AWS
Data Pipeline. 3 These capabilities of the AWS platform make it an extremely good fit for
solving big data problems. You can read about many customers that have implemented
successful big data analytics workloads on AWS on the AWS case studies web page. 4
Amazon Redshift
Amazon Redshift is a fast, fully-managed, petabyte-scale data warehouse service that
makes it simple and cost-effective to efficiently analyze all your data using your existing
business intelligence tools. 5 It is optimized for datasets ranging from a few hundred
gigabytes to a petabyte or more, and is designed to cost less than a tenth of the cost of
most traditional data warehousing solutions. Amazon Redshift delivers fast query and
I/O performance for virtually any size dataset by using columnar storage technology
while parallelizing and distributing queries across multiple nodes. As a managed service,
automation is provided for most of the common administrative tasks associated with
provisioning, configuring, monitoring, backing up, and securing a data warehouse,
making it very easy and inexpensive to manage and maintain. This automation allows
you to build a petabyte-scale data warehouse in minutes, a task that has traditionally
taken weeks, or months, to complete in an on-premises implementation.
Ideal Usage Pattern
Amazon Redshift is ideal for online analytical processing (OLAP) using your existing
business intelligence tools. Organizations are using Amazon Redshift to do the following:
needs without having to wait for additional hardware, or being required to over-invest to
provision enough capacity. For mission-critical applications on a more traditional
infrastructure, system designers have no choice but to over-provision, because a surge
in additional data due to an increase in business need must be something the system
can handle. By contrast, on AWS you can provision more capacity and compute in a
matter of minutes, meaning that your big data applications grow and shrink as demand
dictates, and your system runs as close to optimal efficiency as possible. In addition, you
get flexible computing on a world-class infrastructure with access to the many different
geographic regions that AWS offers 1 , along with the ability to utilize other scalable
services that Amazon offers such as Amazon Simple Storage Service (S3) 2 and AWS
Data Pipeline. 3 These capabilities of the AWS platform make it an extremely good fit for
solving big data problems. You can read about many customers that have implemented
successful big data analytics workloads on AWS on the AWS case studies web page. 4
Amazon Redshift
Amazon Redshift is a fast, fully-managed, petabyte-scale data warehouse service that
makes it simple and cost-effective to efficiently analyze all your data using your existing
business intelligence tools. 5 It is optimized for datasets ranging from a few hundred
gigabytes to a petabyte or more, and is designed to cost less than a tenth of the cost of
most traditional data warehousing solutions. Amazon Redshift delivers fast query and
I/O performance for virtually any size dataset by using columnar storage technology
while parallelizing and distributing queries across multiple nodes. As a managed service,
automation is provided for most of the common administrative tasks associated with
provisioning, configuring, monitoring, backing up, and securing a data warehouse,
making it very easy and inexpensive to manage and maintain. This automation allows
you to build a petabyte-scale data warehouse in minutes, a task that has traditionally
taken weeks, or months, to complete in an on-premises implementation.
Ideal Usage Pattern
Amazon Redshift is ideal for online analytical processing (OLAP) using your existing
business intelligence tools. Organizations are using Amazon Redshift to do the following:

Page 4 of 29
Analyze global sales data for multiple products
Store historical stock trade data
Analyze ad impressions and clicks
Aggregate gaming data
Analyze social trends
1 http://aws.amazon.com/about-aws/globalinfrastructure/
2 http://aws.amazon.com/s3/
3 http://aws.amazon.com/datapipeline/
4 http://aws.amazon.com/solutions/case-studies/big-data/

Page 4 of 29
Analyze global sales data for multiple products
Store historical stock trade data
Analyze ad impressions and clicks
Aggregate gaming data
Analyze social trends
1 http://aws.amazon.com/about-aws/globalinfrastructure/
2 http://aws.amazon.com/s3/
3 http://aws.amazon.com/datapipeline/
4 http://aws.amazon.com/solutions/case-studies/big-data/

needs without having to wait for additional hardware, or being required to over-invest to
provision enough capacity. For mission-critical applications on a more traditional
infrastructure, system designers have no choice but to over-provision, because a surge
in additional data due to an increase in business need must be something the system
can handle. By contrast, on AWS you can provision more capacity and compute in a
matter of minutes, meaning that your big data applications grow and shrink as demand
dictates, and your system runs as close to optimal efficiency as possible. In addition, you
get flexible computing on a world-class infrastructure with access to the many different
geographic regions that AWS offers 1 , along with the ability to utilize other scalable
services that Amazon offers such as Amazon Simple Storage Service (S3) 2 and AWS
Data Pipeline. 3 These capabilities of the AWS platform make it an extremely good fit for
solving big data problems. You can read about many customers that have implemented
successful big data analytics workloads on AWS on the AWS case studies web page. 4
Amazon Redshift
Amazon Redshift is a fast, fully-managed, petabyte-scale data warehouse service that
makes it simple and cost-effective to efficiently analyze all your data using your existing
business intelligence tools. 5 It is optimized for datasets ranging from a few hundred
gigabytes to a petabyte or more, and is designed to cost less than a tenth of the cost of
most traditional data warehousing solutions. Amazon Redshift delivers fast query and
I/O performance for virtually any size dataset by using columnar storage technology
while parallelizing and distributing queries across multiple nodes. As a managed service,
automation is provided for most of the common administrative tasks associated with
provisioning, configuring, monitoring, backing up, and securing a data warehouse,
making it very easy and inexpensive to manage and maintain. This automation allows
you to build a petabyte-scale data warehouse in minutes, a task that has traditionally
taken weeks, or months, to complete in an on-premises implementation.
Ideal Usage Pattern
Amazon Redshift is ideal for online analytical processing (OLAP) using your existing
business intelligence tools. Organizations are using Amazon Redshift to do the following:
needs without having to wait for additional hardware, or being required to over-invest to
provision enough capacity. For mission-critical applications on a more traditional
infrastructure, system designers have no choice but to over-provision, because a surge
in additional data due to an increase in business need must be something the system
can handle. By contrast, on AWS you can provision more capacity and compute in a
matter of minutes, meaning that your big data applications grow and shrink as demand
dictates, and your system runs as close to optimal efficiency as possible. In addition, you
get flexible computing on a world-class infrastructure with access to the many different
geographic regions that AWS offers 1 , along with the ability to utilize other scalable
services that Amazon offers such as Amazon Simple Storage Service (S3) 2 and AWS
Data Pipeline. 3 These capabilities of the AWS platform make it an extremely good fit for
solving big data problems. You can read about many customers that have implemented
successful big data analytics workloads on AWS on the AWS case studies web page. 4
Amazon Redshift
Amazon Redshift is a fast, fully-managed, petabyte-scale data warehouse service that
makes it simple and cost-effective to efficiently analyze all your data using your existing
business intelligence tools. 5 It is optimized for datasets ranging from a few hundred
gigabytes to a petabyte or more, and is designed to cost less than a tenth of the cost of
most traditional data warehousing solutions. Amazon Redshift delivers fast query and
I/O performance for virtually any size dataset by using columnar storage technology
while parallelizing and distributing queries across multiple nodes. As a managed service,
automation is provided for most of the common administrative tasks associated with
provisioning, configuring, monitoring, backing up, and securing a data warehouse,
making it very easy and inexpensive to manage and maintain. This automation allows
you to build a petabyte-scale data warehouse in minutes, a task that has traditionally
taken weeks, or months, to complete in an on-premises implementation.
Ideal Usage Pattern
Amazon Redshift is ideal for online analytical processing (OLAP) using your existing
business intelligence tools. Organizations are using Amazon Redshift to do the following:

Page 4 of 29
Analyze global sales data for multiple products
Store historical stock trade data
Analyze ad impressions and clicks
Aggregate gaming data
Analyze social trends
1 http://aws.amazon.com/about-aws/globalinfrastructure/
2 http://aws.amazon.com/s3/
3 http://aws.amazon.com/datapipeline/
4 http://aws.amazon.com/solutions/case-studies/big-data/

Page 4 of 29
Analyze global sales data for multiple products
Store historical stock trade data
Analyze ad impressions and clicks
Aggregate gaming data
Analyze social trends
1 http://aws.amazon.com/about-aws/globalinfrastructure/
2 http://aws.amazon.com/s3/
3 http://aws.amazon.com/datapipeline/
4 http://aws.amazon.com/solutions/case-studies/big-data/

needs without having to wait for additional hardware, or being required to over-invest to
provision enough capacity. For mission-critical applications on a more traditional
infrastructure, system designers have no choice but to over-provision, because a surge
in additional data due to an increase in business need must be something the system
can handle. By contrast, on AWS you can provision more capacity and compute in a
matter of minutes, meaning that your big data applications grow and shrink as demand
dictates, and your system runs as close to optimal efficiency as possible. In addition, you
get flexible computing on a world-class infrastructure with access to the many different
geographic regions that AWS offers 1 , along with the ability to utilize other scalable
services that Amazon offers such as Amazon Simple Storage Service (S3) 2 and AWS
Data Pipeline. 3 These capabilities of the AWS platform make it an extremely good fit for
solving big data problems. You can read about many customers that have implemented
successful big data analytics workloads on AWS on the AWS case studies web page. 4
Amazon Redshift
Amazon Redshift is a fast, fully-managed, petabyte-scale data warehouse service that
makes it simple and cost-effective to efficiently analyze all your data using your existing
business intelligence tools. 5 It is optimized for datasets ranging from a few hundred
gigabytes to a petabyte or more, and is designed to cost less than a tenth of the cost of
most traditional data warehousing solutions. Amazon Redshift delivers fast query and
I/O performance for virtually any size dataset by using columnar storage technology
while parallelizing and distributing queries across multiple nodes. As a managed service,
automation is provided for most of the common administrative tasks associated with
provisioning, configuring, monitoring, backing up, and securing a data warehouse,
making it very easy and inexpensive to manage and maintain. This automation allows
you to build a petabyte-scale data warehouse in minutes, a task that has traditionally
taken weeks, or months, to complete in an on-premises implementation.
Ideal Usage Pattern
Amazon Redshift is ideal for online analytical processing (OLAP) using your existing
business intelligence tools. Organizations are using Amazon Redshift to do the following:
needs without having to wait for additional hardware, or being required to over-invest to
provision enough capacity. For mission-critical applications on a more traditional
infrastructure, system designers have no choice but to over-provision, because a surge
in additional data due to an increase in business need must be something the system
can handle. By contrast, on AWS you can provision more capacity and compute in a
matter of minutes, meaning that your big data applications grow and shrink as demand
dictates, and your system runs as close to optimal efficiency as possible. In addition, you
get flexible computing on a world-class infrastructure with access to the many different
geographic regions that AWS offers 1 , along with the ability to utilize other scalable
services that Amazon offers such as Amazon Simple Storage Service (S3) 2 and AWS
Data Pipeline. 3 These capabilities of the AWS platform make it an extremely good fit for
solving big data problems. You can read about many customers that have implemented
successful big data analytics workloads on AWS on the AWS case studies web page. 4
Amazon Redshift
Amazon Redshift is a fast, fully-managed, petabyte-scale data warehouse service that
makes it simple and cost-effective to efficiently analyze all your data using your existing
business intelligence tools. 5 It is optimized for datasets ranging from a few hundred
gigabytes to a petabyte or more, and is designed to cost less than a tenth of the cost of
most traditional data warehousing solutions. Amazon Redshift delivers fast query and
I/O performance for virtually any size dataset by using columnar storage technology
while parallelizing and distributing queries across multiple nodes. As a managed service,
automation is provided for most of the common administrative tasks associated with
provisioning, configuring, monitoring, backing up, and securing a data warehouse,
making it very easy and inexpensive to manage and maintain. This automation allows
you to build a petabyte-scale data warehouse in minutes, a task that has traditionally
taken weeks, or months, to complete in an on-premises implementation.
Ideal Usage Pattern
Amazon Redshift is ideal for online analytical processing (OLAP) using your existing
business intelligence tools. Organizations are using Amazon Redshift to do the following:

Page 4 of 29
Analyze global sales data for multiple products
Store historical stock trade data
Analyze ad impressions and clicks
Aggregate gaming data
Analyze social trends
1 http://aws.amazon.com/about-aws/globalinfrastructure/
2 http://aws.amazon.com/s3/
3 http://aws.amazon.com/datapipeline/
4 http://aws.amazon.com/solutions/case-studies/big-data/

Page 4 of 29
Analyze global sales data for multiple products
Store historical stock trade data
Analyze ad impressions and clicks
Aggregate gaming data
Analyze social trends
1 http://aws.amazon.com/about-aws/globalinfrastructure/
2 http://aws.amazon.com/s3/
3 http://aws.amazon.com/datapipeline/
4 http://aws.amazon.com/solutions/case-studies/big-data/

needs without having to wait for additional hardware, or being required to over-invest to
provision enough capacity. For mission-critical applications on a more traditional
infrastructure, system designers have no choice but to over-provision, because a surge
in additional data due to an increase in business need must be something the system
can handle. By contrast, on AWS you can provision more capacity and compute in a
matter of minutes, meaning that your big data applications grow and shrink as demand
dictates, and your system runs as close to optimal efficiency as possible. In addition, you
get flexible computing on a world-class infrastructure with access to the many different
geographic regions that AWS offers 1 , along with the ability to utilize other scalable
services that Amazon offers such as Amazon Simple Storage Service (S3) 2 and AWS
Data Pipeline. 3 These capabilities of the AWS platform make it an extremely good fit for
solving big data problems. You can read about many customers that have implemented
successful big data analytics workloads on AWS on the AWS case studies web page. 4
Amazon Redshift
Amazon Redshift is a fast, fully-managed, petabyte-scale data warehouse service that
makes it simple and cost-effective to efficiently analyze all your data using your existing
business intelligence tools. 5 It is optimized for datasets ranging from a few hundred
gigabytes to a petabyte or more, and is designed to cost less than a tenth of the cost of
most traditional data warehousing solutions. Amazon Redshift delivers fast query and
I/O performance for virtually any size dataset by using columnar storage technology
while parallelizing and distributing queries across multiple nodes. As a managed service,
automation is provided for most of the common administrative tasks associated with
provisioning, configuring, monitoring, backing up, and securing a data warehouse,
making it very easy and inexpensive to manage and maintain. This automation allows
you to build a petabyte-scale data warehouse in minutes, a task that has traditionally
taken weeks, or months, to complete in an on-premises implementation.
Ideal Usage Pattern
Amazon Redshift is ideal for online analytical processing (OLAP) using your existing
business intelligence tools. Organizations are using Amazon Redshift to do the following:
needs without having to wait for additional hardware, or being required to over-invest to
provision enough capacity. For mission-critical applications on a more traditional
infrastructure, system designers have no choice but to over-provision, because a surge
in additional data due to an increase in business need must be something the system
can handle. By contrast, on AWS you can provision more capacity and compute in a
matter of minutes, meaning that your big data applications grow and shrink as demand
dictates, and your system runs as close to optimal efficiency as possible. In addition, you
get flexible computing on a world-class infrastructure with access to the many different
geographic regions that AWS offers 1 , along with the ability to utilize other scalable
services that Amazon offers such as Amazon Simple Storage Service (S3) 2 and AWS
Data Pipeline. 3 These capabilities of the AWS platform make it an extremely good fit for
solving big data problems. You can read about many customers that have implemented
successful big data analytics workloads on AWS on the AWS case studies web page. 4
Amazon Redshift
Amazon Redshift is a fast, fully-managed, petabyte-scale data warehouse service that
makes it simple and cost-effective to efficiently analyze all your data using your existing
business intelligence tools. 5 It is optimized for datasets ranging from a few hundred
gigabytes to a petabyte or more, and is designed to cost less than a tenth of the cost of
most traditional data warehousing solutions. Amazon Redshift delivers fast query and
I/O performance for virtually any size dataset by using columnar storage technology
while parallelizing and distributing queries across multiple nodes. As a managed service,
automation is provided for most of the common administrative tasks associated with
provisioning, configuring, monitoring, backing up, and securing a data warehouse,
making it very easy and inexpensive to manage and maintain. This automation allows
you to build a petabyte-scale data warehouse in minutes, a task that has traditionally
taken weeks, or months, to complete in an on-premises implementation.
Ideal Usage Pattern
Amazon Redshift is ideal for online analytical processing (OLAP) using your existing
business intelligence tools. Organizations are using Amazon Redshift to do the following:

Page 4 of 29
Analyze global sales data for multiple products
Store historical stock trade data
Analyze ad impressions and clicks
Aggregate gaming data
Analyze social trends
1 http://aws.amazon.com/about-aws/globalinfrastructure/
2 http://aws.amazon.com/s3/
3 http://aws.amazon.com/datapipeline/
4 http://aws.amazon.com/solutions/case-studies/big-data/

Page 4 of 29
Analyze global sales data for multiple products
Store historical stock trade data
Analyze ad impressions and clicks
Aggregate gaming data
Analyze social trends
1 http://aws.amazon.com/about-aws/globalinfrastructure/
2 http://aws.amazon.com/s3/
3 http://aws.amazon.com/datapipeline/
4 http://aws.amazon.com/solutions/case-studies/big-data/

needs without having to wait for additional hardware, or being required to over-invest to
provision enough capacity. For mission-critical applications on a more traditional
infrastructure, system designers have no choice but to over-provision, because a surge
in additional data due to an increase in business need must be something the system
can handle. By contrast, on AWS you can provision more capacity and compute in a
matter of minutes, meaning that your big data applications grow and shrink as demand
dictates, and your system runs as close to optimal efficiency as possible. In addition, you
get flexible computing on a world-class infrastructure with access to the many different
geographic regions that AWS offers 1 , along with the ability to utilize other scalable
services that Amazon offers such as Amazon Simple Storage Service (S3) 2 and AWS
Data Pipeline. 3 These capabilities of the AWS platform make it an extremely good fit for
solving big data problems. You can read about many customers that have implemented
successful big data analytics workloads on AWS on the AWS case studies web page. 4
Amazon Redshift
Amazon Redshift is a fast, fully-managed, petabyte-scale data warehouse service that
makes it simple and cost-effective to efficiently analyze all your data using your existing
business intelligence tools. 5 It is optimized for datasets ranging from a few hundred
gigabytes to a petabyte or more, and is designed to cost less than a tenth of the cost of
most traditional data warehousing solutions. Amazon Redshift delivers fast query and
I/O performance for virtually any size dataset by using columnar storage technology
while parallelizing and distributing queries across multiple nodes. As a managed service,
automation is provided for most of the common administrative tasks associated with
provisioning, configuring, monitoring, backing up, and securing a data warehouse,
making it very easy and inexpensive to manage and maintain. This automation allows
you to build a petabyte-scale data warehouse in minutes, a task that has traditionally
taken weeks, or months, to complete in an on-premises implementation.
Ideal Usage Pattern
Amazon Redshift is ideal for online analytical processing (OLAP) using your existing
business intelligence tools. Organizations are using Amazon Redshift to do the following:
needs without having to wait for additional hardware, or being required to over-invest to
provision enough capacity. For mission-critical applications on a more traditional
infrastructure, system designers have no choice but to over-provision, because a surge
in additional data due to an increase in business need must be something the system
can handle. By contrast, on AWS you can provision more capacity and compute in a
matter of minutes, meaning that your big data applications grow and shrink as demand
dictates, and your system runs as close to optimal efficiency as possible. In addition, you
get flexible computing on a world-class infrastructure with access to the many different
geographic regions that AWS offers 1 , along with the ability to utilize other scalable
services that Amazon offers such as Amazon Simple Storage Service (S3) 2 and AWS
Data Pipeline. 3 These capabilities of the AWS platform make it an extremely good fit for
solving big data problems. You can read about many customers that have implemented
successful big data analytics workloads on AWS on the AWS case studies web page. 4
Amazon Redshift
Amazon Redshift is a fast, fully-managed, petabyte-scale data warehouse service that
makes it simple and cost-effective to efficiently analyze all your data using your existing
business intelligence tools. 5 It is optimized for datasets ranging from a few hundred
gigabytes to a petabyte or more, and is designed to cost less than a tenth of the cost of
most traditional data warehousing solutions. Amazon Redshift delivers fast query and
I/O performance for virtually any size dataset by using columnar storage technology
while parallelizing and distributing queries across multiple nodes. As a managed service,
automation is provided for most of the common administrative tasks associated with
provisioning, configuring, monitoring, backing up, and securing a data warehouse,
making it very easy and inexpensive to manage and maintain. This automation allows
you to build a petabyte-scale data warehouse in minutes, a task that has traditionally
taken weeks, or months, to complete in an on-premises implementation.
Ideal Usage Pattern
Amazon Redshift is ideal for online analytical processing (OLAP) using your existing
business intelligence tools. Organizations are using Amazon Redshift to do the following:

Page 4 of 29
Analyze global sales data for multiple products
Store historical stock trade data
Analyze ad impressions and clicks
Aggregate gaming data
Analyze social trends
1 http://aws.amazon.com/about-aws/globalinfrastructure/
2 http://aws.amazon.com/s3/
3 http://aws.amazon.com/datapipeline/
4 http://aws.amazon.com/solutions/case-studies/big-data/

Page 4 of 29
Analyze global sales data for multiple products
Store historical stock trade data
Analyze ad impressions and clicks
Aggregate gaming data
Analyze social trends
1 http://aws.amazon.com/about-aws/globalinfrastructure/
2 http://aws.amazon.com/s3/
3 http://aws.amazon.com/datapipeline/
4 http://aws.amazon.com/solutions/case-studies/big-data/

needs without having to wait for additional hardware, or being required to over-invest to
provision enough capacity. For mission-critical applications on a more traditional
infrastructure, system designers have no choice but to over-provision, because a surge
in additional data due to an increase in business need must be something the system
can handle. By contrast, on AWS you can provision more capacity and compute in a
matter of minutes, meaning that your big data applications grow and shrink as demand
dictates, and your system runs as close to optimal efficiency as possible. In addition, you
get flexible computing on a world-class infrastructure with access to the many different
geographic regions that AWS offers 1 , along with the ability to utilize other scalable
services that Amazon offers such as Amazon Simple Storage Service (S3) 2 and AWS
Data Pipeline. 3 These capabilities of the AWS platform make it an extremely good fit for
solving big data problems. You can read about many customers that have implemented
successful big data analytics workloads on AWS on the AWS case studies web page. 4
Amazon Redshift
Amazon Redshift is a fast, fully-managed, petabyte-scale data warehouse service that
makes it simple and cost-effective to efficiently analyze all your data using your existing
business intelligence tools. 5 It is optimized for datasets ranging from a few hundred
gigabytes to a petabyte or more, and is designed to cost less than a tenth of the cost of
most traditional data warehousing solutions. Amazon Redshift delivers fast query and
I/O performance for virtually any size dataset by using columnar storage technology
while parallelizing and distributing queries across multiple nodes. As a managed service,
automation is provided for most of the common administrative tasks associated with
provisioning, configuring, monitoring, backing up, and securing a data warehouse,
making it very easy and inexpensive to manage and maintain. This automation allows
you to build a petabyte-scale data warehouse in minutes, a task that has traditionally
taken weeks, or months, to complete in an on-premises implementation.
Ideal Usage Pattern
Amazon Redshift is ideal for online analytical processing (OLAP) using your existing
business intelligence tools. Organizations are using Amazon Redshift to do the following:
needs without having to wait for additional hardware, or being required to over-invest to
provision enough capacity. For mission-critical applications on a more traditional
infrastructure, system designers have no choice but to over-provision, because a surge
in additional data due to an increase in business need must be something the system
can handle. By contrast, on AWS you can provision more capacity and compute in a
matter of minutes, meaning that your big data applications grow and shrink as demand
dictates, and your system runs as close to optimal efficiency as possible. In addition, you
get flexible computing on a world-class infrastructure with access to the many different
geographic regions that AWS offers 1 , along with the ability to utilize other scalable
services that Amazon offers such as Amazon Simple Storage Service (S3) 2 and AWS
Data Pipeline. 3 These capabilities of the AWS platform make it an extremely good fit for
solving big data problems. You can read about many customers that have implemented
successful big data analytics workloads on AWS on the AWS case studies web page. 4
Amazon Redshift
Amazon Redshift is a fast, fully-managed, petabyte-scale data warehouse service that
makes it simple and cost-effective to efficiently analyze all your data using your existing
business intelligence tools. 5 It is optimized for datasets ranging from a few hundred
gigabytes to a petabyte or more, and is designed to cost less than a tenth of the cost of
most traditional data warehousing solutions. Amazon Redshift delivers fast query and
I/O performance for virtually any size dataset by using columnar storage technology
while parallelizing and distributing queries across multiple nodes. As a managed service,
automation is provided for most of the common administrative tasks associated with
provisioning, configuring, monitoring, backing up, and securing a data warehouse,
making it very easy and inexpensive to manage and maintain. This automation allows
you to build a petabyte-scale data warehouse in minutes, a task that has traditionally
taken weeks, or months, to complete in an on-premises implementation.
Ideal Usage Pattern
Amazon Redshift is ideal for online analytical processing (OLAP) using your existing
business intelligence tools. Organizations are using Amazon Redshift to do the following:

Page 4 of 29
Analyze global sales data for multiple products
Store historical stock trade data
Analyze ad impressions and clicks
Aggregate gaming data
Analyze social trends
1 http://aws.amazon.com/about-aws/globalinfrastructure/
2 http://aws.amazon.com/s3/
3 http://aws.amazon.com/datapipeline/
4 http://aws.amazon.com/solutions/case-studies/big-data/

Page 4 of 29
Analyze global sales data for multiple products
Store historical stock trade data
Analyze ad impressions and clicks
Aggregate gaming data
Analyze social trends
1 http://aws.amazon.com/about-aws/globalinfrastructure/
2 http://aws.amazon.com/s3/
3 http://aws.amazon.com/datapipeline/
4 http://aws.amazon.com/solutions/case-studies/big-data/
needs without having to wait for additional hardware, or being required to over-invest to
provision enough capacity. For mission-critical applications on a more traditional
infrastructure, system designers have no choice but to over-provision, because a surge
in additional data due to an increase in business need must be something the system
can handle. By contrast, on AWS you can provision more capacity and compute in a
matter of minutes, meaning that your big data applications grow and shrink as demand
dictates, and your system runs as close to optimal efficiency as possible. In addition, you
get flexible computing on a world-class infrastructure with access to the many different
geographic regions that AWS offers 1 , along with the ability to utilize other scalable
services that Amazon offers such as Amazon Simple Storage Service (S3) 2 and AWS
Data Pipeline. 3 These capabilities of the AWS platform make it an extremely good fit for
solving big data problems. You can read about many customers that have implemented
successful big data analytics workloads on AWS on the AWS case studies web page. 4
Amazon Redshift
Amazon Redshift is a fast, fully-managed, petabyte-scale data warehouse service that
makes it simple and cost-effective to efficiently analyze all your data using your existing
business intelligence tools. 5 It is optimized for datasets ranging from a few hundred
gigabytes to a petabyte or more, and is designed to cost less than a tenth of the cost of
most traditional data warehousing solutions. Amazon Redshift delivers fast query and
I/O performance for virtually any size dataset by using columnar storage technology
while parallelizing and distributing queries across multiple nodes. As a managed service,
automation is provided for most of the common administrative tasks associated with
provisioning, configuring, monitoring, backing up, and securing a data warehouse,
making it very easy and inexpensive to manage and maintain. This automation allows
you to build a petabyte-scale data warehouse in minutes, a task that has traditionally
taken weeks, or months, to complete in an on-premises implementation.
Ideal Usage Pattern
Amazon Redshift is ideal for online analytical processing (OLAP) using your existing
business intelligence tools. Organizations are using Amazon Redshift to do the following:
needs without having to wait for additional hardware, or being required to over-invest to
provision enough capacity. For mission-critical applications on a more traditional
infrastructure, system designers have no choice but to over-provision, because a surge
in additional data due to an increase in business need must be something the system
can handle. By contrast, on AWS you can provision more capacity and compute in a
matter of minutes, meaning that your big data applications grow and shrink as demand
dictates, and your system runs as close to optimal efficiency as possible. In addition, you
get flexible computing on a world-class infrastructure with access to the many different
geographic regions that AWS offers 1 , along with the ability to utilize other scalable
services that Amazon offers such as Amazon Simple Storage Service (S3) 2 and AWS
Data Pipeline. 3 These capabilities of the AWS platform make it an extremely good fit for
solving big data problems. You can read about many customers that have implemented
successful big data analytics workloads on AWS on the AWS case studies web page. 4
Amazon Redshift
Amazon Redshift is a fast, fully-managed, petabyte-scale data warehouse service that
makes it simple and cost-effective to efficiently analyze all your data using your existing
business intelligence tools. 5 It is optimized for datasets ranging from a few hundred
gigabytes to a petabyte or more, and is designed to cost less than a tenth of the cost of
most traditional data warehousing solutions. Amazon Redshift delivers fast query and
I/O performance for virtually any size dataset by using columnar storage technology
while parallelizing and distributing queries across multiple nodes. As a managed service,
automation is provided for most of the common administrative tasks associated with
provisioning, configuring, monitoring, backing up, and securing a data warehouse,
making it very easy and inexpensive to manage and maintain. This automation allows
you to build a petabyte-scale data warehouse in minutes, a task that has traditionally
taken weeks, or months, to complete in an on-premises implementation.
Ideal Usage Pattern
Amazon Redshift is ideal for online analytical processing (OLAP) using your existing
business intelligence tools. Organizations are using Amazon Redshift to do the following:

Page 4 of 29
Analyze global sales data for multiple products
Store historical stock trade data
Analyze ad impressions and clicks
Aggregate gaming data
Analyze social trends
1 http://aws.amazon.com/about-aws/globalinfrastructure/
2 http://aws.amazon.com/s3/
3 http://aws.amazon.com/datapipeline/
4 http://aws.amazon.com/solutions/case-studies/big-data/

Page 4 of 29
Analyze global sales data for multiple products
Store historical stock trade data
Analyze ad impressions and clicks
Aggregate gaming data
Analyze social trends
1 http://aws.amazon.com/about-aws/globalinfrastructure/
2 http://aws.amazon.com/s3/
3 http://aws.amazon.com/datapipeline/
4 http://aws.amazon.com/solutions/case-studies/big-data/
needs without having to wait for additional hardware, or being required to over-invest to
provision enough capacity. For mission-critical applications on a more traditional
infrastructure, system designers have no choice but to over-provision, because a surge
in additional data due to an increase in business need must be something the system
can handle. By contrast, on AWS you can provision more capacity and compute in a
matter of minutes, meaning that your big data applications grow and shrink as demand
dictates, and your system runs as close to optimal efficiency as possible. In addition, you
get flexible computing on a world-class infrastructure with access to the many different
geographic regions that AWS offers 1 , along with the ability to utilize other scalable
services that Amazon offers such as Amazon Simple Storage Service (S3) 2 and AWS
Data Pipeline. 3 These capabilities of the AWS platform make it an extremely good fit for
solving big data problems. You can read about many customers that have implemented
successful big data analytics workloads on AWS on the AWS case studies web page. 4
Amazon Redshift
Amazon Redshift is a fast, fully-managed, petabyte-scale data warehouse service that
makes it simple and cost-effective to efficiently analyze all your data using your existing
business intelligence tools. 5 It is optimized for datasets ranging from a few hundred
gigabytes to a petabyte or more, and is designed to cost less than a tenth of the cost of
most traditional data warehousing solutions. Amazon Redshift delivers fast query and
I/O performance for virtually any size dataset by using columnar storage technology
while parallelizing and distributing queries across multiple nodes. As a managed service,
automation is provided for most of the common administrative tasks associated with
provisioning, configuring, monitoring, backing up, and securing a data warehouse,
making it very easy and inexpensive to manage and maintain. This automation allows
you to build a petabyte-scale data warehouse in minutes, a task that has traditionally
taken weeks, or months, to complete in an on-premises implementation.
Ideal Usage Pattern
Amazon Redshift is ideal for online analytical processing (OLAP) using your existing
business intelligence tools. Organizations are using Amazon Redshift to do the following:
needs without having to wait for additional hardware, or being required to over-invest to
provision enough capacity. For mission-critical applications on a more traditional
infrastructure, system designers have no choice but to over-provision, because a surge
in additional data due to an increase in business need must be something the system
can handle. By contrast, on AWS you can provision more capacity and compute in a
matter of minutes, meaning that your big data applications grow and shrink as demand
dictates, and your system runs as close to optimal efficiency as possible. In addition, you
get flexible computing on a world-class infrastructure with access to the many different
geographic regions that AWS offers 1 , along with the ability to utilize other scalable
services that Amazon offers such as Amazon Simple Storage Service (S3) 2 and AWS
Data Pipeline. 3 These capabilities of the AWS platform make it an extremely good fit for
solving big data problems. You can read about many customers that have implemented
successful big data analytics workloads on AWS on the AWS case studies web page. 4
Amazon Redshift
Amazon Redshift is a fast, fully-managed, petabyte-scale data warehouse service that
makes it simple and cost-effective to efficiently analyze all your data using your existing
business intelligence tools. 5 It is optimized for datasets ranging from a few hundred
gigabytes to a petabyte or more, and is designed to cost less than a tenth of the cost of
most traditional data warehousing solutions. Amazon Redshift delivers fast query and
I/O performance for virtually any size dataset by using columnar storage technology
while parallelizing and distributing queries across multiple nodes. As a managed service,
automation is provided for most of the common administrative tasks associated with
provisioning, configuring, monitoring, backing up, and securing a data warehouse,
making it very easy and inexpensive to manage and maintain. This automation allows
you to build a petabyte-scale data warehouse in minutes, a task that has traditionally
taken weeks, or months, to complete in an on-premises implementation.
Ideal Usage Pattern
Amazon Redshift is ideal for online analytical processing (OLAP) using your existing
business intelligence tools. Organizations are using Amazon Redshift to do the following:

Page 4 of 29
Analyze global sales data for multiple products
Store historical stock trade data
Analyze ad impressions and clicks
Aggregate gaming data
Analyze social trends
1 http://aws.amazon.com/about-aws/globalinfrastructure/
2 http://aws.amazon.com/s3/
3 http://aws.amazon.com/datapipeline/
4 http://aws.amazon.com/solutions/case-studies/big-data/

Page 4 of 29
Analyze global sales data for multiple products
Store historical stock trade data
Analyze ad impressions and clicks
Aggregate gaming data
Analyze social trends
1 http://aws.amazon.com/about-aws/globalinfrastructure/
2 http://aws.amazon.com/s3/
3 http://aws.amazon.com/datapipeline/
4 http://aws.amazon.com/solutions/case-studies/big-data/

needs without having to wait for additional hardware, or being required to over-invest to
provision enough capacity. For mission-critical applications on a more traditional
infrastructure, system designers have no choice but to over-provision, because a surge
in additional data due to an increase in business need must be something the system
can handle. By contrast, on AWS you can provision more capacity and compute in a
matter of minutes, meaning that your big data applications grow and shrink as demand
dictates, and your system runs as close to optimal efficiency as possible. In addition, you
get flexible computing on a world-class infrastructure with access to the many different
geographic regions that AWS offers 1 , along with the ability to utilize other scalable
services that Amazon offers such as Amazon Simple Storage Service (S3) 2 and AWS
Data Pipeline. 3 These capabilities of the AWS platform make it an extremely good fit for
solving big data problems. You can read about many customers that have implemented
successful big data analytics workloads on AWS on the AWS case studies web page. 4
Amazon Redshift
Amazon Redshift is a fast, fully-managed, petabyte-scale data warehouse service that
makes it simple and cost-effective to efficiently analyze all your data using your existing
business intelligence tools. 5 It is optimized for datasets ranging from a few hundred
gigabytes to a petabyte or more, and is designed to cost less than a tenth of the cost of
most traditional data warehousing solutions. Amazon Redshift delivers fast query and
I/O performance for virtually any size dataset by using columnar storage technology
while parallelizing and distributing queries across multiple nodes. As a managed service,
automation is provided for most of the common administrative tasks associated with
provisioning, configuring, monitoring, backing up, and securing a data warehouse,
making it very easy and inexpensive to manage and maintain. This automation allows
you to build a petabyte-scale data warehouse in minutes, a task that has traditionally
taken weeks, or months, to complete in an on-premises implementation.
Ideal Usage Pattern
Amazon Redshift is ideal for online analytical processing (OLAP) using your existing
business intelligence tools. Organizations are using Amazon Redshift to do the following:
needs without having to wait for additional hardware, or being required to over-invest to
provision enough capacity. For mission-critical applications on a more traditional
infrastructure, system designers have no choice but to over-provision, because a surge
in additional data due to an increase in business need must be something the system
can handle. By contrast, on AWS you can provision more capacity and compute in a
matter of minutes, meaning that your big data applications grow and shrink as demand
dictates, and your system runs as close to optimal efficiency as possible. In addition, you
get flexible computing on a world-class infrastructure with access to the many different
geographic regions that AWS offers 1 , along with the ability to utilize other scalable
services that Amazon offers such as Amazon Simple Storage Service (S3) 2 and AWS
Data Pipeline. 3 These capabilities of the AWS platform make it an extremely good fit for
solving big data problems. You can read about many customers that have implemented
successful big data analytics workloads on AWS on the AWS case studies web page. 4
Amazon Redshift
Amazon Redshift is a fast, fully-managed, petabyte-scale data warehouse service that
makes it simple and cost-effective to efficiently analyze all your data using your existing
business intelligence tools. 5 It is optimized for datasets ranging from a few hundred
gigabytes to a petabyte or more, and is designed to cost less than a tenth of the cost of
most traditional data warehousing solutions. Amazon Redshift delivers fast query and
I/O performance for virtually any size dataset by using columnar storage technology
while parallelizing and distributing queries across multiple nodes. As a managed service,
automation is provided for most of the common administrative tasks associated with
provisioning, configuring, monitoring, backing up, and securing a data warehouse,
making it very easy and inexpensive to manage and maintain. This automation allows
you to build a petabyte-scale data warehouse in minutes, a task that has traditionally
taken weeks, or months, to complete in an on-premises implementation.
Ideal Usage Pattern
Amazon Redshift is ideal for online analytical processing (OLAP) using your existing
business intelligence tools. Organizations are using Amazon Redshift to do the following:

Page 4 of 29
Analyze global sales data for multiple products
Store historical stock trade data
Analyze ad impressions and clicks
Aggregate gaming data
Analyze social trends
1 http://aws.amazon.com/about-aws/globalinfrastructure/
2 http://aws.amazon.com/s3/
3 http://aws.amazon.com/datapipeline/
4 http://aws.amazon.com/solutions/case-studies/big-data/

Page 4 of 29
Analyze global sales data for multiple products
Store historical stock trade data
Analyze ad impressions and clicks
Aggregate gaming data
Analyze social trends
1 http://aws.amazon.com/about-aws/globalinfrastructure/
2 http://aws.amazon.com/s3/
3 http://aws.amazon.com/datapipeline/
4 http://aws.amazon.com/solutions/case-studies/big-data/

needs without having to wait for additional hardware, or being required to over-invest to
provision enough capacity. For mission-critical applications on a more traditional
infrastructure, system designers have no choice but to over-provision, because a surge
in additional data due to an increase in business need must be something the system
can handle. By contrast, on AWS you can provision more capacity and compute in a
matter of minutes, meaning that your big data applications grow and shrink as demand
dictates, and your system runs as close to optimal efficiency as possible. In addition, you
get flexible computing on a world-class infrastructure with access to the many different
geographic regions that AWS offers 1 , along with the ability to utilize other scalable
services that Amazon offers such as Amazon Simple Storage Service (S3) 2 and AWS
Data Pipeline. 3 These capabilities of the AWS platform make it an extremely good fit for
solving big data problems. You can read about many customers that have implemented
successful big data analytics workloads on AWS on the AWS case studies web page. 4
Amazon Redshift
Amazon Redshift is a fast, fully-managed, petabyte-scale data warehouse service that
makes it simple and cost-effective to efficiently analyze all your data using your existing
business intelligence tools. 5 It is optimized for datasets ranging from a few hundred
gigabytes to a petabyte or more, and is designed to cost less than a tenth of the cost of
most traditional data warehousing solutions. Amazon Redshift delivers fast query and
I/O performance for virtually any size dataset by using columnar storage technology
while parallelizing and distributing queries across multiple nodes. As a managed service,
automation is provided for most of the common administrative tasks associated with
provisioning, configuring, monitoring, backing up, and securing a data warehouse,
making it very easy and inexpensive to manage and maintain. This automation allows
you to build a petabyte-scale data warehouse in minutes, a task that has traditionally
taken weeks, or months, to complete in an on-premises implementation.
Ideal Usage Pattern
Amazon Redshift is ideal for online analytical processing (OLAP) using your existing
business intelligence tools. Organizations are using Amazon Redshift to do the following:
needs without having to wait for additional hardware, or being required to over-invest to
provision enough capacity. For mission-critical applications on a more traditional
infrastructure, system designers have no choice but to over-provision, because a surge
in additional data due to an increase in business need must be something the system
can handle. By contrast, on AWS you can provision more capacity and compute in a
matter of minutes, meaning that your big data applications grow and shrink as demand
dictates, and your system runs as close to optimal efficiency as possible. In addition, you
get flexible computing on a world-class infrastructure with access to the many different
geographic regions that AWS offers 1 , along with the ability to utilize other scalable
services that Amazon offers such as Amazon Simple Storage Service (S3) 2 and AWS
Data Pipeline. 3 These capabilities of the AWS platform make it an extremely good fit for
solving big data problems. You can read about many customers that have implemented
successful big data analytics workloads on AWS on the AWS case studies web page. 4
Amazon Redshift
Amazon Redshift is a fast, fully-managed, petabyte-scale data warehouse service that
makes it simple and cost-effective to efficiently analyze all your data using your existing
business intelligence tools. 5 It is optimized for datasets ranging from a few hundred
gigabytes to a petabyte or more, and is designed to cost less than a tenth of the cost of
most traditional data warehousing solutions. Amazon Redshift delivers fast query and
I/O performance for virtually any size dataset by using columnar storage technology
while parallelizing and distributing queries across multiple nodes. As a managed service,
automation is provided for most of the common administrative tasks associated with
provisioning, configuring, monitoring, backing up, and securing a data warehouse,
making it very easy and inexpensive to manage and maintain. This automation allows
you to build a petabyte-scale data warehouse in minutes, a task that has traditionally
taken weeks, or months, to complete in an on-premises implementation.
Ideal Usage Pattern
Amazon Redshift is ideal for online analytical processing (OLAP) using your existing
business intelligence tools. Organizations are using Amazon Redshift to do the following:

Page 4 of 29
Analyze global sales data for multiple products
Store historical stock trade data
Analyze ad impressions and clicks
Aggregate gaming data
Analyze social trends
1 http://aws.amazon.com/about-aws/globalinfrastructure/
2 http://aws.amazon.com/s3/
3 http://aws.amazon.com/datapipeline/
4 http://aws.amazon.com/solutions/case-studies/big-data/

Page 4 of 29
Analyze global sales data for multiple products
Store historical stock trade data
Analyze ad impressions and clicks
Aggregate gaming data
Analyze social trends
1 http://aws.amazon.com/about-aws/globalinfrastructure/
2 http://aws.amazon.com/s3/
3 http://aws.amazon.com/datapipeline/
4 http://aws.amazon.com/solutions/case-studies/big-data/

needs without having to wait for additional hardware, or being required to over-invest to
provision enough capacity. For mission-critical applications on a more traditional
infrastructure, system designers have no choice but to over-provision, because a surge
in additional data due to an increase in business need must be something the system
can handle. By contrast, on AWS you can provision more capacity and compute in a
matter of minutes, meaning that your big data applications grow and shrink as demand
dictates, and your system runs as close to optimal efficiency as possible. In addition, you
get flexible computing on a world-class infrastructure with access to the many different
geographic regions that AWS offers 1 , along with the ability to utilize other scalable
services that Amazon offers such as Amazon Simple Storage Service (S3) 2 and AWS
Data Pipeline. 3 These capabilities of the AWS platform make it an extremely good fit for
solving big data problems. You can read about many customers that have implemented
successful big data analytics workloads on AWS on the AWS case studies web page. 4
Amazon Redshift
Amazon Redshift is a fast, fully-managed, petabyte-scale data warehouse service that
makes it simple and cost-effective to efficiently analyze all your data using your existing
business intelligence tools. 5 It is optimized for datasets ranging from a few hundred
gigabytes to a petabyte or more, and is designed to cost less than a tenth of the cost of
most traditional data warehousing solutions. Amazon Redshift delivers fast query and
I/O performance for virtually any size dataset by using columnar storage technology
while parallelizing and distributing queries across multiple nodes. As a managed service,
automation is provided for most of the common administrative tasks associated with
provisioning, configuring, monitoring, backing up, and securing a data warehouse,
making it very easy and inexpensive to manage and maintain. This automation allows
you to build a petabyte-scale data warehouse in minutes, a task that has traditionally
taken weeks, or months, to complete in an on-premises implementation.
Ideal Usage Pattern
Amazon Redshift is ideal for online analytical processing (OLAP) using your existing
business intelligence tools. Organizations are using Amazon Redshift to do the following:
needs without having to wait for additional hardware, or being required to over-invest to
provision enough capacity. For mission-critical applications on a more traditional
infrastructure, system designers have no choice but to over-provision, because a surge
in additional data due to an increase in business need must be something the system
can handle. By contrast, on AWS you can provision more capacity and compute in a
matter of minutes, meaning that your big data applications grow and shrink as demand
dictates, and your system runs as close to optimal efficiency as possible. In addition, you
get flexible computing on a world-class infrastructure with access to the many different
geographic regions that AWS offers 1 , along with the ability to utilize other scalable
services that Amazon offers such as Amazon Simple Storage Service (S3) 2 and AWS
Data Pipeline. 3 These capabilities of the AWS platform make it an extremely good fit for
solving big data problems. You can read about many customers that have implemented
successful big data analytics workloads on AWS on the AWS case studies web page. 4
Amazon Redshift
Amazon Redshift is a fast, fully-managed, petabyte-scale data warehouse service that
makes it simple and cost-effective to efficiently analyze all your data using your existing
business intelligence tools. 5 It is optimized for datasets ranging from a few hundred
gigabytes to a petabyte or more, and is designed to cost less than a tenth of the cost of
most traditional data warehousing solutions. Amazon Redshift delivers fast query and
I/O performance for virtually any size dataset by using columnar storage technology
while parallelizing and distributing queries across multiple nodes. As a managed service,
automation is provided for most of the common administrative tasks associated with
provisioning, configuring, monitoring, backing up, and securing a data warehouse,
making it very easy and inexpensive to manage and maintain. This automation allows
you to build a petabyte-scale data warehouse in minutes, a task that has traditionally
taken weeks, or months, to complete in an on-premises implementation.
Ideal Usage Pattern
Amazon Redshift is ideal for online analytical processing (OLAP) using your existing
business intelligence tools. Organizations are using Amazon Redshift to do the following:

Page 4 of 29
Analyze global sales data for multiple products
Store historical stock trade data
Analyze ad impressions and clicks
Aggregate gaming data
Analyze social trends
1 http://aws.amazon.com/about-aws/globalinfrastructure/
2 http://aws.amazon.com/s3/
3 http://aws.amazon.com/datapipeline/
4 http://aws.amazon.com/solutions/case-studies/big-data/

Page 4 of 29
Analyze global sales data for multiple products
Store historical stock trade data
Analyze ad impressions and clicks
Aggregate gaming data
Analyze social trends
1 http://aws.amazon.com/about-aws/globalinfrastructure/
2 http://aws.amazon.com/s3/
3 http://aws.amazon.com/datapipeline/
4 http://aws.amazon.com/solutions/case-studies/big-data/

needs without having to wait for additional hardware, or being required to over-invest to
provision enough capacity. For mission-critical applications on a more traditional
infrastructure, system designers have no choice but to over-provision, because a surge
in additional data due to an increase in business need must be something the system
can handle. By contrast, on AWS you can provision more capacity and compute in a
matter of minutes, meaning that your big data applications grow and shrink as demand
dictates, and your system runs as close to optimal efficiency as possible. In addition, you
get flexible computing on a world-class infrastructure with access to the many different
geographic regions that AWS offers 1 , along with the ability to utilize other scalable
services that Amazon offers such as Amazon Simple Storage Service (S3) 2 and AWS
Data Pipeline. 3 These capabilities of the AWS platform make it an extremely good fit for
solving big data problems. You can read about many customers that have implemented
successful big data analytics workloads on AWS on the AWS case studies web page. 4
Amazon Redshift
Amazon Redshift is a fast, fully-managed, petabyte-scale data warehouse service that
makes it simple and cost-effective to efficiently analyze all your data using your existing
business intelligence tools. 5 It is optimized for datasets ranging from a few hundred
gigabytes to a petabyte or more, and is designed to cost less than a tenth of the cost of
most traditional data warehousing solutions. Amazon Redshift delivers fast query and
I/O performance for virtually any size dataset by using columnar storage technology
while parallelizing and distributing queries across multiple nodes. As a managed service,
automation is provided for most of the common administrative tasks associated with
provisioning, configuring, monitoring, backing up, and securing a data warehouse,
making it very easy and inexpensive to manage and maintain. This automation allows
you to build a petabyte-scale data warehouse in minutes, a task that has traditionally
taken weeks, or months, to complete in an on-premises implementation.
Ideal Usage Pattern
Amazon Redshift is ideal for online analytical processing (OLAP) using your existing
business intelligence tools. Organizations are using Amazon Redshift to do the following:
needs without having to wait for additional hardware, or being required to over-invest to
provision enough capacity. For mission-critical applications on a more traditional
infrastructure, system designers have no choice but to over-provision, because a surge
in additional data due to an increase in business need must be something the system
can handle. By contrast, on AWS you can provision more capacity and compute in a
matter of minutes, meaning that your big data applications grow and shrink as demand
dictates, and your system runs as close to optimal efficiency as possible. In addition, you
get flexible computing on a world-class infrastructure with access to the many different
geographic regions that AWS offers 1 , along with the ability to utilize other scalable
services that Amazon offers such as Amazon Simple Storage Service (S3) 2 and AWS
Data Pipeline. 3 These capabilities of the AWS platform make it an extremely good fit for
solving big data problems. You can read about many customers that have implemented
successful big data analytics workloads on AWS on the AWS case studies web page. 4
Amazon Redshift
Amazon Redshift is a fast, fully-managed, petabyte-scale data warehouse service that
makes it simple and cost-effective to efficiently analyze all your data using your existing
business intelligence tools. 5 It is optimized for datasets ranging from a few hundred
gigabytes to a petabyte or more, and is designed to cost less than a tenth of the cost of
most traditional data warehousing solutions. Amazon Redshift delivers fast query and
I/O performance for virtually any size dataset by using columnar storage technology
while parallelizing and distributing queries across multiple nodes. As a managed service,
automation is provided for most of the common administrative tasks associated with
provisioning, configuring, monitoring, backing up, and securing a data warehouse,
making it very easy and inexpensive to manage and maintain. This automation allows
you to build a petabyte-scale data warehouse in minutes, a task that has traditionally
taken weeks, or months, to complete in an on-premises implementation.
Ideal Usage Pattern
Amazon Redshift is ideal for online analytical processing (OLAP) using your existing
business intelligence tools. Organizations are using Amazon Redshift to do the following:

Page 4 of 29
Analyze global sales data for multiple products
Store historical stock trade data
Analyze ad impressions and clicks
Aggregate gaming data
Analyze social trends
1 http://aws.amazon.com/about-aws/globalinfrastructure/
2 http://aws.amazon.com/s3/
3 http://aws.amazon.com/datapipeline/
4 http://aws.amazon.com/solutions/case-studies/big-data/

Page 4 of 29
Analyze global sales data for multiple products
Store historical stock trade data
Analyze ad impressions and clicks
Aggregate gaming data
Analyze social trends
1 http://aws.amazon.com/about-aws/globalinfrastructure/
2 http://aws.amazon.com/s3/
3 http://aws.amazon.com/datapipeline/
4 http://aws.amazon.com/solutions/case-studies/big-data/

needs without having to wait for additional hardware, or being required to over-invest to
provision enough capacity. For mission-critical applications on a more traditional
infrastructure, system designers have no choice but to over-provision, because a surge
in additional data due to an increase in business need must be something the system
can handle. By contrast, on AWS you can provision more capacity and compute in a
matter of minutes, meaning that your big data applications grow and shrink as demand
dictates, and your system runs as close to optimal efficiency as possible. In addition, you
get flexible computing on a world-class infrastructure with access to the many different
geographic regions that AWS offers 1 , along with the ability to utilize other scalable
services that Amazon offers such as Amazon Simple Storage Service (S3) 2 and AWS
Data Pipeline. 3 These capabilities of the AWS platform make it an extremely good fit for
solving big data problems. You can read about many customers that have implemented
successful big data analytics workloads on AWS on the AWS case studies web page. 4
Amazon Redshift
Amazon Redshift is a fast, fully-managed, petabyte-scale data warehouse service that
makes it simple and cost-effective to efficiently analyze all your data using your existing
business intelligence tools. 5 It is optimized for datasets ranging from a few hundred
gigabytes to a petabyte or more, and is designed to cost less than a tenth of the cost of
most traditional data warehousing solutions. Amazon Redshift delivers fast query and
I/O performance for virtually any size dataset by using columnar storage technology
while parallelizing and distributing queries across multiple nodes. As a managed service,
automation is provided for most of the common administrative tasks associated with
provisioning, configuring, monitoring, backing up, and securing a data warehouse,
making it very easy and inexpensive to manage and maintain. This automation allows
you to build a petabyte-scale data warehouse in minutes, a task that has traditionally
taken weeks, or months, to complete in an on-premises implementation.
Ideal Usage Pattern
Amazon Redshift is ideal for online analytical processing (OLAP) using your existing
business intelligence tools. Organizations are using Amazon Redshift to do the following:
needs without having to wait for additional hardware, or being required to over-invest to
provision enough capacity. For mission-critical applications on a more traditional
infrastructure, system designers have no choice but to over-provision, because a surge
in additional data due to an increase in business need must be something the system
can handle. By contrast, on AWS you can provision more capacity and compute in a
matter of minutes, meaning that your big data applications grow and shrink as demand
dictates, and your system runs as close to optimal efficiency as possible. In addition, you
get flexible computing on a world-class infrastructure with access to the many different
geographic regions that AWS offers 1 , along with the ability to utilize other scalable
services that Amazon offers such as Amazon Simple Storage Service (S3) 2 and AWS
Data Pipeline. 3 These capabilities of the AWS platform make it an extremely good fit for
solving big data problems. You can read about many customers that have implemented
successful big data analytics workloads on AWS on the AWS case studies web page. 4
Amazon Redshift
Amazon Redshift is a fast, fully-managed, petabyte-scale data warehouse service that
makes it simple and cost-effective to efficiently analyze all your data using your existing
business intelligence tools. 5 It is optimized for datasets ranging from a few hundred
gigabytes to a petabyte or more, and is designed to cost less than a tenth of the cost of
most traditional data warehousing solutions. Amazon Redshift delivers fast query and
I/O performance for virtually any size dataset by using columnar storage technology
while parallelizing and distributing queries across multiple nodes. As a managed service,
automation is provided for most of the common administrative tasks associated with
provisioning, configuring, monitoring, backing up, and securing a data warehouse,
making it very easy and inexpensive to manage and maintain. This automation allows
you to build a petabyte-scale data warehouse in minutes, a task that has traditionally
taken weeks, or months, to complete in an on-premises implementation.
Ideal Usage Pattern
Amazon Redshift is ideal for online analytical processing (OLAP) using your existing
business intelligence tools. Organizations are using Amazon Redshift to do the following:

Page 4 of 29
Analyze global sales data for multiple products
Store historical stock trade data
Analyze ad impressions and clicks
Aggregate gaming data
Analyze social trends
1 http://aws.amazon.com/about-aws/globalinfrastructure/
2 http://aws.amazon.com/s3/
3 http://aws.amazon.com/datapipeline/
4 http://aws.amazon.com/solutions/case-studies/big-data/

Page 4 of 29
Analyze global sales data for multiple products
Store historical stock trade data
Analyze ad impressions and clicks
Aggregate gaming data
Analyze social trends
1 http://aws.amazon.com/about-aws/globalinfrastructure/
2 http://aws.amazon.com/s3/
3 http://aws.amazon.com/datapipeline/
4 http://aws.amazon.com/solutions/case-studies/big-data/

needs without having to wait for additional hardware, or being required to over-invest to
provision enough capacity. For mission-critical applications on a more traditional
infrastructure, system designers have no choice but to over-provision, because a surge
in additional data due to an increase in business need must be something the system
can handle. By contrast, on AWS you can provision more capacity and compute in a
matter of minutes, meaning that your big data applications grow and shrink as demand
dictates, and your system runs as close to optimal efficiency as possible. In addition, you
get flexible computing on a world-class infrastructure with access to the many different
geographic regions that AWS offers 1 , along with the ability to utilize other scalable
services that Amazon offers such as Amazon Simple Storage Service (S3) 2 and AWS
Data Pipeline. 3 These capabilities of the AWS platform make it an extremely good fit for
solving big data problems. You can read about many customers that have implemented
successful big data analytics workloads on AWS on the AWS case studies web page. 4
Amazon Redshift
Amazon Redshift is a fast, fully-managed, petabyte-scale data warehouse service that
makes it simple and cost-effective to efficiently analyze all your data using your existing
business intelligence tools. 5 It is optimized for datasets ranging from a few hundred
gigabytes to a petabyte or more, and is designed to cost less than a tenth of the cost of
most traditional data warehousing solutions. Amazon Redshift delivers fast query and
I/O performance for virtually any size dataset by using columnar storage technology
while parallelizing and distributing queries across multiple nodes. As a managed service,
automation is provided for most of the common administrative tasks associated with
provisioning, configuring, monitoring, backing up, and securing a data warehouse,
making it very easy and inexpensive to manage and maintain. This automation allows
you to build a petabyte-scale data warehouse in minutes, a task that has traditionally
taken weeks, or months, to complete in an on-premises implementation.
Ideal Usage Pattern
Amazon Redshift is ideal for online analytical processing (OLAP) using your existing
business intelligence tools. Organizations are using Amazon Redshift to do the following:
needs without having to wait for additional hardware, or being required to over-invest to
provision enough capacity. For mission-critical applications on a more traditional
infrastructure, system designers have no choice but to over-provision, because a surge
in additional data due to an increase in business need must be something the system
can handle. By contrast, on AWS you can provision more capacity and compute in a
matter of minutes, meaning that your big data applications grow and shrink as demand
dictates, and your system runs as close to optimal efficiency as possible. In addition, you
get flexible computing on a world-class infrastructure with access to the many different
geographic regions that AWS offers 1 , along with the ability to utilize other scalable
services that Amazon offers such as Amazon Simple Storage Service (S3) 2 and AWS
Data Pipeline. 3 These capabilities of the AWS platform make it an extremely good fit for
solving big data problems. You can read about many customers that have implemented
successful big data analytics workloads on AWS on the AWS case studies web page. 4
Amazon Redshift
Amazon Redshift is a fast, fully-managed, petabyte-scale data warehouse service that
makes it simple and cost-effective to efficiently analyze all your data using your existing
business intelligence tools. 5 It is optimized for datasets ranging from a few hundred
gigabytes to a petabyte or more, and is designed to cost less than a tenth of the cost of
most traditional data warehousing solutions. Amazon Redshift delivers fast query and
I/O performance for virtually any size dataset by using columnar storage technology
while parallelizing and distributing queries across multiple nodes. As a managed service,
automation is provided for most of the common administrative tasks associated with
provisioning, configuring, monitoring, backing up, and securing a data warehouse,
making it very easy and inexpensive to manage and maintain. This automation allows
you to build a petabyte-scale data warehouse in minutes, a task that has traditionally
taken weeks, or months, to complete in an on-premises implementation.
Ideal Usage Pattern
Amazon Redshift is ideal for online analytical processing (OLAP) using your existing
business intelligence tools. Organizations are using Amazon Redshift to do the following:

Page 4 of 29
Analyze global sales data for multiple products
Store historical stock trade data
Analyze ad impressions and clicks
Aggregate gaming data
Analyze social trends
1 http://aws.amazon.com/about-aws/globalinfrastructure/
2 http://aws.amazon.com/s3/
3 http://aws.amazon.com/datapipeline/
4 http://aws.amazon.com/solutions/case-studies/big-data/

Page 4 of 29
Analyze global sales data for multiple products
Store historical stock trade data
Analyze ad impressions and clicks
Aggregate gaming data
Analyze social trends
1 http://aws.amazon.com/about-aws/globalinfrastructure/
2 http://aws.amazon.com/s3/
3 http://aws.amazon.com/datapipeline/
4 http://aws.amazon.com/solutions/case-studies/big-data/

needs without having to wait for additional hardware, or being required to over-invest to
provision enough capacity. For mission-critical applications on a more traditional
infrastructure, system designers have no choice but to over-provision, because a surge
in additional data due to an increase in business need must be something the system
can handle. By contrast, on AWS you can provision more capacity and compute in a
matter of minutes, meaning that your big data applications grow and shrink as demand
dictates, and your system runs as close to optimal efficiency as possible. In addition, you
get flexible computing on a world-class infrastructure with access to the many different
geographic regions that AWS offers 1 , along with the ability to utilize other scalable
services that Amazon offers such as Amazon Simple Storage Service (S3) 2 and AWS
Data Pipeline. 3 These capabilities of the AWS platform make it an extremely good fit for
solving big data problems. You can read about many customers that have implemented
successful big data analytics workloads on AWS on the AWS case studies web page. 4
Amazon Redshift
Amazon Redshift is a fast, fully-managed, petabyte-scale data warehouse service that
makes it simple and cost-effective to efficiently analyze all your data using your existing
business intelligence tools. 5 It is optimized for datasets ranging from a few hundred
gigabytes to a petabyte or more, and is designed to cost less than a tenth of the cost of
most traditional data warehousing solutions. Amazon Redshift delivers fast query and
I/O performance for virtually any size dataset by using columnar storage technology
while parallelizing and distributing queries across multiple nodes. As a managed service,
automation is provided for most of the common administrative tasks associated with
provisioning, configuring, monitoring, backing up, and securing a data warehouse,
making it very easy and inexpensive to manage and maintain. This automation allows
you to build a petabyte-scale data warehouse in minutes, a task that has traditionally
taken weeks, or months, to complete in an on-premises implementation.
Ideal Usage Pattern
Amazon Redshift is ideal for online analytical processing (OLAP) using your existing
business intelligence tools. Organizations are using Amazon Redshift to do the following:
needs without having to wait for additional hardware, or being required to over-invest to
provision enough capacity. For mission-critical applications on a more traditional
infrastructure, system designers have no choice but to over-provision, because a surge
in additional data due to an increase in business need must be something the system
can handle. By contrast, on AWS you can provision more capacity and compute in a
matter of minutes, meaning that your big data applications grow and shrink as demand
dictates, and your system runs as close to optimal efficiency as possible. In addition, you
get flexible computing on a world-class infrastructure with access to the many different
geographic regions that AWS offers 1 , along with the ability to utilize other scalable
services that Amazon offers such as Amazon Simple Storage Service (S3) 2 and AWS
Data Pipeline. 3 These capabilities of the AWS platform make it an extremely good fit for
solving big data problems. You can read about many customers that have implemented
successful big data analytics workloads on AWS on the AWS case studies web page. 4
Amazon Redshift
Amazon Redshift is a fast, fully-managed, petabyte-scale data warehouse service that
makes it simple and cost-effective to efficiently analyze all your data using your existing
business intelligence tools. 5 It is optimized for datasets ranging from a few hundred
gigabytes to a petabyte or more, and is designed to cost less than a tenth of the cost of
most traditional data warehousing solutions. Amazon Redshift delivers fast query and
I/O performance for virtually any size dataset by using columnar storage technology
while parallelizing and distributing queries across multiple nodes. As a managed service,
automation is provided for most of the common administrative tasks associated with
provisioning, configuring, monitoring, backing up, and securing a data warehouse,
making it very easy and inexpensive to manage and maintain. This automation allows
you to build a petabyte-scale data warehouse in minutes, a task that has traditionally
taken weeks, or months, to complete in an on-premises implementation.
Ideal Usage Pattern
Amazon Redshift is ideal for online analytical processing (OLAP) using your existing
business intelligence tools. Organizations are using Amazon Redshift to do the following:

Page 4 of 29
Analyze global sales data for multiple products
Store historical stock trade data
Analyze ad impressions and clicks
Aggregate gaming data
Analyze social trends
1 http://aws.amazon.com/about-aws/globalinfrastructure/
2 http://aws.amazon.com/s3/
3 http://aws.amazon.com/datapipeline/
4 http://aws.amazon.com/solutions/case-studies/big-data/

Page 4 of 29
Analyze global sales data for multiple products
Store historical stock trade data
Analyze ad impressions and clicks
Aggregate gaming data
Analyze social trends
1 http://aws.amazon.com/about-aws/globalinfrastructure/
2 http://aws.amazon.com/s3/
3 http://aws.amazon.com/datapipeline/
4 http://aws.amazon.com/solutions/case-studies/big-data/
needs without having to wait for additional hardware, or being required to over-invest to
provision enough capacity. For mission-critical applications on a more traditional
infrastructure, system designers have no choice but to over-provision, because a surge
in additional data due to an increase in business need must be something the system
can handle. By contrast, on AWS you can provision more capacity and compute in a
matter of minutes, meaning that your big data applications grow and shrink as demand
dictates, and your system runs as close to optimal efficiency as possible. In addition, you
get flexible computing on a world-class infrastructure with access to the many different
geographic regions that AWS offers 1 , along with the ability to utilize other scalable
services that Amazon offers such as Amazon Simple Storage Service (S3) 2 and AWS
Data Pipeline. 3 These capabilities of the AWS platform make it an extremely good fit for
solving big data problems. You can read about many customers that have implemented
successful big data analytics workloads on AWS on the AWS case studies web page. 4
Amazon Redshift
Amazon Redshift is a fast, fully-managed, petabyte-scale data warehouse service that
makes it simple and cost-effective to efficiently analyze all your data using your existing
business intelligence tools. 5 It is optimized for datasets ranging from a few hundred
gigabytes to a petabyte or more, and is designed to cost less than a tenth of the cost of
most traditional data warehousing solutions. Amazon Redshift delivers fast query and
I/O performance for virtually any size dataset by using columnar storage technology
while parallelizing and distributing queries across multiple nodes. As a managed service,
automation is provided for most of the common administrative tasks associated with
provisioning, configuring, monitoring, backing up, and securing a data warehouse,
making it very easy and inexpensive to manage and maintain. This automation allows
you to build a petabyte-scale data warehouse in minutes, a task that has traditionally
taken weeks, or months, to complete in an on-premises implementation.
Ideal Usage Pattern
Amazon Redshift is ideal for online analytical processing (OLAP) using your existing
business intelligence tools. Organizations are using Amazon Redshift to do the following:
needs without having to wait for additional hardware, or being required to over-invest to
provision enough capacity. For mission-critical applications on a more traditional
infrastructure, system designers have no choice but to over-provision, because a surge
in additional data due to an increase in business need must be something the system
can handle. By contrast, on AWS you can provision more capacity and compute in a
matter of minutes, meaning that your big data applications grow and shrink as demand
dictates, and your system runs as close to optimal efficiency as possible. In addition, you
get flexible computing on a world-class infrastructure with access to the many different
geographic regions that AWS offers 1 , along with the ability to utilize other scalable
services that Amazon offers such as Amazon Simple Storage Service (S3) 2 and AWS
Data Pipeline. 3 These capabilities of the AWS platform make it an extremely good fit for
solving big data problems. You can read about many customers that have implemented
successful big data analytics workloads on AWS on the AWS case studies web page. 4
Amazon Redshift
Amazon Redshift is a fast, fully-managed, petabyte-scale data warehouse service that
makes it simple and cost-effective to efficiently analyze all your data using your existing
business intelligence tools. 5 It is optimized for datasets ranging from a few hundred
gigabytes to a petabyte or more, and is designed to cost less than a tenth of the cost of
most traditional data warehousing solutions. Amazon Redshift delivers fast query and
I/O performance for virtually any size dataset by using columnar storage technology
while parallelizing and distributing queries across multiple nodes. As a managed service,
automation is provided for most of the common administrative tasks associated with
provisioning, configuring, monitoring, backing up, and securing a data warehouse,
making it very easy and inexpensive to manage and maintain. This automation allows
you to build a petabyte-scale data warehouse in minutes, a task that has traditionally
taken weeks, or months, to complete in an on-premises implementation.
Ideal Usage Pattern
Amazon Redshift is ideal for online analytical processing (OLAP) using your existing
business intelligence tools. Organizations are using Amazon Redshift to do the following:

Page 4 of 29
Analyze global sales data for multiple products
Store historical stock trade data
Analyze ad impressions and clicks
Aggregate gaming data
Analyze social trends
1 http://aws.amazon.com/about-aws/globalinfrastructure/
2 http://aws.amazon.com/s3/
3 http://aws.amazon.com/datapipeline/
4 http://aws.amazon.com/solutions/case-studies/big-data/

Page 4 of 29
Analyze global sales data for multiple products
Store historical stock trade data
Analyze ad impressions and clicks
Aggregate gaming data
Analyze social trends
1 http://aws.amazon.com/about-aws/globalinfrastructure/
2 http://aws.amazon.com/s3/
3 http://aws.amazon.com/datapipeline/
4 http://aws.amazon.com/solutions/case-studies/big-data/
needs without having to wait for additional hardware, or being required to over-invest to
provision enough capacity. For mission-critical applications on a more traditional
infrastructure, system designers have no choice but to over-provision, because a surge
in additional data due to an increase in business need must be something the system
can handle. By contrast, on AWS you can provision more capacity and compute in a
matter of minutes, meaning that your big data applications grow and shrink as demand
dictates, and your system runs as close to optimal efficiency as possible. In addition, you
get flexible computing on a world-class infrastructure with access to the many different
geographic regions that AWS offers 1 , along with the ability to utilize other scalable
services that Amazon offers such as Amazon Simple Storage Service (S3) 2 and AWS
Data Pipeline. 3 These capabilities of the AWS platform make it an extremely good fit for
solving big data problems. You can read about many customers that have implemented
successful big data analytics workloads on AWS on the AWS case studies web page. 4
Amazon Redshift
Amazon Redshift is a fast, fully-managed, petabyte-scale data warehouse service that
makes it simple and cost-effective to efficiently analyze all your data using your existing
business intelligence tools. 5 It is optimized for datasets ranging from a few hundred
gigabytes to a petabyte or more, and is designed to cost less than a tenth of the cost of
most traditional data warehousing solutions. Amazon Redshift delivers fast query and
I/O performance for virtually any size dataset by using columnar storage technology
while parallelizing and distributing queries across multiple nodes. As a managed service,
automation is provided for most of the common administrative tasks associated with
provisioning, configuring, monitoring, backing up, and securing a data warehouse,
making it very easy and inexpensive to manage and maintain. This automation allows
you to build a petabyte-scale data warehouse in minutes, a task that has traditionally
taken weeks, or months, to complete in an on-premises implementation.
Ideal Usage Pattern
Amazon Redshift is ideal for online analytical processing (OLAP) using your existing
business intelligence tools. Organizations are using Amazon Redshift to do the following:
needs without having to wait for additional hardware, or being required to over-invest to
provision enough capacity. For mission-critical applications on a more traditional
infrastructure, system designers have no choice but to over-provision, because a surge
in additional data due to an increase in business need must be something the system
can handle. By contrast, on AWS you can provision more capacity and compute in a
matter of minutes, meaning that your big data applications grow and shrink as demand
dictates, and your system runs as close to optimal efficiency as possible. In addition, you
get flexible computing on a world-class infrastructure with access to the many different
geographic regions that AWS offers 1 , along with the ability to utilize other scalable
services that Amazon offers such as Amazon Simple Storage Service (S3) 2 and AWS
Data Pipeline. 3 These capabilities of the AWS platform make it an extremely good fit for
solving big data problems. You can read about many customers that have implemented
successful big data analytics workloads on AWS on the AWS case studies web page. 4
Amazon Redshift
Amazon Redshift is a fast, fully-managed, petabyte-scale data warehouse service that
makes it simple and cost-effective to efficiently analyze all your data using your existing
business intelligence tools. 5 It is optimized for datasets ranging from a few hundred
gigabytes to a petabyte or more, and is designed to cost less than a tenth of the cost of
most traditional data warehousing solutions. Amazon Redshift delivers fast query and
I/O performance for virtually any size dataset by using columnar storage technology
while parallelizing and distributing queries across multiple nodes. As a managed service,
automation is provided for most of the common administrative tasks associated with
provisioning, configuring, monitoring, backing up, and securing a data warehouse,
making it very easy and inexpensive to manage and maintain. This automation allows
you to build a petabyte-scale data warehouse in minutes, a task that has traditionally
taken weeks, or months, to complete in an on-premises implementation.
Ideal Usage Pattern
Amazon Redshift is ideal for online analytical processing (OLAP) using your existing
business intelligence tools. Organizations are using Amazon Redshift to do the following:

Page 4 of 29
Analyze global sales data for multiple products
Store historical stock trade data
Analyze ad impressions and clicks
Aggregate gaming data
Analyze social trends
1 http://aws.amazon.com/about-aws/globalinfrastructure/
2 http://aws.amazon.com/s3/
3 http://aws.amazon.com/datapipeline/
4 http://aws.amazon.com/solutions/case-studies/big-data/

Page 4 of 29
Analyze global sales data for multiple products
Store historical stock trade data
Analyze ad impressions and clicks
Aggregate gaming data
Analyze social trends
1 http://aws.amazon.com/about-aws/globalinfrastructure/
2 http://aws.amazon.com/s3/
3 http://aws.amazon.com/datapipeline/
4 http://aws.amazon.com/solutions/case-studies/big-data/

needs without having to wait for additional hardware, or being required to over-invest to
provision enough capacity. For mission-critical applications on a more traditional
infrastructure, system designers have no choice but to over-provision, because a surge
in additional data due to an increase in business need must be something the system
can handle. By contrast, on AWS you can provision more capacity and compute in a
matter of minutes, meaning that your big data applications grow and shrink as demand
dictates, and your system runs as close to optimal efficiency as possible. In addition, you
get flexible computing on a world-class infrastructure with access to the many different
geographic regions that AWS offers 1 , along with the ability to utilize other scalable
services that Amazon offers such as Amazon Simple Storage Service (S3) 2 and AWS
Data Pipeline. 3 These capabilities of the AWS platform make it an extremely good fit for
solving big data problems. You can read about many customers that have implemented
successful big data analytics workloads on AWS on the AWS case studies web page. 4
Amazon Redshift
Amazon Redshift is a fast, fully-managed, petabyte-scale data warehouse service that
makes it simple and cost-effective to efficiently analyze all your data using your existing
business intelligence tools. 5 It is optimized for datasets ranging from a few hundred
gigabytes to a petabyte or more, and is designed to cost less than a tenth of the cost of
most traditional data warehousing solutions. Amazon Redshift delivers fast query and
I/O performance for virtually any size dataset by using columnar storage technology
while parallelizing and distributing queries across multiple nodes. As a managed service,
automation is provided for most of the common administrative tasks associated with
provisioning, configuring, monitoring, backing up, and securing a data warehouse,
making it very easy and inexpensive to manage and maintain. This automation allows
you to build a petabyte-scale data warehouse in minutes, a task that has traditionally
taken weeks, or months, to complete in an on-premises implementation.
Ideal Usage Pattern
Amazon Redshift is ideal for online analytical processing (OLAP) using your existing
business intelligence tools. Organizations are using Amazon Redshift to do the following:
needs without having to wait for additional hardware, or being required to over-invest to
provision enough capacity. For mission-critical applications on a more traditional
infrastructure, system designers have no choice but to over-provision, because a surge
in additional data due to an increase in business need must be something the system
can handle. By contrast, on AWS you can provision more capacity and compute in a
matter of minutes, meaning that your big data applications grow and shrink as demand
dictates, and your system runs as close to optimal efficiency as possible. In addition, you
get flexible computing on a world-class infrastructure with access to the many different
geographic regions that AWS offers 1 , along with the ability to utilize other scalable
services that Amazon offers such as Amazon Simple Storage Service (S3) 2 and AWS
Data Pipeline. 3 These capabilities of the AWS platform make it an extremely good fit for
solving big data problems. You can read about many customers that have implemented
successful big data analytics workloads on AWS on the AWS case studies web page. 4
Amazon Redshift
Amazon Redshift is a fast, fully-managed, petabyte-scale data warehouse service that
makes it simple and cost-effective to efficiently analyze all your data using your existing
business intelligence tools. 5 It is optimized for datasets ranging from a few hundred
gigabytes to a petabyte or more, and is designed to cost less than a tenth of the cost of
most traditional data warehousing solutions. Amazon Redshift delivers fast query and
I/O performance for virtually any size dataset by using columnar storage technology
while parallelizing and distributing queries across multiple nodes. As a managed service,
automation is provided for most of the common administrative tasks associated with
provisioning, configuring, monitoring, backing up, and securing a data warehouse,
making it very easy and inexpensive to manage and maintain. This automation allows
you to build a petabyte-scale data warehouse in minutes, a task that has traditionally
taken weeks, or months, to complete in an on-premises implementation.
Ideal Usage Pattern
Amazon Redshift is ideal for online analytical processing (OLAP) using your existing
business intelligence tools. Organizations are using Amazon Redshift to do the following:

Page 4 of 29
Analyze global sales data for multiple products
Store historical stock trade data
Analyze ad impressions and clicks
Aggregate gaming data
Analyze social trends
1 http://aws.amazon.com/about-aws/globalinfrastructure/
2 http://aws.amazon.com/s3/
3 http://aws.amazon.com/datapipeline/
4 http://aws.amazon.com/solutions/case-studies/big-data/

Page 4 of 29
Analyze global sales data for multiple products
Store historical stock trade data
Analyze ad impressions and clicks
Aggregate gaming data
Analyze social trends
1 http://aws.amazon.com/about-aws/globalinfrastructure/
2 http://aws.amazon.com/s3/
3 http://aws.amazon.com/datapipeline/
4 http://aws.amazon.com/solutions/case-studies/big-data/

needs without having to wait for additional hardware, or being required to over-invest to
provision enough capacity. For mission-critical applications on a more traditional
infrastructure, system designers have no choice but to over-provision, because a surge
in additional data due to an increase in business need must be something the system
can handle. By contrast, on AWS you can provision more capacity and compute in a
matter of minutes, meaning that your big data applications grow and shrink as demand
dictates, and your system runs as close to optimal efficiency as possible. In addition, you
get flexible computing on a world-class infrastructure with access to the many different
geographic regions that AWS offers 1 , along with the ability to utilize other scalable
services that Amazon offers such as Amazon Simple Storage Service (S3) 2 and AWS
Data Pipeline. 3 These capabilities of the AWS platform make it an extremely good fit for
solving big data problems. You can read about many customers that have implemented
successful big data analytics workloads on AWS on the AWS case studies web page. 4
Amazon Redshift
Amazon Redshift is a fast, fully-managed, petabyte-scale data warehouse service that
makes it simple and cost-effective to efficiently analyze all your data using your existing
business intelligence tools. 5 It is optimized for datasets ranging from a few hundred
gigabytes to a petabyte or more, and is designed to cost less than a tenth of the cost of
most traditional data warehousing solutions. Amazon Redshift delivers fast query and
I/O performance for virtually any size dataset by using columnar storage technology
while parallelizing and distributing queries across multiple nodes. As a managed service,
automation is provided for most of the common administrative tasks associated with
provisioning, configuring, monitoring, backing up, and securing a data warehouse,
making it very easy and inexpensive to manage and maintain. This automation allows
you to build a petabyte-scale data warehouse in minutes, a task that has traditionally
taken weeks, or months, to complete in an on-premises implementation.
Ideal Usage Pattern
Amazon Redshift is ideal for online analytical processing (OLAP) using your existing
business intelligence tools. Organizations are using Amazon Redshift to do the following:
needs without having to wait for additional hardware, or being required to over-invest to
provision enough capacity. For mission-critical applications on a more traditional
infrastructure, system designers have no choice but to over-provision, because a surge
in additional data due to an increase in business need must be something the system
can handle. By contrast, on AWS you can provision more capacity and compute in a
matter of minutes, meaning that your big data applications grow and shrink as demand
dictates, and your system runs as close to optimal efficiency as possible. In addition, you
get flexible computing on a world-class infrastructure with access to the many different
geographic regions that AWS offers 1 , along with the ability to utilize other scalable
services that Amazon offers such as Amazon Simple Storage Service (S3) 2 and AWS
Data Pipeline. 3 These capabilities of the AWS platform make it an extremely good fit for
solving big data problems. You can read about many customers that have implemented
successful big data analytics workloads on AWS on the AWS case studies web page. 4
Amazon Redshift
Amazon Redshift is a fast, fully-managed, petabyte-scale data warehouse service that
makes it simple and cost-effective to efficiently analyze all your data using your existing
business intelligence tools. 5 It is optimized for datasets ranging from a few hundred
gigabytes to a petabyte or more, and is designed to cost less than a tenth of the cost of
most traditional data warehousing solutions. Amazon Redshift delivers fast query and
I/O performance for virtually any size dataset by using columnar storage technology
while parallelizing and distributing queries across multiple nodes. As a managed service,
automation is provided for most of the common administrative tasks associated with
provisioning, configuring, monitoring, backing up, and securing a data warehouse,
making it very easy and inexpensive to manage and maintain. This automation allows
you to build a petabyte-scale data warehouse in minutes, a task that has traditionally
taken weeks, or months, to complete in an on-premises implementation.
Ideal Usage Pattern
Amazon Redshift is ideal for online analytical processing (OLAP) using your existing
business intelligence tools. Organizations are using Amazon Redshift to do the following:

Page 4 of 29
Analyze global sales data for multiple products
Store historical stock trade data
Analyze ad impressions and clicks
Aggregate gaming data
Analyze social trends
1 http://aws.amazon.com/about-aws/globalinfrastructure/
2 http://aws.amazon.com/s3/
3 http://aws.amazon.com/datapipeline/
4 http://aws.amazon.com/solutions/case-studies/big-data/

Page 4 of 29
Analyze global sales data for multiple products
Store historical stock trade data
Analyze ad impressions and clicks
Aggregate gaming data
Analyze social trends
1 http://aws.amazon.com/about-aws/globalinfrastructure/
2 http://aws.amazon.com/s3/
3 http://aws.amazon.com/datapipeline/
4 http://aws.amazon.com/solutions/case-studies/big-data/

needs without having to wait for additional hardware, or being required to over-invest to
provision enough capacity. For mission-critical applications on a more traditional
infrastructure, system designers have no choice but to over-provision, because a surge
in additional data due to an increase in business need must be something the system
can handle. By contrast, on AWS you can provision more capacity and compute in a
matter of minutes, meaning that your big data applications grow and shrink as demand
dictates, and your system runs as close to optimal efficiency as possible. In addition, you
get flexible computing on a world-class infrastructure with access to the many different
geographic regions that AWS offers 1 , along with the ability to utilize other scalable
services that Amazon offers such as Amazon Simple Storage Service (S3) 2 and AWS
Data Pipeline. 3 These capabilities of the AWS platform make it an extremely good fit for
solving big data problems. You can read about many customers that have implemented
successful big data analytics workloads on AWS on the AWS case studies web page. 4
Amazon Redshift
Amazon Redshift is a fast, fully-managed, petabyte-scale data warehouse service that
makes it simple and cost-effective to efficiently analyze all your data using your existing
business intelligence tools. 5 It is optimized for datasets ranging from a few hundred
gigabytes to a petabyte or more, and is designed to cost less than a tenth of the cost of
most traditional data warehousing solutions. Amazon Redshift delivers fast query and
I/O performance for virtually any size dataset by using columnar storage technology
while parallelizing and distributing queries across multiple nodes. As a managed service,
automation is provided for most of the common administrative tasks associated with
provisioning, configuring, monitoring, backing up, and securing a data warehouse,
making it very easy and inexpensive to manage and maintain. This automation allows
you to build a petabyte-scale data warehouse in minutes, a task that has traditionally
taken weeks, or months, to complete in an on-premises implementation.
Ideal Usage Pattern
Amazon Redshift is ideal for online analytical processing (OLAP) using your existing
business intelligence tools. Organizations are using Amazon Redshift to do the following:
needs without having to wait for additional hardware, or being required to over-invest to
provision enough capacity. For mission-critical applications on a more traditional
infrastructure, system designers have no choice but to over-provision, because a surge
in additional data due to an increase in business need must be something the system
can handle. By contrast, on AWS you can provision more capacity and compute in a
matter of minutes, meaning that your big data applications grow and shrink as demand
dictates, and your system runs as close to optimal efficiency as possible. In addition, you
get flexible computing on a world-class infrastructure with access to the many different
geographic regions that AWS offers 1 , along with the ability to utilize other scalable
services that Amazon offers such as Amazon Simple Storage Service (S3) 2 and AWS
Data Pipeline. 3 These capabilities of the AWS platform make it an extremely good fit for
solving big data problems. You can read about many customers that have implemented
successful big data analytics workloads on AWS on the AWS case studies web page. 4
Amazon Redshift
Amazon Redshift is a fast, fully-managed, petabyte-scale data warehouse service that
makes it simple and cost-effective to efficiently analyze all your data using your existing
business intelligence tools. 5 It is optimized for datasets ranging from a few hundred
gigabytes to a petabyte or more, and is designed to cost less than a tenth of the cost of
most traditional data warehousing solutions. Amazon Redshift delivers fast query and
I/O performance for virtually any size dataset by using columnar storage technology
while parallelizing and distributing queries across multiple nodes. As a managed service,
automation is provided for most of the common administrative tasks associated with
provisioning, configuring, monitoring, backing up, and securing a data warehouse,
making it very easy and inexpensive to manage and maintain. This automation allows
you to build a petabyte-scale data warehouse in minutes, a task that has traditionally
taken weeks, or months, to complete in an on-premises implementation.
Ideal Usage Pattern
Amazon Redshift is ideal for online analytical processing (OLAP) using your existing
business intelligence tools. Organizations are using Amazon Redshift to do the following:

Page 4 of 29
Analyze global sales data for multiple products
Store historical stock trade data
Analyze ad impressions and clicks
Aggregate gaming data
Analyze social trends
1 http://aws.amazon.com/about-aws/globalinfrastructure/
2 http://aws.amazon.com/s3/
3 http://aws.amazon.com/datapipeline/
4 http://aws.amazon.com/solutions/case-studies/big-data/

Page 4 of 29
Analyze global sales data for multiple products
Store historical stock trade data
Analyze ad impressions and clicks
Aggregate gaming data
Analyze social trends
1 http://aws.amazon.com/about-aws/globalinfrastructure/
2 http://aws.amazon.com/s3/
3 http://aws.amazon.com/datapipeline/
4 http://aws.amazon.com/solutions/case-studies/big-data/

needs without having to wait for additional hardware, or being required to over-invest to
provision enough capacity. For mission-critical applications on a more traditional
infrastructure, system designers have no choice but to over-provision, because a surge
in additional data due to an increase in business need must be something the system
can handle. By contrast, on AWS you can provision more capacity and compute in a
matter of minutes, meaning that your big data applications grow and shrink as demand
dictates, and your system runs as close to optimal efficiency as possible. In addition, you
get flexible computing on a world-class infrastructure with access to the many different
geographic regions that AWS offers 1 , along with the ability to utilize other scalable
services that Amazon offers such as Amazon Simple Storage Service (S3) 2 and AWS
Data Pipeline. 3 These capabilities of the AWS platform make it an extremely good fit for
solving big data problems. You can read about many customers that have implemented
successful big data analytics workloads on AWS on the AWS case studies web page. 4
Amazon Redshift
Amazon Redshift is a fast, fully-managed, petabyte-scale data warehouse service that
makes it simple and cost-effective to efficiently analyze all your data using your existing
business intelligence tools. 5 It is optimized for datasets ranging from a few hundred
gigabytes to a petabyte or more, and is designed to cost less than a tenth of the cost of
most traditional data warehousing solutions. Amazon Redshift delivers fast query and
I/O performance for virtually any size dataset by using columnar storage technology
while parallelizing and distributing queries across multiple nodes. As a managed service,
automation is provided for most of the common administrative tasks associated with
provisioning, configuring, monitoring, backing up, and securing a data warehouse,
making it very easy and inexpensive to manage and maintain. This automation allows
you to build a petabyte-scale data warehouse in minutes, a task that has traditionally
taken weeks, or months, to complete in an on-premises implementation.
Ideal Usage Pattern
Amazon Redshift is ideal for online analytical processing (OLAP) using your existing
business intelligence tools. Organizations are using Amazon Redshift to do the following:
needs without having to wait for additional hardware, or being required to over-invest to
provision enough capacity. For mission-critical applications on a more traditional
infrastructure, system designers have no choice but to over-provision, because a surge
in additional data due to an increase in business need must be something the system
can handle. By contrast, on AWS you can provision more capacity and compute in a
matter of minutes, meaning that your big data applications grow and shrink as demand
dictates, and your system runs as close to optimal efficiency as possible. In addition, you
get flexible computing on a world-class infrastructure with access to the many different
geographic regions that AWS offers 1 , along with the ability to utilize other scalable
services that Amazon offers such as Amazon Simple Storage Service (S3) 2 and AWS
Data Pipeline. 3 These capabilities of the AWS platform make it an extremely good fit for
solving big data problems. You can read about many customers that have implemented
successful big data analytics workloads on AWS on the AWS case studies web page. 4
Amazon Redshift
Amazon Redshift is a fast, fully-managed, petabyte-scale data warehouse service that
makes it simple and cost-effective to efficiently analyze all your data using your existing
business intelligence tools. 5 It is optimized for datasets ranging from a few hundred
gigabytes to a petabyte or more, and is designed to cost less than a tenth of the cost of
most traditional data warehousing solutions. Amazon Redshift delivers fast query and
I/O performance for virtually any size dataset by using columnar storage technology
while parallelizing and distributing queries across multiple nodes. As a managed service,
automation is provided for most of the common administrative tasks associated with
provisioning, configuring, monitoring, backing up, and securing a data warehouse,
making it very easy and inexpensive to manage and maintain. This automation allows
you to build a petabyte-scale data warehouse in minutes, a task that has traditionally
taken weeks, or months, to complete in an on-premises implementation.
Ideal Usage Pattern
Amazon Redshift is ideal for online analytical processing (OLAP) using your existing
business intelligence tools. Organizations are using Amazon Redshift to do the following:

Page 4 of 29
Analyze global sales data for multiple products
Store historical stock trade data
Analyze ad impressions and clicks
Aggregate gaming data
Analyze social trends
1 http://aws.amazon.com/about-aws/globalinfrastructure/
2 http://aws.amazon.com/s3/
3 http://aws.amazon.com/datapipeline/
4 http://aws.amazon.com/solutions/case-studies/big-data/

Page 4 of 29
Analyze global sales data for multiple products
Store historical stock trade data
Analyze ad impressions and clicks
Aggregate gaming data
Analyze social trends
1 http://aws.amazon.com/about-aws/globalinfrastructure/
2 http://aws.amazon.com/s3/
3 http://aws.amazon.com/datapipeline/
4 http://aws.amazon.com/solutions/case-studies/big-data/

needs without having to wait for additional hardware, or being required to over-invest to
provision enough capacity. For mission-critical applications on a more traditional
infrastructure, system designers have no choice but to over-provision, because a surge
in additional data due to an increase in business need must be something the system
can handle. By contrast, on AWS you can provision more capacity and compute in a
matter of minutes, meaning that your big data applications grow and shrink as demand
dictates, and your system runs as close to optimal efficiency as possible. In addition, you
get flexible computing on a world-class infrastructure with access to the many different
geographic regions that AWS offers 1 , along with the ability to utilize other scalable
services that Amazon offers such as Amazon Simple Storage Service (S3) 2 and AWS
Data Pipeline. 3 These capabilities of the AWS platform make it an extremely good fit for
solving big data problems. You can read about many customers that have implemented
successful big data analytics workloads on AWS on the AWS case studies web page. 4
Amazon Redshift
Amazon Redshift is a fast, fully-managed, petabyte-scale data warehouse service that
makes it simple and cost-effective to efficiently analyze all your data using your existing
business intelligence tools. 5 It is optimized for datasets ranging from a few hundred
gigabytes to a petabyte or more, and is designed to cost less than a tenth of the cost of
most traditional data warehousing solutions. Amazon Redshift delivers fast query and
I/O performance for virtually any size dataset by using columnar storage technology
while parallelizing and distributing queries across multiple nodes. As a managed service,
automation is provided for most of the common administrative tasks associated with
provisioning, configuring, monitoring, backing up, and securing a data warehouse,
making it very easy and inexpensive to manage and maintain. This automation allows
you to build a petabyte-scale data warehouse in minutes, a task that has traditionally
taken weeks, or months, to complete in an on-premises implementation.
Ideal Usage Pattern
Amazon Redshift is ideal for online analytical processing (OLAP) using your existing
business intelligence tools. Organizations are using Amazon Redshift to do the following:
needs without having to wait for additional hardware, or being required to over-invest to
provision enough capacity. For mission-critical applications on a more traditional
infrastructure, system designers have no choice but to over-provision, because a surge
in additional data due to an increase in business need must be something the system
can handle. By contrast, on AWS you can provision more capacity and compute in a
matter of minutes, meaning that your big data applications grow and shrink as demand
dictates, and your system runs as close to optimal efficiency as possible. In addition, you
get flexible computing on a world-class infrastructure with access to the many different
geographic regions that AWS offers 1 , along with the ability to utilize other scalable
services that Amazon offers such as Amazon Simple Storage Service (S3) 2 and AWS
Data Pipeline. 3 These capabilities of the AWS platform make it an extremely good fit for
solving big data problems. You can read about many customers that have implemented
successful big data analytics workloads on AWS on the AWS case studies web page. 4
Amazon Redshift
Amazon Redshift is a fast, fully-managed, petabyte-scale data warehouse service that
makes it simple and cost-effective to efficiently analyze all your data using your existing
business intelligence tools. 5 It is optimized for datasets ranging from a few hundred
gigabytes to a petabyte or more, and is designed to cost less than a tenth of the cost of
most traditional data warehousing solutions. Amazon Redshift delivers fast query and
I/O performance for virtually any size dataset by using columnar storage technology
while parallelizing and distributing queries across multiple nodes. As a managed service,
automation is provided for most of the common administrative tasks associated with
provisioning, configuring, monitoring, backing up, and securing a data warehouse,
making it very easy and inexpensive to manage and maintain. This automation allows
you to build a petabyte-scale data warehouse in minutes, a task that has traditionally
taken weeks, or months, to complete in an on-premises implementation.
Ideal Usage Pattern
Amazon Redshift is ideal for online analytical processing (OLAP) using your existing
business intelligence tools. Organizations are using Amazon Redshift to do the following:

Page 4 of 29
Analyze global sales data for multiple products
Store historical stock trade data
Analyze ad impressions and clicks
Aggregate gaming data
Analyze social trends
1 http://aws.amazon.com/about-aws/globalinfrastructure/
2 http://aws.amazon.com/s3/
3 http://aws.amazon.com/datapipeline/
4 http://aws.amazon.com/solutions/case-studies/big-data/

Page 4 of 29
Analyze global sales data for multiple products
Store historical stock trade data
Analyze ad impressions and clicks
Aggregate gaming data
Analyze social trends
1 http://aws.amazon.com/about-aws/globalinfrastructure/
2 http://aws.amazon.com/s3/
3 http://aws.amazon.com/datapipeline/
4 http://aws.amazon.com/solutions/case-studies/big-data/

needs without having to wait for additional hardware, or being required to over-invest to
provision enough capacity. For mission-critical applications on a more traditional
infrastructure, system designers have no choice but to over-provision, because a surge
in additional data due to an increase in business need must be something the system
can handle. By contrast, on AWS you can provision more capacity and compute in a
matter of minutes, meaning that your big data applications grow and shrink as demand
dictates, and your system runs as close to optimal efficiency as possible. In addition, you
get flexible computing on a world-class infrastructure with access to the many different
geographic regions that AWS offers 1 , along with the ability to utilize other scalable
services that Amazon offers such as Amazon Simple Storage Service (S3) 2 and AWS
Data Pipeline. 3 These capabilities of the AWS platform make it an extremely good fit for
solving big data problems. You can read about many customers that have implemented
successful big data analytics workloads on AWS on the AWS case studies web page. 4
Amazon Redshift
Amazon Redshift is a fast, fully-managed, petabyte-scale data warehouse service that
makes it simple and cost-effective to efficiently analyze all your data using your existing
business intelligence tools. 5 It is optimized for datasets ranging from a few hundred
gigabytes to a petabyte or more, and is designed to cost less than a tenth of the cost of
most traditional data warehousing solutions. Amazon Redshift delivers fast query and
I/O performance for virtually any size dataset by using columnar storage technology
while parallelizing and distributing queries across multiple nodes. As a managed service,
automation is provided for most of the common administrative tasks associated with
provisioning, configuring, monitoring, backing up, and securing a data warehouse,
making it very easy and inexpensive to manage and maintain. This automation allows
you to build a petabyte-scale data warehouse in minutes, a task that has traditionally
taken weeks, or months, to complete in an on-premises implementation.
Ideal Usage Pattern
Amazon Redshift is ideal for online analytical processing (OLAP) using your existing
business intelligence tools. Organizations are using Amazon Redshift to do the following:
needs without having to wait for additional hardware, or being required to over-invest to
provision enough capacity. For mission-critical applications on a more traditional
infrastructure, system designers have no choice but to over-provision, because a surge
in additional data due to an increase in business need must be something the system
can handle. By contrast, on AWS you can provision more capacity and compute in a
matter of minutes, meaning that your big data applications grow and shrink as demand
dictates, and your system runs as close to optimal efficiency as possible. In addition, you
get flexible computing on a world-class infrastructure with access to the many different
geographic regions that AWS offers 1 , along with the ability to utilize other scalable
services that Amazon offers such as Amazon Simple Storage Service (S3) 2 and AWS
Data Pipeline. 3 These capabilities of the AWS platform make it an extremely good fit for
solving big data problems. You can read about many customers that have implemented
successful big data analytics workloads on AWS on the AWS case studies web page. 4
Amazon Redshift
Amazon Redshift is a fast, fully-managed, petabyte-scale data warehouse service that
makes it simple and cost-effective to efficiently analyze all your data using your existing
business intelligence tools. 5 It is optimized for datasets ranging from a few hundred
gigabytes to a petabyte or more, and is designed to cost less than a tenth of the cost of
most traditional data warehousing solutions. Amazon Redshift delivers fast query and
I/O performance for virtually any size dataset by using columnar storage technology
while parallelizing and distributing queries across multiple nodes. As a managed service,
automation is provided for most of the common administrative tasks associated with
provisioning, configuring, monitoring, backing up, and securing a data warehouse,
making it very easy and inexpensive to manage and maintain. This automation allows
you to build a petabyte-scale data warehouse in minutes, a task that has traditionally
taken weeks, or months, to complete in an on-premises implementation.
Ideal Usage Pattern
Amazon Redshift is ideal for online analytical processing (OLAP) using your existing
business intelligence tools. Organizations are using Amazon Redshift to do the following:

Page 4 of 29
Analyze global sales data for multiple products
Store historical stock trade data
Analyze ad impressions and clicks
Aggregate gaming data
Analyze social trends
1 http://aws.amazon.com/about-aws/globalinfrastructure/
2 http://aws.amazon.com/s3/
3 http://aws.amazon.com/datapipeline/
4 http://aws.amazon.com/solutions/case-studies/big-data/

Page 4 of 29
Analyze global sales data for multiple products
Store historical stock trade data
Analyze ad impressions and clicks
Aggregate gaming data
Analyze social trends
1 http://aws.amazon.com/about-aws/globalinfrastructure/
2 http://aws.amazon.com/s3/
3 http://aws.amazon.com/datapipeline/
4 http://aws.amazon.com/solutions/case-studies/big-data/

needs without having to wait for additional hardware, or being required to over-invest to
provision enough capacity. For mission-critical applications on a more traditional
infrastructure, system designers have no choice but to over-provision, because a surge
in additional data due to an increase in business need must be something the system
can handle. By contrast, on AWS you can provision more capacity and compute in a
matter of minutes, meaning that your big data applications grow and shrink as demand
dictates, and your system runs as close to optimal efficiency as possible. In addition, you
get flexible computing on a world-class infrastructure with access to the many different
geographic regions that AWS offers 1 , along with the ability to utilize other scalable
services that Amazon offers such as Amazon Simple Storage Service (S3) 2 and AWS
Data Pipeline. 3 These capabilities of the AWS platform make it an extremely good fit for
solving big data problems. You can read about many customers that have implemented
successful big data analytics workloads on AWS on the AWS case studies web page. 4
Amazon Redshift
Amazon Redshift is a fast, fully-managed, petabyte-scale data warehouse service that
makes it simple and cost-effective to efficiently analyze all your data using your existing
business intelligence tools. 5 It is optimized for datasets ranging from a few hundred
gigabytes to a petabyte or more, and is designed to cost less than a tenth of the cost of
most traditional data warehousing solutions. Amazon Redshift delivers fast query and
I/O performance for virtually any size dataset by using columnar storage technology
while parallelizing and distributing queries across multiple nodes. As a managed service,
automation is provided for most of the common administrative tasks associated with
provisioning, configuring, monitoring, backing up, and securing a data warehouse,
making it very easy and inexpensive to manage and maintain. This automation allows
you to build a petabyte-scale data warehouse in minutes, a task that has traditionally
taken weeks, or months, to complete in an on-premises implementation.
Ideal Usage Pattern
Amazon Redshift is ideal for online analytical processing (OLAP) using your existing
business intelligence tools. Organizations are using Amazon Redshift to do the following:
needs without having to wait for additional hardware, or being required to over-invest to
provision enough capacity. For mission-critical applications on a more traditional
infrastructure, system designers have no choice but to over-provision, because a surge
in additional data due to an increase in business need must be something the system
can handle. By contrast, on AWS you can provision more capacity and compute in a
matter of minutes, meaning that your big data applications grow and shrink as demand
dictates, and your system runs as close to optimal efficiency as possible. In addition, you
get flexible computing on a world-class infrastructure with access to the many different
geographic regions that AWS offers 1 , along with the ability to utilize other scalable
services that Amazon offers such as Amazon Simple Storage Service (S3) 2 and AWS
Data Pipeline. 3 These capabilities of the AWS platform make it an extremely good fit for
solving big data problems. You can read about many customers that have implemented
successful big data analytics workloads on AWS on the AWS case studies web page. 4
Amazon Redshift
Amazon Redshift is a fast, fully-managed, petabyte-scale data warehouse service that
makes it simple and cost-effective to efficiently analyze all your data using your existing
business intelligence tools. 5 It is optimized for datasets ranging from a few hundred
gigabytes to a petabyte or more, and is designed to cost less than a tenth of the cost of
most traditional data warehousing solutions. Amazon Redshift delivers fast query and
I/O performance for virtually any size dataset by using columnar storage technology
while parallelizing and distributing queries across multiple nodes. As a managed service,
automation is provided for most of the common administrative tasks associated with
provisioning, configuring, monitoring, backing up, and securing a data warehouse,
making it very easy and inexpensive to manage and maintain. This automation allows
you to build a petabyte-scale data warehouse in minutes, a task that has traditionally
taken weeks, or months, to complete in an on-premises implementation.
Ideal Usage Pattern
Amazon Redshift is ideal for online analytical processing (OLAP) using your existing
business intelligence tools. Organizations are using Amazon Redshift to do the following:

Page 4 of 29
Analyze global sales data for multiple products
Store historical stock trade data
Analyze ad impressions and clicks
Aggregate gaming data
Analyze social trends
1 http://aws.amazon.com/about-aws/globalinfrastructure/
2 http://aws.amazon.com/s3/
3 http://aws.amazon.com/datapipeline/
4 http://aws.amazon.com/solutions/case-studies/big-data/

Page 4 of 29
Analyze global sales data for multiple products
Store historical stock trade data
Analyze ad impressions and clicks
Aggregate gaming data
Analyze social trends
1 http://aws.amazon.com/about-aws/globalinfrastructure/
2 http://aws.amazon.com/s3/
3 http://aws.amazon.com/datapipeline/
4 http://aws.amazon.com/solutions/case-studies/big-data/
needs without having to wait for additional hardware, or being required to over-invest to
provision enough capacity. For mission-critical applications on a more traditional
infrastructure, system designers have no choice but to over-provision, because a surge
in additional data due to an increase in business need must be something the system
can handle. By contrast, on AWS you can provision more capacity and compute in a
matter of minutes, meaning that your big data applications grow and shrink as demand
dictates, and your system runs as close to optimal efficiency as possible. In addition, you
get flexible computing on a world-class infrastructure with access to the many different
geographic regions that AWS offers 1 , along with the ability to utilize other scalable
services that Amazon offers such as Amazon Simple Storage Service (S3) 2 and AWS
Data Pipeline. 3 These capabilities of the AWS platform make it an extremely good fit for
solving big data problems. You can read about many customers that have implemented
successful big data analytics workloads on AWS on the AWS case studies web page. 4
Amazon Redshift
Amazon Redshift is a fast, fully-managed, petabyte-scale data warehouse service that
makes it simple and cost-effective to efficiently analyze all your data using your existing
business intelligence tools. 5 It is optimized for datasets ranging from a few hundred
gigabytes to a petabyte or more, and is designed to cost less than a tenth of the cost of
most traditional data warehousing solutions. Amazon Redshift delivers fast query and
I/O performance for virtually any size dataset by using columnar storage technology
while parallelizing and distributing queries across multiple nodes. As a managed service,
automation is provided for most of the common administrative tasks associated with
provisioning, configuring, monitoring, backing up, and securing a data warehouse,
making it very easy and inexpensive to manage and maintain. This automation allows
you to build a petabyte-scale data warehouse in minutes, a task that has traditionally
taken weeks, or months, to complete in an on-premises implementation.
Ideal Usage Pattern
Amazon Redshift is ideal for online analytical processing (OLAP) using your existing
business intelligence tools. Organizations are using Amazon Redshift to do the following:
needs without having to wait for additional hardware, or being required to over-invest to
provision enough capacity. For mission-critical applications on a more traditional
infrastructure, system designers have no choice but to over-provision, because a surge
in additional data due to an increase in business need must be something the system
can handle. By contrast, on AWS you can provision more capacity and compute in a
matter of minutes, meaning that your big data applications grow and shrink as demand
dictates, and your system runs as close to optimal efficiency as possible. In addition, you
get flexible computing on a world-class infrastructure with access to the many different
geographic regions that AWS offers 1 , along with the ability to utilize other scalable
services that Amazon offers such as Amazon Simple Storage Service (S3) 2 and AWS
Data Pipeline. 3 These capabilities of the AWS platform make it an extremely good fit for
solving big data problems. You can read about many customers that have implemented
successful big data analytics workloads on AWS on the AWS case studies web page. 4
Amazon Redshift
Amazon Redshift is a fast, fully-managed, petabyte-scale data warehouse service that
makes it simple and cost-effective to efficiently analyze all your data using your existing
business intelligence tools. 5 It is optimized for datasets ranging from a few hundred
gigabytes to a petabyte or more, and is designed to cost less than a tenth of the cost of
most traditional data warehousing solutions. Amazon Redshift delivers fast query and
I/O performance for virtually any size dataset by using columnar storage technology
while parallelizing and distributing queries across multiple nodes. As a managed service,
automation is provided for most of the common administrative tasks associated with
provisioning, configuring, monitoring, backing up, and securing a data warehouse,
making it very easy and inexpensive to manage and maintain. This automation allows
you to build a petabyte-scale data warehouse in minutes, a task that has traditionally
taken weeks, or months, to complete in an on-premises implementation.
Ideal Usage Pattern
Amazon Redshift is ideal for online analytical processing (OLAP) using your existing
business intelligence tools. Organizations are using Amazon Redshift to do the following:

Page 4 of 29
Analyze global sales data for multiple products
Store historical stock trade data
Analyze ad impressions and clicks
Aggregate gaming data
Analyze social trends
1 http://aws.amazon.com/about-aws/globalinfrastructure/
2 http://aws.amazon.com/s3/
3 http://aws.amazon.com/datapipeline/
4 http://aws.amazon.com/solutions/case-studies/big-data/

Page 4 of 29
Analyze global sales data for multiple products
Store historical stock trade data
Analyze ad impressions and clicks
Aggregate gaming data
Analyze social trends
1 http://aws.amazon.com/about-aws/globalinfrastructure/
2 http://aws.amazon.com/s3/
3 http://aws.amazon.com/datapipeline/
4 http://aws.amazon.com/solutions/case-studies/big-data/
needs without having to wait for additional hardware, or being required to over-invest to
provision enough capacity. For mission-critical applications on a more traditional
infrastructure, system designers have no choice but to over-provision, because a surge
in additional data due to an increase in business need must be something the system
can handle. By contrast, on AWS you can provision more capacity and compute in a
matter of minutes, meaning that your big data applications grow and shrink as demand
dictates, and your system runs as close to optimal efficiency as possible. In addition, you
get flexible computing on a world-class infrastructure with access to the many different
geographic regions that AWS offers 1 , along with the ability to utilize other scalable
services that Amazon offers such as Amazon Simple Storage Service (S3) 2 and AWS
Data Pipeline. 3 These capabilities of the AWS platform make it an extremely good fit for
solving big data problems. You can read about many customers that have implemented
successful big data analytics workloads on AWS on the AWS case studies web page. 4
Amazon Redshift
Amazon Redshift is a fast, fully-managed, petabyte-scale data warehouse service that
makes it simple and cost-effective to efficiently analyze all your data using your existing
business intelligence tools. 5 It is optimized for datasets ranging from a few hundred
gigabytes to a petabyte or more, and is designed to cost less than a tenth of the cost of
most traditional data warehousing solutions. Amazon Redshift delivers fast query and
I/O performance for virtually any size dataset by using columnar storage technology
while parallelizing and distributing queries across multiple nodes. As a managed service,
automation is provided for most of the common administrative tasks associated with
provisioning, configuring, monitoring, backing up, and securing a data warehouse,
making it very easy and inexpensive to manage and maintain. This automation allows
you to build a petabyte-scale data warehouse in minutes, a task that has traditionally
taken weeks, or months, to complete in an on-premises implementation.
Ideal Usage Pattern
Amazon Redshift is ideal for online analytical processing (OLAP) using your existing
business intelligence tools. Organizations are using Amazon Redshift to do the following:
needs without having to wait for additional hardware, or being required to over-invest to
provision enough capacity. For mission-critical applications on a more traditional
infrastructure, system designers have no choice but to over-provision, because a surge
in additional data due to an increase in business need must be something the system
can handle. By contrast, on AWS you can provision more capacity and compute in a
matter of minutes, meaning that your big data applications grow and shrink as demand
dictates, and your system runs as close to optimal efficiency as possible. In addition, you
get flexible computing on a world-class infrastructure with access to the many different
geographic regions that AWS offers 1 , along with the ability to utilize other scalable
services that Amazon offers such as Amazon Simple Storage Service (S3) 2 and AWS
Data Pipeline. 3 These capabilities of the AWS platform make it an extremely good fit for
solving big data problems. You can read about many customers that have implemented
successful big data analytics workloads on AWS on the AWS case studies web page. 4
Amazon Redshift
Amazon Redshift is a fast, fully-managed, petabyte-scale data warehouse service that
makes it simple and cost-effective to efficiently analyze all your data using your existing
business intelligence tools. 5 It is optimized for datasets ranging from a few hundred
gigabytes to a petabyte or more, and is designed to cost less than a tenth of the cost of
most traditional data warehousing solutions. Amazon Redshift delivers fast query and
I/O performance for virtually any size dataset by using columnar storage technology
while parallelizing and distributing queries across multiple nodes. As a managed service,
automation is provided for most of the common administrative tasks associated with
provisioning, configuring, monitoring, backing up, and securing a data warehouse,
making it very easy and inexpensive to manage and maintain. This automation allows
you to build a petabyte-scale data warehouse in minutes, a task that has traditionally
taken weeks, or months, to complete in an on-premises implementation.
Ideal Usage Pattern
Amazon Redshift is ideal for online analytical processing (OLAP) using your existing
business intelligence tools. Organizations are using Amazon Redshift to do the following:

Page 4 of 29
Analyze global sales data for multiple products
Store historical stock trade data
Analyze ad impressions and clicks
Aggregate gaming data
Analyze social trends
1 http://aws.amazon.com/about-aws/globalinfrastructure/
2 http://aws.amazon.com/s3/
3 http://aws.amazon.com/datapipeline/
4 http://aws.amazon.com/solutions/case-studies/big-data/

Page 4 of 29
Analyze global sales data for multiple products
Store historical stock trade data
Analyze ad impressions and clicks
Aggregate gaming data
Analyze social trends
1 http://aws.amazon.com/about-aws/globalinfrastructure/
2 http://aws.amazon.com/s3/
3 http://aws.amazon.com/datapipeline/
4 http://aws.amazon.com/solutions/case-studies/big-data/

needs without having to wait for additional hardware, or being required to over-invest to
provision enough capacity. For mission-critical applications on a more traditional
infrastructure, system designers have no choice but to over-provision, because a surge
in additional data due to an increase in business need must be something the system
can handle. By contrast, on AWS you can provision more capacity and compute in a
matter of minutes, meaning that your big data applications grow and shrink as demand
dictates, and your system runs as close to optimal efficiency as possible. In addition, you
get flexible computing on a world-class infrastructure with access to the many different
geographic regions that AWS offers 1 , along with the ability to utilize other scalable
services that Amazon offers such as Amazon Simple Storage Service (S3) 2 and AWS
Data Pipeline. 3 These capabilities of the AWS platform make it an extremely good fit for
solving big data problems. You can read about many customers that have implemented
successful big data analytics workloads on AWS on the AWS case studies web page. 4
Amazon Redshift
Amazon Redshift is a fast, fully-managed, petabyte-scale data warehouse service that
makes it simple and cost-effective to efficiently analyze all your data using your existing
business intelligence tools. 5 It is optimized for datasets ranging from a few hundred
gigabytes to a petabyte or more, and is designed to cost less than a tenth of the cost of
most traditional data warehousing solutions. Amazon Redshift delivers fast query and
I/O performance for virtually any size dataset by using columnar storage technology
while parallelizing and distributing queries across multiple nodes. As a managed service,
automation is provided for most of the common administrative tasks associated with
provisioning, configuring, monitoring, backing up, and securing a data warehouse,
making it very easy and inexpensive to manage and maintain. This automation allows
you to build a petabyte-scale data warehouse in minutes, a task that has traditionally
taken weeks, or months, to complete in an on-premises implementation.
Ideal Usage Pattern
Amazon Redshift is ideal for online analytical processing (OLAP) using your existing
business intelligence tools. Organizations are using Amazon Redshift to do the following:
needs without having to wait for additional hardware, or being required to over-invest to
provision enough capacity. For mission-critical applications on a more traditional
infrastructure, system designers have no choice but to over-provision, because a surge
in additional data due to an increase in business need must be something the system
can handle. By contrast, on AWS you can provision more capacity and compute in a
matter of minutes, meaning that your big data applications grow and shrink as demand
dictates, and your system runs as close to optimal efficiency as possible. In addition, you
get flexible computing on a world-class infrastructure with access to the many different
geographic regions that AWS offers 1 , along with the ability to utilize other scalable
services that Amazon offers such as Amazon Simple Storage Service (S3) 2 and AWS
Data Pipeline. 3 These capabilities of the AWS platform make it an extremely good fit for
solving big data problems. You can read about many customers that have implemented
successful big data analytics workloads on AWS on the AWS case studies web page. 4
Amazon Redshift
Amazon Redshift is a fast, fully-managed, petabyte-scale data warehouse service that
makes it simple and cost-effective to efficiently analyze all your data using your existing
business intelligence tools. 5 It is optimized for datasets ranging from a few hundred
gigabytes to a petabyte or more, and is designed to cost less than a tenth of the cost of
most traditional data warehousing solutions. Amazon Redshift delivers fast query and
I/O performance for virtually any size dataset by using columnar storage technology
while parallelizing and distributing queries across multiple nodes. As a managed service,
automation is provided for most of the common administrative tasks associated with
provisioning, configuring, monitoring, backing up, and securing a data warehouse,
making it very easy and inexpensive to manage and maintain. This automation allows
you to build a petabyte-scale data warehouse in minutes, a task that has traditionally
taken weeks, or months, to complete in an on-premises implementation.
Ideal Usage Pattern
Amazon Redshift is ideal for online analytical processing (OLAP) using your existing
business intelligence tools. Organizations are using Amazon Redshift to do the following:

Page 4 of 29
Analyze global sales data for multiple products
Store historical stock trade data
Analyze ad impressions and clicks
Aggregate gaming data
Analyze social trends
1 http://aws.amazon.com/about-aws/globalinfrastructure/
2 http://aws.amazon.com/s3/
3 http://aws.amazon.com/datapipeline/
4 http://aws.amazon.com/solutions/case-studies/big-data/

Page 4 of 29
Analyze global sales data for multiple products
Store historical stock trade data
Analyze ad impressions and clicks
Aggregate gaming data
Analyze social trends
1 http://aws.amazon.com/about-aws/globalinfrastructure/
2 http://aws.amazon.com/s3/
3 http://aws.amazon.com/datapipeline/
4 http://aws.amazon.com/solutions/case-studies/big-data/

needs without having to wait for additional hardware, or being required to over-invest to
provision enough capacity. For mission-critical applications on a more traditional
infrastructure, system designers have no choice but to over-provision, because a surge
in additional data due to an increase in business need must be something the system
can handle. By contrast, on AWS you can provision more capacity and compute in a
matter of minutes, meaning that your big data applications grow and shrink as demand
dictates, and your system runs as close to optimal efficiency as possible. In addition, you
get flexible computing on a world-class infrastructure with access to the many different
geographic regions that AWS offers 1 , along with the ability to utilize other scalable
services that Amazon offers such as Amazon Simple Storage Service (S3) 2 and AWS
Data Pipeline. 3 These capabilities of the AWS platform make it an extremely good fit for
solving big data problems. You can read about many customers that have implemented
successful big data analytics workloads on AWS on the AWS case studies web page. 4
Amazon Redshift
Amazon Redshift is a fast, fully-managed, petabyte-scale data warehouse service that
makes it simple and cost-effective to efficiently analyze all your data using your existing
business intelligence tools. 5 It is optimized for datasets ranging from a few hundred
gigabytes to a petabyte or more, and is designed to cost less than a tenth of the cost of
most traditional data warehousing solutions. Amazon Redshift delivers fast query and
I/O performance for virtually any size dataset by using columnar storage technology
while parallelizing and distributing queries across multiple nodes. As a managed service,
automation is provided for most of the common administrative tasks associated with
provisioning, configuring, monitoring, backing up, and securing a data warehouse,
making it very easy and inexpensive to manage and maintain. This automation allows
you to build a petabyte-scale data warehouse in minutes, a task that has traditionally
taken weeks, or months, to complete in an on-premises implementation.
Ideal Usage Pattern
Amazon Redshift is ideal for online analytical processing (OLAP) using your existing
business intelligence tools. Organizations are using Amazon Redshift to do the following:
needs without having to wait for additional hardware, or being required to over-invest to
provision enough capacity. For mission-critical applications on a more traditional
infrastructure, system designers have no choice but to over-provision, because a surge
in additional data due to an increase in business need must be something the system
can handle. By contrast, on AWS you can provision more capacity and compute in a
matter of minutes, meaning that your big data applications grow and shrink as demand
dictates, and your system runs as close to optimal efficiency as possible. In addition, you
get flexible computing on a world-class infrastructure with access to the many different
geographic regions that AWS offers 1 , along with the ability to utilize other scalable
services that Amazon offers such as Amazon Simple Storage Service (S3) 2 and AWS
Data Pipeline. 3 These capabilities of the AWS platform make it an extremely good fit for
solving big data problems. You can read about many customers that have implemented
successful big data analytics workloads on AWS on the AWS case studies web page. 4
Amazon Redshift
Amazon Redshift is a fast, fully-managed, petabyte-scale data warehouse service that
makes it simple and cost-effective to efficiently analyze all your data using your existing
business intelligence tools. 5 It is optimized for datasets ranging from a few hundred
gigabytes to a petabyte or more, and is designed to cost less than a tenth of the cost of
most traditional data warehousing solutions. Amazon Redshift delivers fast query and
I/O performance for virtually any size dataset by using columnar storage technology
while parallelizing and distributing queries across multiple nodes. As a managed service,
automation is provided for most of the common administrative tasks associated with
provisioning, configuring, monitoring, backing up, and securing a data warehouse,
making it very easy and inexpensive to manage and maintain. This automation allows
you to build a petabyte-scale data warehouse in minutes, a task that has traditionally
taken weeks, or months, to complete in an on-premises implementation.
Ideal Usage Pattern
Amazon Redshift is ideal for online analytical processing (OLAP) using your existing
business intelligence tools. Organizations are using Amazon Redshift to do the following:

Page 4 of 29
Analyze global sales data for multiple products
Store historical stock trade data
Analyze ad impressions and clicks
Aggregate gaming data
Analyze social trends
1 http://aws.amazon.com/about-aws/globalinfrastructure/
2 http://aws.amazon.com/s3/
3 http://aws.amazon.com/datapipeline/
4 http://aws.amazon.com/solutions/case-studies/big-data/

Page 4 of 29
Analyze global sales data for multiple products
Store historical stock trade data
Analyze ad impressions and clicks
Aggregate gaming data
Analyze social trends
1 http://aws.amazon.com/about-aws/globalinfrastructure/
2 http://aws.amazon.com/s3/
3 http://aws.amazon.com/datapipeline/
4 http://aws.amazon.com/solutions/case-studies/big-data/

needs without having to wait for additional hardware, or being required to over-invest to
provision enough capacity. For mission-critical applications on a more traditional
infrastructure, system designers have no choice but to over-provision, because a surge
in additional data due to an increase in business need must be something the system
can handle. By contrast, on AWS you can provision more capacity and compute in a
matter of minutes, meaning that your big data applications grow and shrink as demand
dictates, and your system runs as close to optimal efficiency as possible. In addition, you
get flexible computing on a world-class infrastructure with access to the many different
geographic regions that AWS offers 1 , along with the ability to utilize other scalable
services that Amazon offers such as Amazon Simple Storage Service (S3) 2 and AWS
Data Pipeline. 3 These capabilities of the AWS platform make it an extremely good fit for
solving big data problems. You can read about many customers that have implemented
successful big data analytics workloads on AWS on the AWS case studies web page. 4
Amazon Redshift
Amazon Redshift is a fast, fully-managed, petabyte-scale data warehouse service that
makes it simple and cost-effective to efficiently analyze all your data using your existing
business intelligence tools. 5 It is optimized for datasets ranging from a few hundred
gigabytes to a petabyte or more, and is designed to cost less than a tenth of the cost of
most traditional data warehousing solutions. Amazon Redshift delivers fast query and
I/O performance for virtually any size dataset by using columnar storage technology
while parallelizing and distributing queries across multiple nodes. As a managed service,
automation is provided for most of the common administrative tasks associated with
provisioning, configuring, monitoring, backing up, and securing a data warehouse,
making it very easy and inexpensive to manage and maintain. This automation allows
you to build a petabyte-scale data warehouse in minutes, a task that has traditionally
taken weeks, or months, to complete in an on-premises implementation.
Ideal Usage Pattern
Amazon Redshift is ideal for online analytical processing (OLAP) using your existing
business intelligence tools. Organizations are using Amazon Redshift to do the following:
needs without having to wait for additional hardware, or being required to over-invest to
provision enough capacity. For mission-critical applications on a more traditional
infrastructure, system designers have no choice but to over-provision, because a surge
in additional data due to an increase in business need must be something the system
can handle. By contrast, on AWS you can provision more capacity and compute in a
matter of minutes, meaning that your big data applications grow and shrink as demand
dictates, and your system runs as close to optimal efficiency as possible. In addition, you
get flexible computing on a world-class infrastructure with access to the many different
geographic regions that AWS offers 1 , along with the ability to utilize other scalable
services that Amazon offers such as Amazon Simple Storage Service (S3) 2 and AWS
Data Pipeline. 3 These capabilities of the AWS platform make it an extremely good fit for
solving big data problems. You can read about many customers that have implemented
successful big data analytics workloads on AWS on the AWS case studies web page. 4
Amazon Redshift
Amazon Redshift is a fast, fully-managed, petabyte-scale data warehouse service that
makes it simple and cost-effective to efficiently analyze all your data using your existing
business intelligence tools. 5 It is optimized for datasets ranging from a few hundred
gigabytes to a petabyte or more, and is designed to cost less than a tenth of the cost of
most traditional data warehousing solutions. Amazon Redshift delivers fast query and
I/O performance for virtually any size dataset by using columnar storage technology
while parallelizing and distributing queries across multiple nodes. As a managed service,
automation is provided for most of the common administrative tasks associated with
provisioning, configuring, monitoring, backing up, and securing a data warehouse,
making it very easy and inexpensive to manage and maintain. This automation allows
you to build a petabyte-scale data warehouse in minutes, a task that has traditionally
taken weeks, or months, to complete in an on-premises implementation.
Ideal Usage Pattern
Amazon Redshift is ideal for online analytical processing (OLAP) using your existing
business intelligence tools. Organizations are using Amazon Redshift to do the following:

Page 4 of 29
Analyze global sales data for multiple products
Store historical stock trade data
Analyze ad impressions and clicks
Aggregate gaming data
Analyze social trends
1 http://aws.amazon.com/about-aws/globalinfrastructure/
2 http://aws.amazon.com/s3/
3 http://aws.amazon.com/datapipeline/
4 http://aws.amazon.com/solutions/case-studies/big-data/

Page 4 of 29
Analyze global sales data for multiple products
Store historical stock trade data
Analyze ad impressions and clicks
Aggregate gaming data
Analyze social trends
1 http://aws.amazon.com/about-aws/globalinfrastructure/
2 http://aws.amazon.com/s3/
3 http://aws.amazon.com/datapipeline/
4 http://aws.amazon.com/solutions/case-studies/big-data/

needs without having to wait for additional hardware, or being required to over-invest to
provision enough capacity. For mission-critical applications on a more traditional
infrastructure, system designers have no choice but to over-provision, because a surge
in additional data due to an increase in business need must be something the system
can handle. By contrast, on AWS you can provision more capacity and compute in a
matter of minutes, meaning that your big data applications grow and shrink as demand
dictates, and your system runs as close to optimal efficiency as possible. In addition, you
get flexible computing on a world-class infrastructure with access to the many different
geographic regions that AWS offers 1 , along with the ability to utilize other scalable
services that Amazon offers such as Amazon Simple Storage Service (S3) 2 and AWS
Data Pipeline. 3 These capabilities of the AWS platform make it an extremely good fit for
solving big data problems. You can read about many customers that have implemented
successful big data analytics workloads on AWS on the AWS case studies web page. 4
Amazon Redshift
Amazon Redshift is a fast, fully-managed, petabyte-scale data warehouse service that
makes it simple and cost-effective to efficiently analyze all your data using your existing
business intelligence tools. 5 It is optimized for datasets ranging from a few hundred
gigabytes to a petabyte or more, and is designed to cost less than a tenth of the cost of
most traditional data warehousing solutions. Amazon Redshift delivers fast query and
I/O performance for virtually any size dataset by using columnar storage technology
while parallelizing and distributing queries across multiple nodes. As a managed service,
automation is provided for most of the common administrative tasks associated with
provisioning, configuring, monitoring, backing up, and securing a data warehouse,
making it very easy and inexpensive to manage and maintain. This automation allows
you to build a petabyte-scale data warehouse in minutes, a task that has traditionally
taken weeks, or months, to complete in an on-premises implementation.
Ideal Usage Pattern
Amazon Redshift is ideal for online analytical processing (OLAP) using your existing
business intelligence tools. Organizations are using Amazon Redshift to do the following:
needs without having to wait for additional hardware, or being required to over-invest to
provision enough capacity. For mission-critical applications on a more traditional
infrastructure, system designers have no choice but to over-provision, because a surge
in additional data due to an increase in business need must be something the system
can handle. By contrast, on AWS you can provision more capacity and compute in a
matter of minutes, meaning that your big data applications grow and shrink as demand
dictates, and your system runs as close to optimal efficiency as possible. In addition, you
get flexible computing on a world-class infrastructure with access to the many different
geographic regions that AWS offers 1 , along with the ability to utilize other scalable
services that Amazon offers such as Amazon Simple Storage Service (S3) 2 and AWS
Data Pipeline. 3 These capabilities of the AWS platform make it an extremely good fit for
solving big data problems. You can read about many customers that have implemented
successful big data analytics workloads on AWS on the AWS case studies web page. 4
Amazon Redshift
Amazon Redshift is a fast, fully-managed, petabyte-scale data warehouse service that
makes it simple and cost-effective to efficiently analyze all your data using your existing
business intelligence tools. 5 It is optimized for datasets ranging from a few hundred
gigabytes to a petabyte or more, and is designed to cost less than a tenth of the cost of
most traditional data warehousing solutions. Amazon Redshift delivers fast query and
I/O performance for virtually any size dataset by using columnar storage technology
while parallelizing and distributing queries across multiple nodes. As a managed service,
automation is provided for most of the common administrative tasks associated with
provisioning, configuring, monitoring, backing up, and securing a data warehouse,
making it very easy and inexpensive to manage and maintain. This automation allows
you to build a petabyte-scale data warehouse in minutes, a task that has traditionally
taken weeks, or months, to complete in an on-premises implementation.
Ideal Usage Pattern
Amazon Redshift is ideal for online analytical processing (OLAP) using your existing
business intelligence tools. Organizations are using Amazon Redshift to do the following:

Page 4 of 29
Analyze global sales data for multiple products
Store historical stock trade data
Analyze ad impressions and clicks
Aggregate gaming data
Analyze social trends
1 http://aws.amazon.com/about-aws/globalinfrastructure/
2 http://aws.amazon.com/s3/
3 http://aws.amazon.com/datapipeline/
4 http://aws.amazon.com/solutions/case-studies/big-data/

Page 4 of 29
Analyze global sales data for multiple products
Store historical stock trade data
Analyze ad impressions and clicks
Aggregate gaming data
Analyze social trends
1 http://aws.amazon.com/about-aws/globalinfrastructure/
2 http://aws.amazon.com/s3/
3 http://aws.amazon.com/datapipeline/
4 http://aws.amazon.com/solutions/case-studies/big-data/

needs without having to wait for additional hardware, or being required to over-invest to
provision enough capacity. For mission-critical applications on a more traditional
infrastructure, system designers have no choice but to over-provision, because a surge
in additional data due to an increase in business need must be something the system
can handle. By contrast, on AWS you can provision more capacity and compute in a
matter of minutes, meaning that your big data applications grow and shrink as demand
dictates, and your system runs as close to optimal efficiency as possible. In addition, you
get flexible computing on a world-class infrastructure with access to the many different
geographic regions that AWS offers 1 , along with the ability to utilize other scalable
services that Amazon offers such as Amazon Simple Storage Service (S3) 2 and AWS
Data Pipeline. 3 These capabilities of the AWS platform make it an extremely good fit for
solving big data problems. You can read about many customers that have implemented
successful big data analytics workloads on AWS on the AWS case studies web page. 4
Amazon Redshift
Amazon Redshift is a fast, fully-managed, petabyte-scale data warehouse service that
makes it simple and cost-effective to efficiently analyze all your data using your existing
business intelligence tools. 5 It is optimized for datasets ranging from a few hundred
gigabytes to a petabyte or more, and is designed to cost less than a tenth of the cost of
most traditional data warehousing solutions. Amazon Redshift delivers fast query and
I/O performance for virtually any size dataset by using columnar storage technology
while parallelizing and distributing queries across multiple nodes. As a managed service,
automation is provided for most of the common administrative tasks associated with
provisioning, configuring, monitoring, backing up, and securing a data warehouse,
making it very easy and inexpensive to manage and maintain. This automation allows
you to build a petabyte-scale data warehouse in minutes, a task that has traditionally
taken weeks, or months, to complete in an on-premises implementation.
Ideal Usage Pattern
Amazon Redshift is ideal for online analytical processing (OLAP) using your existing
business intelligence tools. Organizations are using Amazon Redshift to do the following:
needs without having to wait for additional hardware, or being required to over-invest to
provision enough capacity. For mission-critical applications on a more traditional
infrastructure, system designers have no choice but to over-provision, because a surge
in additional data due to an increase in business need must be something the system
can handle. By contrast, on AWS you can provision more capacity and compute in a
matter of minutes, meaning that your big data applications grow and shrink as demand
dictates, and your system runs as close to optimal efficiency as possible. In addition, you
get flexible computing on a world-class infrastructure with access to the many different
geographic regions that AWS offers 1 , along with the ability to utilize other scalable
services that Amazon offers such as Amazon Simple Storage Service (S3) 2 and AWS
Data Pipeline. 3 These capabilities of the AWS platform make it an extremely good fit for
solving big data problems. You can read about many customers that have implemented
successful big data analytics workloads on AWS on the AWS case studies web page. 4
Amazon Redshift
Amazon Redshift is a fast, fully-managed, petabyte-scale data warehouse service that
makes it simple and cost-effective to efficiently analyze all your data using your existing
business intelligence tools. 5 It is optimized for datasets ranging from a few hundred
gigabytes to a petabyte or more, and is designed to cost less than a tenth of the cost of
most traditional data warehousing solutions. Amazon Redshift delivers fast query and
I/O performance for virtually any size dataset by using columnar storage technology
while parallelizing and distributing queries across multiple nodes. As a managed service,
automation is provided for most of the common administrative tasks associated with
provisioning, configuring, monitoring, backing up, and securing a data warehouse,
making it very easy and inexpensive to manage and maintain. This automation allows
you to build a petabyte-scale data warehouse in minutes, a task that has traditionally
taken weeks, or months, to complete in an on-premises implementation.
Ideal Usage Pattern
Amazon Redshift is ideal for online analytical processing (OLAP) using your existing
business intelligence tools. Organizations are using Amazon Redshift to do the following:

Page 4 of 29
Analyze global sales data for multiple products
Store historical stock trade data
Analyze ad impressions and clicks
Aggregate gaming data
Analyze social trends
1 http://aws.amazon.com/about-aws/globalinfrastructure/
2 http://aws.amazon.com/s3/
3 http://aws.amazon.com/datapipeline/
4 http://aws.amazon.com/solutions/case-studies/big-data/

Page 4 of 29
Analyze global sales data for multiple products
Store historical stock trade data
Analyze ad impressions and clicks
Aggregate gaming data
Analyze social trends
1 http://aws.amazon.com/about-aws/globalinfrastructure/
2 http://aws.amazon.com/s3/
3 http://aws.amazon.com/datapipeline/
4 http://aws.amazon.com/solutions/case-studies/big-data/

needs without having to wait for additional hardware, or being required to over-invest to
provision enough capacity. For mission-critical applications on a more traditional
infrastructure, system designers have no choice but to over-provision, because a surge
in additional data due to an increase in business need must be something the system
can handle. By contrast, on AWS you can provision more capacity and compute in a
matter of minutes, meaning that your big data applications grow and shrink as demand
dictates, and your system runs as close to optimal efficiency as possible. In addition, you
get flexible computing on a world-class infrastructure with access to the many different
geographic regions that AWS offers 1 , along with the ability to utilize other scalable
services that Amazon offers such as Amazon Simple Storage Service (S3) 2 and AWS
Data Pipeline. 3 These capabilities of the AWS platform make it an extremely good fit for
solving big data problems. You can read about many customers that have implemented
successful big data analytics workloads on AWS on the AWS case studies web page. 4
Amazon Redshift
Amazon Redshift is a fast, fully-managed, petabyte-scale data warehouse service that
makes it simple and cost-effective to efficiently analyze all your data using your existing
business intelligence tools. 5 It is optimized for datasets ranging from a few hundred
gigabytes to a petabyte or more, and is designed to cost less than a tenth of the cost of
most traditional data warehousing solutions. Amazon Redshift delivers fast query and
I/O performance for virtually any size dataset by using columnar storage technology
while parallelizing and distributing queries across multiple nodes. As a managed service,
automation is provided for most of the common administrative tasks associated with
provisioning, configuring, monitoring, backing up, and securing a data warehouse,
making it very easy and inexpensive to manage and maintain. This automation allows
you to build a petabyte-scale data warehouse in minutes, a task that has traditionally
taken weeks, or months, to complete in an on-premises implementation.
Ideal Usage Pattern
Amazon Redshift is ideal for online analytical processing (OLAP) using your existing
business intelligence tools. Organizations are using Amazon Redshift to do the following:
needs without having to wait for additional hardware, or being required to over-invest to
provision enough capacity. For mission-critical applications on a more traditional
infrastructure, system designers have no choice but to over-provision, because a surge
in additional data due to an increase in business need must be something the system
can handle. By contrast, on AWS you can provision more capacity and compute in a
matter of minutes, meaning that your big data applications grow and shrink as demand
dictates, and your system runs as close to optimal efficiency as possible. In addition, you
get flexible computing on a world-class infrastructure with access to the many different
geographic regions that AWS offers 1 , along with the ability to utilize other scalable
services that Amazon offers such as Amazon Simple Storage Service (S3) 2 and AWS
Data Pipeline. 3 These capabilities of the AWS platform make it an extremely good fit for
solving big data problems. You can read about many customers that have implemented
successful big data analytics workloads on AWS on the AWS case studies web page. 4
Amazon Redshift
Amazon Redshift is a fast, fully-managed, petabyte-scale data warehouse service that
makes it simple and cost-effective to efficiently analyze all your data using your existing
business intelligence tools. 5 It is optimized for datasets ranging from a few hundred
gigabytes to a petabyte or more, and is designed to cost less than a tenth of the cost of
most traditional data warehousing solutions. Amazon Redshift delivers fast query and
I/O performance for virtually any size dataset by using columnar storage technology
while parallelizing and distributing queries across multiple nodes. As a managed service,
automation is provided for most of the common administrative tasks associated with
provisioning, configuring, monitoring, backing up, and securing a data warehouse,
making it very easy and inexpensive to manage and maintain. This automation allows
you to build a petabyte-scale data warehouse in minutes, a task that has traditionally
taken weeks, or months, to complete in an on-premises implementation.
Ideal Usage Pattern
Amazon Redshift is ideal for online analytical processing (OLAP) using your existing
business intelligence tools. Organizations are using Amazon Redshift to do the following:

Page 4 of 29
Analyze global sales data for multiple products
Store historical stock trade data
Analyze ad impressions and clicks
Aggregate gaming data
Analyze social trends
1 http://aws.amazon.com/about-aws/globalinfrastructure/
2 http://aws.amazon.com/s3/
3 http://aws.amazon.com/datapipeline/
4 http://aws.amazon.com/solutions/case-studies/big-data/

Page 4 of 29
Analyze global sales data for multiple products
Store historical stock trade data
Analyze ad impressions and clicks
Aggregate gaming data
Analyze social trends
1 http://aws.amazon.com/about-aws/globalinfrastructure/
2 http://aws.amazon.com/s3/
3 http://aws.amazon.com/datapipeline/
4 http://aws.amazon.com/solutions/case-studies/big-data/

needs without having to wait for additional hardware, or being required to over-invest to
provision enough capacity. For mission-critical applications on a more traditional
infrastructure, system designers have no choice but to over-provision, because a surge
in additional data due to an increase in business need must be something the system
can handle. By contrast, on AWS you can provision more capacity and compute in a
matter of minutes, meaning that your big data applications grow and shrink as demand
dictates, and your system runs as close to optimal efficiency as possible. In addition, you
get flexible computing on a world-class infrastructure with access to the many different
geographic regions that AWS offers 1 , along with the ability to utilize other scalable
services that Amazon offers such as Amazon Simple Storage Service (S3) 2 and AWS
Data Pipeline. 3 These capabilities of the AWS platform make it an extremely good fit for
solving big data problems. You can read about many customers that have implemented
successful big data analytics workloads on AWS on the AWS case studies web page. 4
Amazon Redshift
Amazon Redshift is a fast, fully-managed, petabyte-scale data warehouse service that
makes it simple and cost-effective to efficiently analyze all your data using your existing
business intelligence tools. 5 It is optimized for datasets ranging from a few hundred
gigabytes to a petabyte or more, and is designed to cost less than a tenth of the cost of
most traditional data warehousing solutions. Amazon Redshift delivers fast query and
I/O performance for virtually any size dataset by using columnar storage technology
while parallelizing and distributing queries across multiple nodes. As a managed service,
automation is provided for most of the common administrative tasks associated with
provisioning, configuring, monitoring, backing up, and securing a data warehouse,
making it very easy and inexpensive to manage and maintain. This automation allows
you to build a petabyte-scale data warehouse in minutes, a task that has traditionally
taken weeks, or months, to complete in an on-premises implementation.
Ideal Usage Pattern
Amazon Redshift is ideal for online analytical processing (OLAP) using your existing
business intelligence tools. Organizations are using Amazon Redshift to do the following:
needs without having to wait for additional hardware, or being required to over-invest to
provision enough capacity. For mission-critical applications on a more traditional
infrastructure, system designers have no choice but to over-provision, because a surge
in additional data due to an increase in business need must be something the system
can handle. By contrast, on AWS you can provision more capacity and compute in a
matter of minutes, meaning that your big data applications grow and shrink as demand
dictates, and your system runs as close to optimal efficiency as possible. In addition, you
get flexible computing on a world-class infrastructure with access to the many different
geographic regions that AWS offers 1 , along with the ability to utilize other scalable
services that Amazon offers such as Amazon Simple Storage Service (S3) 2 and AWS
Data Pipeline. 3 These capabilities of the AWS platform make it an extremely good fit for
solving big data problems. You can read about many customers that have implemented
successful big data analytics workloads on AWS on the AWS case studies web page. 4
Amazon Redshift
Amazon Redshift is a fast, fully-managed, petabyte-scale data warehouse service that
makes it simple and cost-effective to efficiently analyze all your data using your existing
business intelligence tools. 5 It is optimized for datasets ranging from a few hundred
gigabytes to a petabyte or more, and is designed to cost less than a tenth of the cost of
most traditional data warehousing solutions. Amazon Redshift delivers fast query and
I/O performance for virtually any size dataset by using columnar storage technology
while parallelizing and distributing queries across multiple nodes. As a managed service,
automation is provided for most of the common administrative tasks associated with
provisioning, configuring, monitoring, backing up, and securing a data warehouse,
making it very easy and inexpensive to manage and maintain. This automation allows
you to build a petabyte-scale data warehouse in minutes, a task that has traditionally
taken weeks, or months, to complete in an on-premises implementation.
Ideal Usage Pattern
Amazon Redshift is ideal for online analytical processing (OLAP) using your existing
business intelligence tools. Organizations are using Amazon Redshift to do the following:

Page 4 of 29
Analyze global sales data for multiple products
Store historical stock trade data
Analyze ad impressions and clicks
Aggregate gaming data
Analyze social trends
1 http://aws.amazon.com/about-aws/globalinfrastructure/
2 http://aws.amazon.com/s3/
3 http://aws.amazon.com/datapipeline/
4 http://aws.amazon.com/solutions/case-studies/big-data/

Page 4 of 29
Analyze global sales data for multiple products
Store historical stock trade data
Analyze ad impressions and clicks
Aggregate gaming data
Analyze social trends
1 http://aws.amazon.com/about-aws/globalinfrastructure/
2 http://aws.amazon.com/s3/
3 http://aws.amazon.com/datapipeline/
4 http://aws.amazon.com/solutions/case-studies/big-data/
needs without having to wait for additional hardware, or being required to over-invest to
provision enough capacity. For mission-critical applications on a more traditional
infrastructure, system designers have no choice but to over-provision, because a surge
in additional data due to an increase in business need must be something the system
can handle. By contrast, on AWS you can provision more capacity and compute in a
matter of minutes, meaning that your big data applications grow and shrink as demand
dictates, and your system runs as close to optimal efficiency as possible. In addition, you
get flexible computing on a world-class infrastructure with access to the many different
geographic regions that AWS offers 1 , along with the ability to utilize other scalable
services that Amazon offers such as Amazon Simple Storage Service (S3) 2 and AWS
Data Pipeline. 3 These capabilities of the AWS platform make it an extremely good fit for
solving big data problems. You can read about many customers that have implemented
successful big data analytics workloads on AWS on the AWS case studies web page. 4
Amazon Redshift
Amazon Redshift is a fast, fully-managed, petabyte-scale data warehouse service that
makes it simple and cost-effective to efficiently analyze all your data using your existing
business intelligence tools. 5 It is optimized for datasets ranging from a few hundred
gigabytes to a petabyte or more, and is designed to cost less than a tenth of the cost of
most traditional data warehousing solutions. Amazon Redshift delivers fast query and
I/O performance for virtually any size dataset by using columnar storage technology
while parallelizing and distributing queries across multiple nodes. As a managed service,
automation is provided for most of the common administrative tasks associated with
provisioning, configuring, monitoring, backing up, and securing a data warehouse,
making it very easy and inexpensive to manage and maintain. This automation allows
you to build a petabyte-scale data warehouse in minutes, a task that has traditionally
taken weeks, or months, to complete in an on-premises implementation.
Ideal Usage Pattern
Amazon Redshift is ideal for online analytical processing (OLAP) using your existing
business intelligence tools. Organizations are using Amazon Redshift to do the following:
needs without having to wait for additional hardware, or being required to over-invest to
provision enough capacity. For mission-critical applications on a more traditional
infrastructure, system designers have no choice but to over-provision, because a surge
in additional data due to an increase in business need must be something the system
can handle. By contrast, on AWS you can provision more capacity and compute in a
matter of minutes, meaning that your big data applications grow and shrink as demand
dictates, and your system runs as close to optimal efficiency as possible. In addition, you
get flexible computing on a world-class infrastructure with access to the many different
geographic regions that AWS offers 1 , along with the ability to utilize other scalable
services that Amazon offers such as Amazon Simple Storage Service (S3) 2 and AWS
Data Pipeline. 3 These capabilities of the AWS platform make it an extremely good fit for
solving big data problems. You can read about many customers that have implemented
successful big data analytics workloads on AWS on the AWS case studies web page. 4
Amazon Redshift
Amazon Redshift is a fast, fully-managed, petabyte-scale data warehouse service that
makes it simple and cost-effective to efficiently analyze all your data using your existing
business intelligence tools. 5 It is optimized for datasets ranging from a few hundred
gigabytes to a petabyte or more, and is designed to cost less than a tenth of the cost of
most traditional data warehousing solutions. Amazon Redshift delivers fast query and
I/O performance for virtually any size dataset by using columnar storage technology
while parallelizing and distributing queries across multiple nodes. As a managed service,
automation is provided for most of the common administrative tasks associated with
provisioning, configuring, monitoring, backing up, and securing a data warehouse,
making it very easy and inexpensive to manage and maintain. This automation allows
you to build a petabyte-scale data warehouse in minutes, a task that has traditionally
taken weeks, or months, to complete in an on-premises implementation.
Ideal Usage Pattern
Amazon Redshift is ideal for online analytical processing (OLAP) using your existing
business intelligence tools. Organizations are using Amazon Redshift to do the following:

Page 4 of 29
Analyze global sales data for multiple products
Store historical stock trade data
Analyze ad impressions and clicks
Aggregate gaming data
Analyze social trends
1 http://aws.amazon.com/about-aws/globalinfrastructure/
2 http://aws.amazon.com/s3/
3 http://aws.amazon.com/datapipeline/
4 http://aws.amazon.com/solutions/case-studies/big-data/

Page 4 of 29
Analyze global sales data for multiple products
Store historical stock trade data
Analyze ad impressions and clicks
Aggregate gaming data
Analyze social trends
1 http://aws.amazon.com/about-aws/globalinfrastructure/
2 http://aws.amazon.com/s3/
3 http://aws.amazon.com/datapipeline/
4 http://aws.amazon.com/solutions/case-studies/big-data/
needs without having to wait for additional hardware, or being required to over-invest to
provision enough capacity. For mission-critical applications on a more traditional
infrastructure, system designers have no choice but to over-provision, because a surge
in additional data due to an increase in business need must be something the system
can handle. By contrast, on AWS you can provision more capacity and compute in a
matter of minutes, meaning that your big data applications grow and shrink as demand
dictates, and your system runs as close to optimal efficiency as possible. In addition, you
get flexible computing on a world-class infrastructure with access to the many different
geographic regions that AWS offers 1 , along with the ability to utilize other scalable
services that Amazon offers such as Amazon Simple Storage Service (S3) 2 and AWS
Data Pipeline. 3 These capabilities of the AWS platform make it an extremely good fit for
solving big data problems. You can read about many customers that have implemented
successful big data analytics workloads on AWS on the AWS case studies web page. 4
Amazon Redshift
Amazon Redshift is a fast, fully-managed, petabyte-scale data warehouse service that
makes it simple and cost-effective to efficiently analyze all your data using your existing
business intelligence tools. 5 It is optimized for datasets ranging from a few hundred
gigabytes to a petabyte or more, and is designed to cost less than a tenth of the cost of
most traditional data warehousing solutions. Amazon Redshift delivers fast query and
I/O performance for virtually any size dataset by using columnar storage technology
while parallelizing and distributing queries across multiple nodes. As a managed service,
automation is provided for most of the common administrative tasks associated with
provisioning, configuring, monitoring, backing up, and securing a data warehouse,
making it very easy and inexpensive to manage and maintain. This automation allows
you to build a petabyte-scale data warehouse in minutes, a task that has traditionally
taken weeks, or months, to complete in an on-premises implementation.
Ideal Usage Pattern
Amazon Redshift is ideal for online analytical processing (OLAP) using your existing
business intelligence tools. Organizations are using Amazon Redshift to do the following:
needs without having to wait for additional hardware, or being required to over-invest to
provision enough capacity. For mission-critical applications on a more traditional
infrastructure, system designers have no choice but to over-provision, because a surge
in additional data due to an increase in business need must be something the system
can handle. By contrast, on AWS you can provision more capacity and compute in a
matter of minutes, meaning that your big data applications grow and shrink as demand
dictates, and your system runs as close to optimal efficiency as possible. In addition, you
get flexible computing on a world-class infrastructure with access to the many different
geographic regions that AWS offers 1 , along with the ability to utilize other scalable
services that Amazon offers such as Amazon Simple Storage Service (S3) 2 and AWS
Data Pipeline. 3 These capabilities of the AWS platform make it an extremely good fit for
solving big data problems. You can read about many customers that have implemented
successful big data analytics workloads on AWS on the AWS case studies web page. 4
Amazon Redshift
Amazon Redshift is a fast, fully-managed, petabyte-scale data warehouse service that
makes it simple and cost-effective to efficiently analyze all your data using your existing
business intelligence tools. 5 It is optimized for datasets ranging from a few hundred
gigabytes to a petabyte or more, and is designed to cost less than a tenth of the cost of
most traditional data warehousing solutions. Amazon Redshift delivers fast query and
I/O performance for virtually any size dataset by using columnar storage technology
while parallelizing and distributing queries across multiple nodes. As a managed service,
automation is provided for most of the common administrative tasks associated with
provisioning, configuring, monitoring, backing up, and securing a data warehouse,
making it very easy and inexpensive to manage and maintain. This automation allows
you to build a petabyte-scale data warehouse in minutes, a task that has traditionally
taken weeks, or months, to complete in an on-premises implementation.
Ideal Usage Pattern
Amazon Redshift is ideal for online analytical processing (OLAP) using your existing
business intelligence tools. Organizations are using Amazon Redshift to do the following:

Page 4 of 29
Analyze global sales data for multiple products
Store historical stock trade data
Analyze ad impressions and clicks
Aggregate gaming data
Analyze social trends
1 http://aws.amazon.com/about-aws/globalinfrastructure/
2 http://aws.amazon.com/s3/
3 http://aws.amazon.com/datapipeline/
4 http://aws.amazon.com/solutions/case-studies/big-data/

Page 4 of 29
Analyze global sales data for multiple products
Store historical stock trade data
Analyze ad impressions and clicks
Aggregate gaming data
Analyze social trends
1 http://aws.amazon.com/about-aws/globalinfrastructure/
2 http://aws.amazon.com/s3/
3 http://aws.amazon.com/datapipeline/
4 http://aws.amazon.com/solutions/case-studies/big-data/

needs without having to wait for additional hardware, or being required to over-invest to
provision enough capacity. For mission-critical applications on a more traditional
infrastructure, system designers have no choice but to over-provision, because a surge
in additional data due to an increase in business need must be something the system
can handle. By contrast, on AWS you can provision more capacity and compute in a
matter of minutes, meaning that your big data applications grow and shrink as demand
dictates, and your system runs as close to optimal efficiency as possible. In addition, you
get flexible computing on a world-class infrastructure with access to the many different
geographic regions that AWS offers 1 , along with the ability to utilize other scalable
services that Amazon offers such as Amazon Simple Storage Service (S3) 2 and AWS
Data Pipeline. 3 These capabilities of the AWS platform make it an extremely good fit for
solving big data problems. You can read about many customers that have implemented
successful big data analytics workloads on AWS on the AWS case studies web page. 4
Amazon Redshift
Amazon Redshift is a fast, fully-managed, petabyte-scale data warehouse service that
makes it simple and cost-effective to efficiently analyze all your data using your existing
business intelligence tools. 5 It is optimized for datasets ranging from a few hundred
gigabytes to a petabyte or more, and is designed to cost less than a tenth of the cost of
most traditional data warehousing solutions. Amazon Redshift delivers fast query and
I/O performance for virtually any size dataset by using columnar storage technology
while parallelizing and distributing queries across multiple nodes. As a managed service,
automation is provided for most of the common administrative tasks associated with
provisioning, configuring, monitoring, backing up, and securing a data warehouse,
making it very easy and inexpensive to manage and maintain. This automation allows
you to build a petabyte-scale data warehouse in minutes, a task that has traditionally
taken weeks, or months, to complete in an on-premises implementation.
Ideal Usage Pattern
Amazon Redshift is ideal for online analytical processing (OLAP) using your existing
business intelligence tools. Organizations are using Amazon Redshift to do the following:
needs without having to wait for additional hardware, or being required to over-invest to
provision enough capacity. For mission-critical applications on a more traditional
infrastructure, system designers have no choice but to over-provision, because a surge
in additional data due to an increase in business need must be something the system
can handle. By contrast, on AWS you can provision more capacity and compute in a
matter of minutes, meaning that your big data applications grow and shrink as demand
dictates, and your system runs as close to optimal efficiency as possible. In addition, you
get flexible computing on a world-class infrastructure with access to the many different
geographic regions that AWS offers 1 , along with the ability to utilize other scalable
services that Amazon offers such as Amazon Simple Storage Service (S3) 2 and AWS
Data Pipeline. 3 These capabilities of the AWS platform make it an extremely good fit for
solving big data problems. You can read about many customers that have implemented
successful big data analytics workloads on AWS on the AWS case studies web page. 4
Amazon Redshift
Amazon Redshift is a fast, fully-managed, petabyte-scale data warehouse service that
makes it simple and cost-effective to efficiently analyze all your data using your existing
business intelligence tools. 5 It is optimized for datasets ranging from a few hundred
gigabytes to a petabyte or more, and is designed to cost less than a tenth of the cost of
most traditional data warehousing solutions. Amazon Redshift delivers fast query and
I/O performance for virtually any size dataset by using columnar storage technology
while parallelizing and distributing queries across multiple nodes. As a managed service,
automation is provided for most of the common administrative tasks associated with
provisioning, configuring, monitoring, backing up, and securing a data warehouse,
making it very easy and inexpensive to manage and maintain. This automation allows
you to build a petabyte-scale data warehouse in minutes, a task that has traditionally
taken weeks, or months, to complete in an on-premises implementation.
Ideal Usage Pattern
Amazon Redshift is ideal for online analytical processing (OLAP) using your existing
business intelligence tools. Organizations are using Amazon Redshift to do the following:

Page 4 of 29
Analyze global sales data for multiple products
Store historical stock trade data
Analyze ad impressions and clicks
Aggregate gaming data
Analyze social trends
1 http://aws.amazon.com/about-aws/globalinfrastructure/
2 http://aws.amazon.com/s3/
3 http://aws.amazon.com/datapipeline/
4 http://aws.amazon.com/solutions/case-studies/big-data/

Page 4 of 29
Analyze global sales data for multiple products
Store historical stock trade data
Analyze ad impressions and clicks
Aggregate gaming data
Analyze social trends
1 http://aws.amazon.com/about-aws/globalinfrastructure/
2 http://aws.amazon.com/s3/
3 http://aws.amazon.com/datapipeline/
4 http://aws.amazon.com/solutions/case-studies/big-data/

needs without having to wait for additional hardware, or being required to over-invest to
provision enough capacity. For mission-critical applications on a more traditional
infrastructure, system designers have no choice but to over-provision, because a surge
in additional data due to an increase in business need must be something the system
can handle. By contrast, on AWS you can provision more capacity and compute in a
matter of minutes, meaning that your big data applications grow and shrink as demand
dictates, and your system runs as close to optimal efficiency as possible. In addition, you
get flexible computing on a world-class infrastructure with access to the many different
geographic regions that AWS offers 1 , along with the ability to utilize other scalable
services that Amazon offers such as Amazon Simple Storage Service (S3) 2 and AWS
Data Pipeline. 3 These capabilities of the AWS platform make it an extremely good fit for
solving big data problems. You can read about many customers that have implemented
successful big data analytics workloads on AWS on the AWS case studies web page. 4
Amazon Redshift
Amazon Redshift is a fast, fully-managed, petabyte-scale data warehouse service that
makes it simple and cost-effective to efficiently analyze all your data using your existing
business intelligence tools. 5 It is optimized for datasets ranging from a few hundred
gigabytes to a petabyte or more, and is designed to cost less than a tenth of the cost of
most traditional data warehousing solutions. Amazon Redshift delivers fast query and
I/O performance for virtually any size dataset by using columnar storage technology
while parallelizing and distributing queries across multiple nodes. As a managed service,
automation is provided for most of the common administrative tasks associated with
provisioning, configuring, monitoring, backing up, and securing a data warehouse,
making it very easy and inexpensive to manage and maintain. This automation allows
you to build a petabyte-scale data warehouse in minutes, a task that has traditionally
taken weeks, or months, to complete in an on-premises implementation.
Ideal Usage Pattern
Amazon Redshift is ideal for online analytical processing (OLAP) using your existing
business intelligence tools. Organizations are using Amazon Redshift to do the following:
needs without having to wait for additional hardware, or being required to over-invest to
provision enough capacity. For mission-critical applications on a more traditional
infrastructure, system designers have no choice but to over-provision, because a surge
in additional data due to an increase in business need must be something the system
can handle. By contrast, on AWS you can provision more capacity and compute in a
matter of minutes, meaning that your big data applications grow and shrink as demand
dictates, and your system runs as close to optimal efficiency as possible. In addition, you
get flexible computing on a world-class infrastructure with access to the many different
geographic regions that AWS offers 1 , along with the ability to utilize other scalable
services that Amazon offers such as Amazon Simple Storage Service (S3) 2 and AWS
Data Pipeline. 3 These capabilities of the AWS platform make it an extremely good fit for
solving big data problems. You can read about many customers that have implemented
successful big data analytics workloads on AWS on the AWS case studies web page. 4
Amazon Redshift
Amazon Redshift is a fast, fully-managed, petabyte-scale data warehouse service that
makes it simple and cost-effective to efficiently analyze all your data using your existing
business intelligence tools. 5 It is optimized for datasets ranging from a few hundred
gigabytes to a petabyte or more, and is designed to cost less than a tenth of the cost of
most traditional data warehousing solutions. Amazon Redshift delivers fast query and
I/O performance for virtually any size dataset by using columnar storage technology
while parallelizing and distributing queries across multiple nodes. As a managed service,
automation is provided for most of the common administrative tasks associated with
provisioning, configuring, monitoring, backing up, and securing a data warehouse,
making it very easy and inexpensive to manage and maintain. This automation allows
you to build a petabyte-scale data warehouse in minutes, a task that has traditionally
taken weeks, or months, to complete in an on-premises implementation.
Ideal Usage Pattern
Amazon Redshift is ideal for online analytical processing (OLAP) using your existing
business intelligence tools. Organizations are using Amazon Redshift to do the following:

Page 4 of 29
Analyze global sales data for multiple products
Store historical stock trade data
Analyze ad impressions and clicks
Aggregate gaming data
Analyze social trends
1 http://aws.amazon.com/about-aws/globalinfrastructure/
2 http://aws.amazon.com/s3/
3 http://aws.amazon.com/datapipeline/
4 http://aws.amazon.com/solutions/case-studies/big-data/

Page 4 of 29
Analyze global sales data for multiple products
Store historical stock trade data
Analyze ad impressions and clicks
Aggregate gaming data
Analyze social trends
1 http://aws.amazon.com/about-aws/globalinfrastructure/
2 http://aws.amazon.com/s3/
3 http://aws.amazon.com/datapipeline/
4 http://aws.amazon.com/solutions/case-studies/big-data/

needs without having to wait for additional hardware, or being required to over-invest to
provision enough capacity. For mission-critical applications on a more traditional
infrastructure, system designers have no choice but to over-provision, because a surge
in additional data due to an increase in business need must be something the system
can handle. By contrast, on AWS you can provision more capacity and compute in a
matter of minutes, meaning that your big data applications grow and shrink as demand
dictates, and your system runs as close to optimal efficiency as possible. In addition, you
get flexible computing on a world-class infrastructure with access to the many different
geographic regions that AWS offers 1 , along with the ability to utilize other scalable
services that Amazon offers such as Amazon Simple Storage Service (S3) 2 and AWS
Data Pipeline. 3 These capabilities of the AWS platform make it an extremely good fit for
solving big data problems. You can read about many customers that have implemented
successful big data analytics workloads on AWS on the AWS case studies web page. 4
Amazon Redshift
Amazon Redshift is a fast, fully-managed, petabyte-scale data warehouse service that
makes it simple and cost-effective to efficiently analyze all your data using your existing
business intelligence tools. 5 It is optimized for datasets ranging from a few hundred
gigabytes to a petabyte or more, and is designed to cost less than a tenth of the cost of
most traditional data warehousing solutions. Amazon Redshift delivers fast query and
I/O performance for virtually any size dataset by using columnar storage technology
while parallelizing and distributing queries across multiple nodes. As a managed service,
automation is provided for most of the common administrative tasks associated with
provisioning, configuring, monitoring, backing up, and securing a data warehouse,
making it very easy and inexpensive to manage and maintain. This automation allows
you to build a petabyte-scale data warehouse in minutes, a task that has traditionally
taken weeks, or months, to complete in an on-premises implementation.
Ideal Usage Pattern
Amazon Redshift is ideal for online analytical processing (OLAP) using your existing
business intelligence tools. Organizations are using Amazon Redshift to do the following:
needs without having to wait for additional hardware, or being required to over-invest to
provision enough capacity. For mission-critical applications on a more traditional
infrastructure, system designers have no choice but to over-provision, because a surge
in additional data due to an increase in business need must be something the system
can handle. By contrast, on AWS you can provision more capacity and compute in a
matter of minutes, meaning that your big data applications grow and shrink as demand
dictates, and your system runs as close to optimal efficiency as possible. In addition, you
get flexible computing on a world-class infrastructure with access to the many different
geographic regions that AWS offers 1 , along with the ability to utilize other scalable
services that Amazon offers such as Amazon Simple Storage Service (S3) 2 and AWS
Data Pipeline. 3 These capabilities of the AWS platform make it an extremely good fit for
solving big data problems. You can read about many customers that have implemented
successful big data analytics workloads on AWS on the AWS case studies web page. 4
Amazon Redshift
Amazon Redshift is a fast, fully-managed, petabyte-scale data warehouse service that
makes it simple and cost-effective to efficiently analyze all your data using your existing
business intelligence tools. 5 It is optimized for datasets ranging from a few hundred
gigabytes to a petabyte or more, and is designed to cost less than a tenth of the cost of
most traditional data warehousing solutions. Amazon Redshift delivers fast query and
I/O performance for virtually any size dataset by using columnar storage technology
while parallelizing and distributing queries across multiple nodes. As a managed service,
automation is provided for most of the common administrative tasks associated with
provisioning, configuring, monitoring, backing up, and securing a data warehouse,
making it very easy and inexpensive to manage and maintain. This automation allows
you to build a petabyte-scale data warehouse in minutes, a task that has traditionally
taken weeks, or months, to complete in an on-premises implementation.
Ideal Usage Pattern
Amazon Redshift is ideal for online analytical processing (OLAP) using your existing
business intelligence tools. Organizations are using Amazon Redshift to do the following:

Page 4 of 29
Analyze global sales data for multiple products
Store historical stock trade data
Analyze ad impressions and clicks
Aggregate gaming data
Analyze social trends
1 http://aws.amazon.com/about-aws/globalinfrastructure/
2 http://aws.amazon.com/s3/
3 http://aws.amazon.com/datapipeline/
4 http://aws.amazon.com/solutions/case-studies/big-data/

Page 4 of 29
Analyze global sales data for multiple products
Store historical stock trade data
Analyze ad impressions and clicks
Aggregate gaming data
Analyze social trends
1 http://aws.amazon.com/about-aws/globalinfrastructure/
2 http://aws.amazon.com/s3/
3 http://aws.amazon.com/datapipeline/
4 http://aws.amazon.com/solutions/case-studies/big-data/

needs without having to wait for additional hardware, or being required to over-invest to
provision enough capacity. For mission-critical applications on a more traditional
infrastructure, system designers have no choice but to over-provision, because a surge
in additional data due to an increase in business need must be something the system
can handle. By contrast, on AWS you can provision more capacity and compute in a
matter of minutes, meaning that your big data applications grow and shrink as demand
dictates, and your system runs as close to optimal efficiency as possible. In addition, you
get flexible computing on a world-class infrastructure with access to the many different
geographic regions that AWS offers 1 , along with the ability to utilize other scalable
services that Amazon offers such as Amazon Simple Storage Service (S3) 2 and AWS
Data Pipeline. 3 These capabilities of the AWS platform make it an extremely good fit for
solving big data problems. You can read about many customers that have implemented
successful big data analytics workloads on AWS on the AWS case studies web page. 4
Amazon Redshift
Amazon Redshift is a fast, fully-managed, petabyte-scale data warehouse service that
makes it simple and cost-effective to efficiently analyze all your data using your existing
business intelligence tools. 5 It is optimized for datasets ranging from a few hundred
gigabytes to a petabyte or more, and is designed to cost less than a tenth of the cost of
most traditional data warehousing solutions. Amazon Redshift delivers fast query and
I/O performance for virtually any size dataset by using columnar storage technology
while parallelizing and distributing queries across multiple nodes. As a managed service,
automation is provided for most of the common administrative tasks associated with
provisioning, configuring, monitoring, backing up, and securing a data warehouse,
making it very easy and inexpensive to manage and maintain. This automation allows
you to build a petabyte-scale data warehouse in minutes, a task that has traditionally
taken weeks, or months, to complete in an on-premises implementation.
Ideal Usage Pattern
Amazon Redshift is ideal for online analytical processing (OLAP) using your existing
business intelligence tools. Organizations are using Amazon Redshift to do the following:
needs without having to wait for additional hardware, or being required to over-invest to
provision enough capacity. For mission-critical applications on a more traditional
infrastructure, system designers have no choice but to over-provision, because a surge
in additional data due to an increase in business need must be something the system
can handle. By contrast, on AWS you can provision more capacity and compute in a
matter of minutes, meaning that your big data applications grow and shrink as demand
dictates, and your system runs as close to optimal efficiency as possible. In addition, you
get flexible computing on a world-class infrastructure with access to the many different
geographic regions that AWS offers 1 , along with the ability to utilize other scalable
services that Amazon offers such as Amazon Simple Storage Service (S3) 2 and AWS
Data Pipeline. 3 These capabilities of the AWS platform make it an extremely good fit for
solving big data problems. You can read about many customers that have implemented
successful big data analytics workloads on AWS on the AWS case studies web page. 4
Amazon Redshift
Amazon Redshift is a fast, fully-managed, petabyte-scale data warehouse service that
makes it simple and cost-effective to efficiently analyze all your data using your existing
business intelligence tools. 5 It is optimized for datasets ranging from a few hundred
gigabytes to a petabyte or more, and is designed to cost less than a tenth of the cost of
most traditional data warehousing solutions. Amazon Redshift delivers fast query and
I/O performance for virtually any size dataset by using columnar storage technology
while parallelizing and distributing queries across multiple nodes. As a managed service,
automation is provided for most of the common administrative tasks associated with
provisioning, configuring, monitoring, backing up, and securing a data warehouse,
making it very easy and inexpensive to manage and maintain. This automation allows
you to build a petabyte-scale data warehouse in minutes, a task that has traditionally
taken weeks, or months, to complete in an on-premises implementation.
Ideal Usage Pattern
Amazon Redshift is ideal for online analytical processing (OLAP) using your existing
business intelligence tools. Organizations are using Amazon Redshift to do the following:

Page 4 of 29
Analyze global sales data for multiple products
Store historical stock trade data
Analyze ad impressions and clicks
Aggregate gaming data
Analyze social trends
1 http://aws.amazon.com/about-aws/globalinfrastructure/
2 http://aws.amazon.com/s3/
3 http://aws.amazon.com/datapipeline/
4 http://aws.amazon.com/solutions/case-studies/big-data/

Page 4 of 29
Analyze global sales data for multiple products
Store historical stock trade data
Analyze ad impressions and clicks
Aggregate gaming data
Analyze social trends
1 http://aws.amazon.com/about-aws/globalinfrastructure/
2 http://aws.amazon.com/s3/
3 http://aws.amazon.com/datapipeline/
4 http://aws.amazon.com/solutions/case-studies/big-data/

needs without having to wait for additional hardware, or being required to over-invest to
provision enough capacity. For mission-critical applications on a more traditional
infrastructure, system designers have no choice but to over-provision, because a surge
in additional data due to an increase in business need must be something the system
can handle. By contrast, on AWS you can provision more capacity and compute in a
matter of minutes, meaning that your big data applications grow and shrink as demand
dictates, and your system runs as close to optimal efficiency as possible. In addition, you
get flexible computing on a world-class infrastructure with access to the many different
geographic regions that AWS offers 1 , along with the ability to utilize other scalable
services that Amazon offers such as Amazon Simple Storage Service (S3) 2 and AWS
Data Pipeline. 3 These capabilities of the AWS platform make it an extremely good fit for
solving big data problems. You can read about many customers that have implemented
successful big data analytics workloads on AWS on the AWS case studies web page. 4
Amazon Redshift
Amazon Redshift is a fast, fully-managed, petabyte-scale data warehouse service that
makes it simple and cost-effective to efficiently analyze all your data using your existing
business intelligence tools. 5 It is optimized for datasets ranging from a few hundred
gigabytes to a petabyte or more, and is designed to cost less than a tenth of the cost of
most traditional data warehousing solutions. Amazon Redshift delivers fast query and
I/O performance for virtually any size dataset by using columnar storage technology
while parallelizing and distributing queries across multiple nodes. As a managed service,
automation is provided for most of the common administrative tasks associated with
provisioning, configuring, monitoring, backing up, and securing a data warehouse,
making it very easy and inexpensive to manage and maintain. This automation allows
you to build a petabyte-scale data warehouse in minutes, a task that has traditionally
taken weeks, or months, to complete in an on-premises implementation.
Ideal Usage Pattern
Amazon Redshift is ideal for online analytical processing (OLAP) using your existing
business intelligence tools. Organizations are using Amazon Redshift to do the following:
needs without having to wait for additional hardware, or being required to over-invest to
provision enough capacity. For mission-critical applications on a more traditional
infrastructure, system designers have no choice but to over-provision, because a surge
in additional data due to an increase in business need must be something the system
can handle. By contrast, on AWS you can provision more capacity and compute in a
matter of minutes, meaning that your big data applications grow and shrink as demand
dictates, and your system runs as close to optimal efficiency as possible. In addition, you
get flexible computing on a world-class infrastructure with access to the many different
geographic regions that AWS offers 1 , along with the ability to utilize other scalable
services that Amazon offers such as Amazon Simple Storage Service (S3) 2 and AWS
Data Pipeline. 3 These capabilities of the AWS platform make it an extremely good fit for
solving big data problems. You can read about many customers that have implemented
successful big data analytics workloads on AWS on the AWS case studies web page. 4
Amazon Redshift
Amazon Redshift is a fast, fully-managed, petabyte-scale data warehouse service that
makes it simple and cost-effective to efficiently analyze all your data using your existing
business intelligence tools. 5 It is optimized for datasets ranging from a few hundred
gigabytes to a petabyte or more, and is designed to cost less than a tenth of the cost of
most traditional data warehousing solutions. Amazon Redshift delivers fast query and
I/O performance for virtually any size dataset by using columnar storage technology
while parallelizing and distributing queries across multiple nodes. As a managed service,
automation is provided for most of the common administrative tasks associated with
provisioning, configuring, monitoring, backing up, and securing a data warehouse,
making it very easy and inexpensive to manage and maintain. This automation allows
you to build a petabyte-scale data warehouse in minutes, a task that has traditionally
taken weeks, or months, to complete in an on-premises implementation.
Ideal Usage Pattern
Amazon Redshift is ideal for online analytical processing (OLAP) using your existing
business intelligence tools. Organizations are using Amazon Redshift to do the following:

Page 4 of 29
Analyze global sales data for multiple products
Store historical stock trade data
Analyze ad impressions and clicks
Aggregate gaming data
Analyze social trends
1 http://aws.amazon.com/about-aws/globalinfrastructure/
2 http://aws.amazon.com/s3/
3 http://aws.amazon.com/datapipeline/
4 http://aws.amazon.com/solutions/case-studies/big-data/

Page 4 of 29
Analyze global sales data for multiple products
Store historical stock trade data
Analyze ad impressions and clicks
Aggregate gaming data
Analyze social trends
1 http://aws.amazon.com/about-aws/globalinfrastructure/
2 http://aws.amazon.com/s3/
3 http://aws.amazon.com/datapipeline/
4 http://aws.amazon.com/solutions/case-studies/big-data/

needs without having to wait for additional hardware, or being required to over-invest to
provision enough capacity. For mission-critical applications on a more traditional
infrastructure, system designers have no choice but to over-provision, because a surge
in additional data due to an increase in business need must be something the system
can handle. By contrast, on AWS you can provision more capacity and compute in a
matter of minutes, meaning that your big data applications grow and shrink as demand
dictates, and your system runs as close to optimal efficiency as possible. In addition, you
get flexible computing on a world-class infrastructure with access to the many different
geographic regions that AWS offers 1 , along with the ability to utilize other scalable
services that Amazon offers such as Amazon Simple Storage Service (S3) 2 and AWS
Data Pipeline. 3 These capabilities of the AWS platform make it an extremely good fit for
solving big data problems. You can read about many customers that have implemented
successful big data analytics workloads on AWS on the AWS case studies web page. 4
Amazon Redshift
Amazon Redshift is a fast, fully-managed, petabyte-scale data warehouse service that
makes it simple and cost-effective to efficiently analyze all your data using your existing
business intelligence tools. 5 It is optimized for datasets ranging from a few hundred
gigabytes to a petabyte or more, and is designed to cost less than a tenth of the cost of
most traditional data warehousing solutions. Amazon Redshift delivers fast query and
I/O performance for virtually any size dataset by using columnar storage technology
while parallelizing and distributing queries across multiple nodes. As a managed service,
automation is provided for most of the common administrative tasks associated with
provisioning, configuring, monitoring, backing up, and securing a data warehouse,
making it very easy and inexpensive to manage and maintain. This automation allows
you to build a petabyte-scale data warehouse in minutes, a task that has traditionally
taken weeks, or months, to complete in an on-premises implementation.
Ideal Usage Pattern
Amazon Redshift is ideal for online analytical processing (OLAP) using your existing
business intelligence tools. Organizations are using Amazon Redshift to do the following:
needs without having to wait for additional hardware, or being required to over-invest to
provision enough capacity. For mission-critical applications on a more traditional
infrastructure, system designers have no choice but to over-provision, because a surge
in additional data due to an increase in business need must be something the system
can handle. By contrast, on AWS you can provision more capacity and compute in a
matter of minutes, meaning that your big data applications grow and shrink as demand
dictates, and your system runs as close to optimal efficiency as possible. In addition, you
get flexible computing on a world-class infrastructure with access to the many different
geographic regions that AWS offers 1 , along with the ability to utilize other scalable
services that Amazon offers such as Amazon Simple Storage Service (S3) 2 and AWS
Data Pipeline. 3 These capabilities of the AWS platform make it an extremely good fit for
solving big data problems. You can read about many customers that have implemented
successful big data analytics workloads on AWS on the AWS case studies web page. 4
Amazon Redshift
Amazon Redshift is a fast, fully-managed, petabyte-scale data warehouse service that
makes it simple and cost-effective to efficiently analyze all your data using your existing
business intelligence tools. 5 It is optimized for datasets ranging from a few hundred
gigabytes to a petabyte or more, and is designed to cost less than a tenth of the cost of
most traditional data warehousing solutions. Amazon Redshift delivers fast query and
I/O performance for virtually any size dataset by using columnar storage technology
while parallelizing and distributing queries across multiple nodes. As a managed service,
automation is provided for most of the common administrative tasks associated with
provisioning, configuring, monitoring, backing up, and securing a data warehouse,
making it very easy and inexpensive to manage and maintain. This automation allows
you to build a petabyte-scale data warehouse in minutes, a task that has traditionally
taken weeks, or months, to complete in an on-premises implementation.
Ideal Usage Pattern
Amazon Redshift is ideal for online analytical processing (OLAP) using your existing
business intelligence tools. Organizations are using Amazon Redshift to do the following:

Page 4 of 29
Analyze global sales data for multiple products
Store historical stock trade data
Analyze ad impressions and clicks
Aggregate gaming data
Analyze social trends
1 http://aws.amazon.com/about-aws/globalinfrastructure/
2 http://aws.amazon.com/s3/
3 http://aws.amazon.com/datapipeline/
4 http://aws.amazon.com/solutions/case-studies/big-data/

Page 4 of 29
Analyze global sales data for multiple products
Store historical stock trade data
Analyze ad impressions and clicks
Aggregate gaming data
Analyze social trends
1 http://aws.amazon.com/about-aws/globalinfrastructure/
2 http://aws.amazon.com/s3/
3 http://aws.amazon.com/datapipeline/
4 http://aws.amazon.com/solutions/case-studies/big-data/

needs without having to wait for additional hardware, or being required to over-invest to
provision enough capacity. For mission-critical applications on a more traditional
infrastructure, system designers have no choice but to over-provision, because a surge
in additional data due to an increase in business need must be something the system
can handle. By contrast, on AWS you can provision more capacity and compute in a
matter of minutes, meaning that your big data applications grow and shrink as demand
dictates, and your system runs as close to optimal efficiency as possible. In addition, you
get flexible computing on a world-class infrastructure with access to the many different
geographic regions that AWS offers 1 , along with the ability to utilize other scalable
services that Amazon offers such as Amazon Simple Storage Service (S3) 2 and AWS
Data Pipeline. 3 These capabilities of the AWS platform make it an extremely good fit for
solving big data problems. You can read about many customers that have implemented
successful big data analytics workloads on AWS on the AWS case studies web page. 4
Amazon Redshift
Amazon Redshift is a fast, fully-managed, petabyte-scale data warehouse service that
makes it simple and cost-effective to efficiently analyze all your data using your existing
business intelligence tools. 5 It is optimized for datasets ranging from a few hundred
gigabytes to a petabyte or more, and is designed to cost less than a tenth of the cost of
most traditional data warehousing solutions. Amazon Redshift delivers fast query and
I/O performance for virtually any size dataset by using columnar storage technology
while parallelizing and distributing queries across multiple nodes. As a managed service,
automation is provided for most of the common administrative tasks associated with
provisioning, configuring, monitoring, backing up, and securing a data warehouse,
making it very easy and inexpensive to manage and maintain. This automation allows
you to build a petabyte-scale data warehouse in minutes, a task that has traditionally
taken weeks, or months, to complete in an on-premises implementation.
Ideal Usage Pattern
Amazon Redshift is ideal for online analytical processing (OLAP) using your existing
business intelligence tools. Organizations are using Amazon Redshift to do the following:
needs without having to wait for additional hardware, or being required to over-invest to
provision enough capacity. For mission-critical applications on a more traditional
infrastructure, system designers have no choice but to over-provision, because a surge
in additional data due to an increase in business need must be something the system
can handle. By contrast, on AWS you can provision more capacity and compute in a
matter of minutes, meaning that your big data applications grow and shrink as demand
dictates, and your system runs as close to optimal efficiency as possible. In addition, you
get flexible computing on a world-class infrastructure with access to the many different
geographic regions that AWS offers 1 , along with the ability to utilize other scalable
services that Amazon offers such as Amazon Simple Storage Service (S3) 2 and AWS
Data Pipeline. 3 These capabilities of the AWS platform make it an extremely good fit for
solving big data problems. You can read about many customers that have implemented
successful big data analytics workloads on AWS on the AWS case studies web page. 4
Amazon Redshift
Amazon Redshift is a fast, fully-managed, petabyte-scale data warehouse service that
makes it simple and cost-effective to efficiently analyze all your data using your existing
business intelligence tools. 5 It is optimized for datasets ranging from a few hundred
gigabytes to a petabyte or more, and is designed to cost less than a tenth of the cost of
most traditional data warehousing solutions. Amazon Redshift delivers fast query and
I/O performance for virtually any size dataset by using columnar storage technology
while parallelizing and distributing queries across multiple nodes. As a managed service,
automation is provided for most of the common administrative tasks associated with
provisioning, configuring, monitoring, backing up, and securing a data warehouse,
making it very easy and inexpensive to manage and maintain. This automation allows
you to build a petabyte-scale data warehouse in minutes, a task that has traditionally
taken weeks, or months, to complete in an on-premises implementation.
Ideal Usage Pattern
Amazon Redshift is ideal for online analytical processing (OLAP) using your existing
business intelligence tools. Organizations are using Amazon Redshift to do the following:

Page 4 of 29
Analyze global sales data for multiple products
Store historical stock trade data
Analyze ad impressions and clicks
Aggregate gaming data
Analyze social trends
1 http://aws.amazon.com/about-aws/globalinfrastructure/
2 http://aws.amazon.com/s3/
3 http://aws.amazon.com/datapipeline/
4 http://aws.amazon.com/solutions/case-studies/big-data/

Page 4 of 29
Analyze global sales data for multiple products
Store historical stock trade data
Analyze ad impressions and clicks
Aggregate gaming data
Analyze social trends
1 http://aws.amazon.com/about-aws/globalinfrastructure/
2 http://aws.amazon.com/s3/
3 http://aws.amazon.com/datapipeline/
4 http://aws.amazon.com/solutions/case-studies/big-data/
needs without having to wait for additional hardware, or being required to over-invest to
provision enough capacity. For mission-critical applications on a more traditional
infrastructure, system designers have no choice but to over-provision, because a surge
in additional data due to an increase in business need must be something the system
can handle. By contrast, on AWS you can provision more capacity and compute in a
matter of minutes, meaning that your big data applications grow and shrink as demand
dictates, and your system runs as close to optimal efficiency as possible. In addition, you
get flexible computing on a world-class infrastructure with access to the many different
geographic regions that AWS offers 1 , along with the ability to utilize other scalable
services that Amazon offers such as Amazon Simple Storage Service (S3) 2 and AWS
Data Pipeline. 3 These capabilities of the AWS platform make it an extremely good fit for
solving big data problems. You can read about many customers that have implemented
successful big data analytics workloads on AWS on the AWS case studies web page. 4
Amazon Redshift
Amazon Redshift is a fast, fully-managed, petabyte-scale data warehouse service that
makes it simple and cost-effective to efficiently analyze all your data using your existing
business intelligence tools. 5 It is optimized for datasets ranging from a few hundred
gigabytes to a petabyte or more, and is designed to cost less than a tenth of the cost of
most traditional data warehousing solutions. Amazon Redshift delivers fast query and
I/O performance for virtually any size dataset by using columnar storage technology
while parallelizing and distributing queries across multiple nodes. As a managed service,
automation is provided for most of the common administrative tasks associated with
provisioning, configuring, monitoring, backing up, and securing a data warehouse,
making it very easy and inexpensive to manage and maintain. This automation allows
you to build a petabyte-scale data warehouse in minutes, a task that has traditionally
taken weeks, or months, to complete in an on-premises implementation.
Ideal Usage Pattern
Amazon Redshift is ideal for online analytical processing (OLAP) using your existing
business intelligence tools. Organizations are using Amazon Redshift to do the following:
needs without having to wait for additional hardware, or being required to over-invest to
provision enough capacity. For mission-critical applications on a more traditional
infrastructure, system designers have no choice but to over-provision, because a surge
in additional data due to an increase in business need must be something the system
can handle. By contrast, on AWS you can provision more capacity and compute in a
matter of minutes, meaning that your big data applications grow and shrink as demand
dictates, and your system runs as close to optimal efficiency as possible. In addition, you
get flexible computing on a world-class infrastructure with access to the many different
geographic regions that AWS offers 1 , along with the ability to utilize other scalable
services that Amazon offers such as Amazon Simple Storage Service (S3) 2 and AWS
Data Pipeline. 3 These capabilities of the AWS platform make it an extremely good fit for
solving big data problems. You can read about many customers that have implemented
successful big data analytics workloads on AWS on the AWS case studies web page. 4
Amazon Redshift
Amazon Redshift is a fast, fully-managed, petabyte-scale data warehouse service that
makes it simple and cost-effective to efficiently analyze all your data using your existing
business intelligence tools. 5 It is optimized for datasets ranging from a few hundred
gigabytes to a petabyte or more, and is designed to cost less than a tenth of the cost of
most traditional data warehousing solutions. Amazon Redshift delivers fast query and
I/O performance for virtually any size dataset by using columnar storage technology
while parallelizing and distributing queries across multiple nodes. As a managed service,
automation is provided for most of the common administrative tasks associated with
provisioning, configuring, monitoring, backing up, and securing a data warehouse,
making it very easy and inexpensive to manage and maintain. This automation allows
you to build a petabyte-scale data warehouse in minutes, a task that has traditionally
taken weeks, or months, to complete in an on-premises implementation.
Ideal Usage Pattern
Amazon Redshift is ideal for online analytical processing (OLAP) using your existing
business intelligence tools. Organizations are using Amazon Redshift to do the following:

Page 4 of 29
Analyze global sales data for multiple products
Store historical stock trade data
Analyze ad impressions and clicks
Aggregate gaming data
Analyze social trends
1 http://aws.amazon.com/about-aws/globalinfrastructure/
2 http://aws.amazon.com/s3/
3 http://aws.amazon.com/datapipeline/
4 http://aws.amazon.com/solutions/case-studies/big-data/

Page 4 of 29
Analyze global sales data for multiple products
Store historical stock trade data
Analyze ad impressions and clicks
Aggregate gaming data
Analyze social trends
1 http://aws.amazon.com/about-aws/globalinfrastructure/
2 http://aws.amazon.com/s3/
3 http://aws.amazon.com/datapipeline/
4 http://aws.amazon.com/solutions/case-studies/big-data/
needs without having to wait for additional hardware, or being required to over-invest to
provision enough capacity. For mission-critical applications on a more traditional
infrastructure, system designers have no choice but to over-provision, because a surge
in additional data due to an increase in business need must be something the system
can handle. By contrast, on AWS you can provision more capacity and compute in a
matter of minutes, meaning that your big data applications grow and shrink as demand
dictates, and your system runs as close to optimal efficiency as possible. In addition, you
get flexible computing on a world-class infrastructure with access to the many different
geographic regions that AWS offers 1 , along with the ability to utilize other scalable
services that Amazon offers such as Amazon Simple Storage Service (S3) 2 and AWS
Data Pipeline. 3 These capabilities of the AWS platform make it an extremely good fit for
solving big data problems. You can read about many customers that have implemented
successful big data analytics workloads on AWS on the AWS case studies web page. 4
Amazon Redshift
Amazon Redshift is a fast, fully-managed, petabyte-scale data warehouse service that
makes it simple and cost-effective to efficiently analyze all your data using your existing
business intelligence tools. 5 It is optimized for datasets ranging from a few hundred
gigabytes to a petabyte or more, and is designed to cost less than a tenth of the cost of
most traditional data warehousing solutions. Amazon Redshift delivers fast query and
I/O performance for virtually any size dataset by using columnar storage technology
while parallelizing and distributing queries across multiple nodes. As a managed service,
automation is provided for most of the common administrative tasks associated with
provisioning, configuring, monitoring, backing up, and securing a data warehouse,
making it very easy and inexpensive to manage and maintain. This automation allows
you to build a petabyte-scale data warehouse in minutes, a task that has traditionally
taken weeks, or months, to complete in an on-premises implementation.
Ideal Usage Pattern
Amazon Redshift is ideal for online analytical processing (OLAP) using your existing
business intelligence tools. Organizations are using Amazon Redshift to do the following:
needs without having to wait for additional hardware, or being required to over-invest to
provision enough capacity. For mission-critical applications on a more traditional
infrastructure, system designers have no choice but to over-provision, because a surge
in additional data due to an increase in business need must be something the system
can handle. By contrast, on AWS you can provision more capacity and compute in a
matter of minutes, meaning that your big data applications grow and shrink as demand
dictates, and your system runs as close to optimal efficiency as possible. In addition, you
get flexible computing on a world-class infrastructure with access to the many different
geographic regions that AWS offers 1 , along with the ability to utilize other scalable
services that Amazon offers such as Amazon Simple Storage Service (S3) 2 and AWS
Data Pipeline. 3 These capabilities of the AWS platform make it an extremely good fit for
solving big data problems. You can read about many customers that have implemented
successful big data analytics workloads on AWS on the AWS case studies web page. 4
Amazon Redshift
Amazon Redshift is a fast, fully-managed, petabyte-scale data warehouse service that
makes it simple and cost-effective to efficiently analyze all your data using your existing
business intelligence tools. 5 It is optimized for datasets ranging from a few hundred
gigabytes to a petabyte or more, and is designed to cost less than a tenth of the cost of
most traditional data warehousing solutions. Amazon Redshift delivers fast query and
I/O performance for virtually any size dataset by using columnar storage technology
while parallelizing and distributing queries across multiple nodes. As a managed service,
automation is provided for most of the common administrative tasks associated with
provisioning, configuring, monitoring, backing up, and securing a data warehouse,
making it very easy and inexpensive to manage and maintain. This automation allows
you to build a petabyte-scale data warehouse in minutes, a task that has traditionally
taken weeks, or months, to complete in an on-premises implementation.
Ideal Usage Pattern
Amazon Redshift is ideal for online analytical processing (OLAP) using your existing
business intelligence tools. Organizations are using Amazon Redshift to do the following:

Page 4 of 29
Analyze global sales data for multiple products
Store historical stock trade data
Analyze ad impressions and clicks
Aggregate gaming data
Analyze social trends
1 http://aws.amazon.com/about-aws/globalinfrastructure/
2 http://aws.amazon.com/s3/
3 http://aws.amazon.com/datapipeline/
4 http://aws.amazon.com/solutions/case-studies/big-data/

Page 4 of 29
Analyze global sales data for multiple products
Store historical stock trade data
Analyze ad impressions and clicks
Aggregate gaming data
Analyze social trends
1 http://aws.amazon.com/about-aws/globalinfrastructure/
2 http://aws.amazon.com/s3/
3 http://aws.amazon.com/datapipeline/
4 http://aws.amazon.com/solutions/case-studies/big-data/

needs without having to wait for additional hardware, or being required to over-invest to
provision enough capacity. For mission-critical applications on a more traditional
infrastructure, system designers have no choice but to over-provision, because a surge
in additional data due to an increase in business need must be something the system
can handle. By contrast, on AWS you can provision more capacity and compute in a
matter of minutes, meaning that your big data applications grow and shrink as demand
dictates, and your system runs as close to optimal efficiency as possible. In addition, you
get flexible computing on a world-class infrastructure with access to the many different
geographic regions that AWS offers 1 , along with the ability to utilize other scalable
services that Amazon offers such as Amazon Simple Storage Service (S3) 2 and AWS
Data Pipeline. 3 These capabilities of the AWS platform make it an extremely good fit for
solving big data problems. You can read about many customers that have implemented
successful big data analytics workloads on AWS on the AWS case studies web page. 4
Amazon Redshift
Amazon Redshift is a fast, fully-managed, petabyte-scale data warehouse service that
makes it simple and cost-effective to efficiently analyze all your data using your existing
business intelligence tools. 5 It is optimized for datasets ranging from a few hundred
gigabytes to a petabyte or more, and is designed to cost less than a tenth of the cost of
most traditional data warehousing solutions. Amazon Redshift delivers fast query and
I/O performance for virtually any size dataset by using columnar storage technology
while parallelizing and distributing queries across multiple nodes. As a managed service,
automation is provided for most of the common administrative tasks associated with
provisioning, configuring, monitoring, backing up, and securing a data warehouse,
making it very easy and inexpensive to manage and maintain. This automation allows
you to build a petabyte-scale data warehouse in minutes, a task that has traditionally
taken weeks, or months, to complete in an on-premises implementation.
Ideal Usage Pattern
Amazon Redshift is ideal for online analytical processing (OLAP) using your existing
business intelligence tools. Organizations are using Amazon Redshift to do the following:
needs without having to wait for additional hardware, or being required to over-invest to
provision enough capacity. For mission-critical applications on a more traditional
infrastructure, system designers have no choice but to over-provision, because a surge
in additional data due to an increase in business need must be something the system
can handle. By contrast, on AWS you can provision more capacity and compute in a
matter of minutes, meaning that your big data applications grow and shrink as demand
dictates, and your system runs as close to optimal efficiency as possible. In addition, you
get flexible computing on a world-class infrastructure with access to the many different
geographic regions that AWS offers 1 , along with the ability to utilize other scalable
services that Amazon offers such as Amazon Simple Storage Service (S3) 2 and AWS
Data Pipeline. 3 These capabilities of the AWS platform make it an extremely good fit for
solving big data problems. You can read about many customers that have implemented
successful big data analytics workloads on AWS on the AWS case studies web page. 4
Amazon Redshift
Amazon Redshift is a fast, fully-managed, petabyte-scale data warehouse service that
makes it simple and cost-effective to efficiently analyze all your data using your existing
business intelligence tools. 5 It is optimized for datasets ranging from a few hundred
gigabytes to a petabyte or more, and is designed to cost less than a tenth of the cost of
most traditional data warehousing solutions. Amazon Redshift delivers fast query and
I/O performance for virtually any size dataset by using columnar storage technology
while parallelizing and distributing queries across multiple nodes. As a managed service,
automation is provided for most of the common administrative tasks associated with
provisioning, configuring, monitoring, backing up, and securing a data warehouse,
making it very easy and inexpensive to manage and maintain. This automation allows
you to build a petabyte-scale data warehouse in minutes, a task that has traditionally
taken weeks, or months, to complete in an on-premises implementation.
Ideal Usage Pattern
Amazon Redshift is ideal for online analytical processing (OLAP) using your existing
business intelligence tools. Organizations are using Amazon Redshift to do the following:

Page 4 of 29
Analyze global sales data for multiple products
Store historical stock trade data
Analyze ad impressions and clicks
Aggregate gaming data
Analyze social trends
1 http://aws.amazon.com/about-aws/globalinfrastructure/
2 http://aws.amazon.com/s3/
3 http://aws.amazon.com/datapipeline/
4 http://aws.amazon.com/solutions/case-studies/big-data/

Page 4 of 29
Analyze global sales data for multiple products
Store historical stock trade data
Analyze ad impressions and clicks
Aggregate gaming data
Analyze social trends
1 http://aws.amazon.com/about-aws/globalinfrastructure/
2 http://aws.amazon.com/s3/
3 http://aws.amazon.com/datapipeline/
4 http://aws.amazon.com/solutions/case-studies/big-data/

needs without having to wait for additional hardware, or being required to over-invest to
provision enough capacity. For mission-critical applications on a more traditional
infrastructure, system designers have no choice but to over-provision, because a surge
in additional data due to an increase in business need must be something the system
can handle. By contrast, on AWS you can provision more capacity and compute in a
matter of minutes, meaning that your big data applications grow and shrink as demand
dictates, and your system runs as close to optimal efficiency as possible. In addition, you
get flexible computing on a world-class infrastructure with access to the many different
geographic regions that AWS offers 1 , along with the ability to utilize other scalable
services that Amazon offers such as Amazon Simple Storage Service (S3) 2 and AWS
Data Pipeline. 3 These capabilities of the AWS platform make it an extremely good fit for
solving big data problems. You can read about many customers that have implemented
successful big data analytics workloads on AWS on the AWS case studies web page. 4
Amazon Redshift
Amazon Redshift is a fast, fully-managed, petabyte-scale data warehouse service that
makes it simple and cost-effective to efficiently analyze all your data using your existing
business intelligence tools. 5 It is optimized for datasets ranging from a few hundred
gigabytes to a petabyte or more, and is designed to cost less than a tenth of the cost of
most traditional data warehousing solutions. Amazon Redshift delivers fast query and
I/O performance for virtually any size dataset by using columnar storage technology
while parallelizing and distributing queries across multiple nodes. As a managed service,
automation is provided for most of the common administrative tasks associated with
provisioning, configuring, monitoring, backing up, and securing a data warehouse,
making it very easy and inexpensive to manage and maintain. This automation allows
you to build a petabyte-scale data warehouse in minutes, a task that has traditionally
taken weeks, or months, to complete in an on-premises implementation.
Ideal Usage Pattern
Amazon Redshift is ideal for online analytical processing (OLAP) using your existing
business intelligence tools. Organizations are using Amazon Redshift to do the following:
needs without having to wait for additional hardware, or being required to over-invest to
provision enough capacity. For mission-critical applications on a more traditional
infrastructure, system designers have no choice but to over-provision, because a surge
in additional data due to an increase in business need must be something the system
can handle. By contrast, on AWS you can provision more capacity and compute in a
matter of minutes, meaning that your big data applications grow and shrink as demand
dictates, and your system runs as close to optimal efficiency as possible. In addition, you
get flexible computing on a world-class infrastructure with access to the many different
geographic regions that AWS offers 1 , along with the ability to utilize other scalable
services that Amazon offers such as Amazon Simple Storage Service (S3) 2 and AWS
Data Pipeline. 3 These capabilities of the AWS platform make it an extremely good fit for
solving big data problems. You can read about many customers that have implemented
successful big data analytics workloads on AWS on the AWS case studies web page. 4
Amazon Redshift
Amazon Redshift is a fast, fully-managed, petabyte-scale data warehouse service that
makes it simple and cost-effective to efficiently analyze all your data using your existing
business intelligence tools. 5 It is optimized for datasets ranging from a few hundred
gigabytes to a petabyte or more, and is designed to cost less than a tenth of the cost of
most traditional data warehousing solutions. Amazon Redshift delivers fast query and
I/O performance for virtually any size dataset by using columnar storage technology
while parallelizing and distributing queries across multiple nodes. As a managed service,
automation is provided for most of the common administrative tasks associated with
provisioning, configuring, monitoring, backing up, and securing a data warehouse,
making it very easy and inexpensive to manage and maintain. This automation allows
you to build a petabyte-scale data warehouse in minutes, a task that has traditionally
taken weeks, or months, to complete in an on-premises implementation.
Ideal Usage Pattern
Amazon Redshift is ideal for online analytical processing (OLAP) using your existing
business intelligence tools. Organizations are using Amazon Redshift to do the following:

Page 4 of 29
Analyze global sales data for multiple products
Store historical stock trade data
Analyze ad impressions and clicks
Aggregate gaming data
Analyze social trends
1 http://aws.amazon.com/about-aws/globalinfrastructure/
2 http://aws.amazon.com/s3/
3 http://aws.amazon.com/datapipeline/
4 http://aws.amazon.com/solutions/case-studies/big-data/

Page 4 of 29
Analyze global sales data for multiple products
Store historical stock trade data
Analyze ad impressions and clicks
Aggregate gaming data
Analyze social trends
1 http://aws.amazon.com/about-aws/globalinfrastructure/
2 http://aws.amazon.com/s3/
3 http://aws.amazon.com/datapipeline/
4 http://aws.amazon.com/solutions/case-studies/big-data/

needs without having to wait for additional hardware, or being required to over-invest to
provision enough capacity. For mission-critical applications on a more traditional
infrastructure, system designers have no choice but to over-provision, because a surge
in additional data due to an increase in business need must be something the system
can handle. By contrast, on AWS you can provision more capacity and compute in a
matter of minutes, meaning that your big data applications grow and shrink as demand
dictates, and your system runs as close to optimal efficiency as possible. In addition, you
get flexible computing on a world-class infrastructure with access to the many different
geographic regions that AWS offers 1 , along with the ability to utilize other scalable
services that Amazon offers such as Amazon Simple Storage Service (S3) 2 and AWS
Data Pipeline. 3 These capabilities of the AWS platform make it an extremely good fit for
solving big data problems. You can read about many customers that have implemented
successful big data analytics workloads on AWS on the AWS case studies web page. 4
Amazon Redshift
Amazon Redshift is a fast, fully-managed, petabyte-scale data warehouse service that
makes it simple and cost-effective to efficiently analyze all your data using your existing
business intelligence tools. 5 It is optimized for datasets ranging from a few hundred
gigabytes to a petabyte or more, and is designed to cost less than a tenth of the cost of
most traditional data warehousing solutions. Amazon Redshift delivers fast query and
I/O performance for virtually any size dataset by using columnar storage technology
while parallelizing and distributing queries across multiple nodes. As a managed service,
automation is provided for most of the common administrative tasks associated with
provisioning, configuring, monitoring, backing up, and securing a data warehouse,
making it very easy and inexpensive to manage and maintain. This automation allows
you to build a petabyte-scale data warehouse in minutes, a task that has traditionally
taken weeks, or months, to complete in an on-premises implementation.
Ideal Usage Pattern
Amazon Redshift is ideal for online analytical processing (OLAP) using your existing
business intelligence tools. Organizations are using Amazon Redshift to do the following:
needs without having to wait for additional hardware, or being required to over-invest to
provision enough capacity. For mission-critical applications on a more traditional
infrastructure, system designers have no choice but to over-provision, because a surge
in additional data due to an increase in business need must be something the system
can handle. By contrast, on AWS you can provision more capacity and compute in a
matter of minutes, meaning that your big data applications grow and shrink as demand
dictates, and your system runs as close to optimal efficiency as possible. In addition, you
get flexible computing on a world-class infrastructure with access to the many different
geographic regions that AWS offers 1 , along with the ability to utilize other scalable
services that Amazon offers such as Amazon Simple Storage Service (S3) 2 and AWS
Data Pipeline. 3 These capabilities of the AWS platform make it an extremely good fit for
solving big data problems. You can read about many customers that have implemented
successful big data analytics workloads on AWS on the AWS case studies web page. 4
Amazon Redshift
Amazon Redshift is a fast, fully-managed, petabyte-scale data warehouse service that
makes it simple and cost-effective to efficiently analyze all your data using your existing
business intelligence tools. 5 It is optimized for datasets ranging from a few hundred
gigabytes to a petabyte or more, and is designed to cost less than a tenth of the cost of
most traditional data warehousing solutions. Amazon Redshift delivers fast query and
I/O performance for virtually any size dataset by using columnar storage technology
while parallelizing and distributing queries across multiple nodes. As a managed service,
automation is provided for most of the common administrative tasks associated with
provisioning, configuring, monitoring, backing up, and securing a data warehouse,
making it very easy and inexpensive to manage and maintain. This automation allows
you to build a petabyte-scale data warehouse in minutes, a task that has traditionally
taken weeks, or months, to complete in an on-premises implementation.
Ideal Usage Pattern
Amazon Redshift is ideal for online analytical processing (OLAP) using your existing
business intelligence tools. Organizations are using Amazon Redshift to do the following:

Page 4 of 29
Analyze global sales data for multiple products
Store historical stock trade data
Analyze ad impressions and clicks
Aggregate gaming data
Analyze social trends
1 http://aws.amazon.com/about-aws/globalinfrastructure/
2 http://aws.amazon.com/s3/
3 http://aws.amazon.com/datapipeline/
4 http://aws.amazon.com/solutions/case-studies/big-data/

Page 4 of 29
Analyze global sales data for multiple products
Store historical stock trade data
Analyze ad impressions and clicks
Aggregate gaming data
Analyze social trends
1 http://aws.amazon.com/about-aws/globalinfrastructure/
2 http://aws.amazon.com/s3/
3 http://aws.amazon.com/datapipeline/
4 http://aws.amazon.com/solutions/case-studies/big-data/

needs without having to wait for additional hardware, or being required to over-invest to
provision enough capacity. For mission-critical applications on a more traditional
infrastructure, system designers have no choice but to over-provision, because a surge
in additional data due to an increase in business need must be something the system
can handle. By contrast, on AWS you can provision more capacity and compute in a
matter of minutes, meaning that your big data applications grow and shrink as demand
dictates, and your system runs as close to optimal efficiency as possible. In addition, you
get flexible computing on a world-class infrastructure with access to the many different
geographic regions that AWS offers 1 , along with the ability to utilize other scalable
services that Amazon offers such as Amazon Simple Storage Service (S3) 2 and AWS
Data Pipeline. 3 These capabilities of the AWS platform make it an extremely good fit for
solving big data problems. You can read about many customers that have implemented
successful big data analytics workloads on AWS on the AWS case studies web page. 4
Amazon Redshift
Amazon Redshift is a fast, fully-managed, petabyte-scale data warehouse service that
makes it simple and cost-effective to efficiently analyze all your data using your existing
business intelligence tools. 5 It is optimized for datasets ranging from a few hundred
gigabytes to a petabyte or more, and is designed to cost less than a tenth of the cost of
most traditional data warehousing solutions. Amazon Redshift delivers fast query and
I/O performance for virtually any size dataset by using columnar storage technology
while parallelizing and distributing queries across multiple nodes. As a managed service,
automation is provided for most of the common administrative tasks associated with
provisioning, configuring, monitoring, backing up, and securing a data warehouse,
making it very easy and inexpensive to manage and maintain. This automation allows
you to build a petabyte-scale data warehouse in minutes, a task that has traditionally
taken weeks, or months, to complete in an on-premises implementation.
Ideal Usage Pattern
Amazon Redshift is ideal for online analytical processing (OLAP) using your existing
business intelligence tools. Organizations are using Amazon Redshift to do the following:
needs without having to wait for additional hardware, or being required to over-invest to
provision enough capacity. For mission-critical applications on a more traditional
infrastructure, system designers have no choice but to over-provision, because a surge
in additional data due to an increase in business need must be something the system
can handle. By contrast, on AWS you can provision more capacity and compute in a
matter of minutes, meaning that your big data applications grow and shrink as demand
dictates, and your system runs as close to optimal efficiency as possible. In addition, you
get flexible computing on a world-class infrastructure with access to the many different
geographic regions that AWS offers 1 , along with the ability to utilize other scalable
services that Amazon offers such as Amazon Simple Storage Service (S3) 2 and AWS
Data Pipeline. 3 These capabilities of the AWS platform make it an extremely good fit for
solving big data problems. You can read about many customers that have implemented
successful big data analytics workloads on AWS on the AWS case studies web page. 4
Amazon Redshift
Amazon Redshift is a fast, fully-managed, petabyte-scale data warehouse service that
makes it simple and cost-effective to efficiently analyze all your data using your existing
business intelligence tools. 5 It is optimized for datasets ranging from a few hundred
gigabytes to a petabyte or more, and is designed to cost less than a tenth of the cost of
most traditional data warehousing solutions. Amazon Redshift delivers fast query and
I/O performance for virtually any size dataset by using columnar storage technology
while parallelizing and distributing queries across multiple nodes. As a managed service,
automation is provided for most of the common administrative tasks associated with
provisioning, configuring, monitoring, backing up, and securing a data warehouse,
making it very easy and inexpensive to manage and maintain. This automation allows
you to build a petabyte-scale data warehouse in minutes, a task that has traditionally
taken weeks, or months, to complete in an on-premises implementation.
Ideal Usage Pattern
Amazon Redshift is ideal for online analytical processing (OLAP) using your existing
business intelligence tools. Organizations are using Amazon Redshift to do the following:

Page 4 of 29
Analyze global sales data for multiple products
Store historical stock trade data
Analyze ad impressions and clicks
Aggregate gaming data
Analyze social trends
1 http://aws.amazon.com/about-aws/globalinfrastructure/
2 http://aws.amazon.com/s3/
3 http://aws.amazon.com/datapipeline/
4 http://aws.amazon.com/solutions/case-studies/big-data/

Page 4 of 29
Analyze global sales data for multiple products
Store historical stock trade data
Analyze ad impressions and clicks
Aggregate gaming data
Analyze social trends
1 http://aws.amazon.com/about-aws/globalinfrastructure/
2 http://aws.amazon.com/s3/
3 http://aws.amazon.com/datapipeline/
4 http://aws.amazon.com/solutions/case-studies/big-data/

needs without having to wait for additional hardware, or being required to over-invest to
provision enough capacity. For mission-critical applications on a more traditional
infrastructure, system designers have no choice but to over-provision, because a surge
in additional data due to an increase in business need must be something the system
can handle. By contrast, on AWS you can provision more capacity and compute in a
matter of minutes, meaning that your big data applications grow and shrink as demand
dictates, and your system runs as close to optimal efficiency as possible. In addition, you
get flexible computing on a world-class infrastructure with access to the many different
geographic regions that AWS offers 1 , along with the ability to utilize other scalable
services that Amazon offers such as Amazon Simple Storage Service (S3) 2 and AWS
Data Pipeline. 3 These capabilities of the AWS platform make it an extremely good fit for
solving big data problems. You can read about many customers that have implemented
successful big data analytics workloads on AWS on the AWS case studies web page. 4
Amazon Redshift
Amazon Redshift is a fast, fully-managed, petabyte-scale data warehouse service that
makes it simple and cost-effective to efficiently analyze all your data using your existing
business intelligence tools. 5 It is optimized for datasets ranging from a few hundred
gigabytes to a petabyte or more, and is designed to cost less than a tenth of the cost of
most traditional data warehousing solutions. Amazon Redshift delivers fast query and
I/O performance for virtually any size dataset by using columnar storage technology
while parallelizing and distributing queries across multiple nodes. As a managed service,
automation is provided for most of the common administrative tasks associated with
provisioning, configuring, monitoring, backing up, and securing a data warehouse,
making it very easy and inexpensive to manage and maintain. This automation allows
you to build a petabyte-scale data warehouse in minutes, a task that has traditionally
taken weeks, or months, to complete in an on-premises implementation.
Ideal Usage Pattern
Amazon Redshift is ideal for online analytical processing (OLAP) using your existing
business intelligence tools. Organizations are using Amazon Redshift to do the following:
needs without having to wait for additional hardware, or being required to over-invest to
provision enough capacity. For mission-critical applications on a more traditional
infrastructure, system designers have no choice but to over-provision, because a surge
in additional data due to an increase in business need must be something the system
can handle. By contrast, on AWS you can provision more capacity and compute in a
matter of minutes, meaning that your big data applications grow and shrink as demand
dictates, and your system runs as close to optimal efficiency as possible. In addition, you
get flexible computing on a world-class infrastructure with access to the many different
geographic regions that AWS offers 1 , along with the ability to utilize other scalable
services that Amazon offers such as Amazon Simple Storage Service (S3) 2 and AWS
Data Pipeline. 3 These capabilities of the AWS platform make it an extremely good fit for
solving big data problems. You can read about many customers that have implemented
successful big data analytics workloads on AWS on the AWS case studies web page. 4
Amazon Redshift
Amazon Redshift is a fast, fully-managed, petabyte-scale data warehouse service that
makes it simple and cost-effective to efficiently analyze all your data using your existing
business intelligence tools. 5 It is optimized for datasets ranging from a few hundred
gigabytes to a petabyte or more, and is designed to cost less than a tenth of the cost of
most traditional data warehousing solutions. Amazon Redshift delivers fast query and
I/O performance for virtually any size dataset by using columnar storage technology
while parallelizing and distributing queries across multiple nodes. As a managed service,
automation is provided for most of the common administrative tasks associated with
provisioning, configuring, monitoring, backing up, and securing a data warehouse,
making it very easy and inexpensive to manage and maintain. This automation allows
you to build a petabyte-scale data warehouse in minutes, a task that has traditionally
taken weeks, or months, to complete in an on-premises implementation.
Ideal Usage Pattern
Amazon Redshift is ideal for online analytical processing (OLAP) using your existing
business intelligence tools. Organizations are using Amazon Redshift to do the following:

Page 4 of 29
Analyze global sales data for multiple products
Store historical stock trade data
Analyze ad impressions and clicks
Aggregate gaming data
Analyze social trends
1 http://aws.amazon.com/about-aws/globalinfrastructure/
2 http://aws.amazon.com/s3/
3 http://aws.amazon.com/datapipeline/
4 http://aws.amazon.com/solutions/case-studies/big-data/

Page 4 of 29
Analyze global sales data for multiple products
Store historical stock trade data
Analyze ad impressions and clicks
Aggregate gaming data
Analyze social trends
1 http://aws.amazon.com/about-aws/globalinfrastructure/
2 http://aws.amazon.com/s3/
3 http://aws.amazon.com/datapipeline/
4 http://aws.amazon.com/solutions/case-studies/big-data/

needs without having to wait for additional hardware, or being required to over-invest to
provision enough capacity. For mission-critical applications on a more traditional
infrastructure, system designers have no choice but to over-provision, because a surge
in additional data due to an increase in business need must be something the system
can handle. By contrast, on AWS you can provision more capacity and compute in a
matter of minutes, meaning that your big data applications grow and shrink as demand
dictates, and your system runs as close to optimal efficiency as possible. In addition, you
get flexible computing on a world-class infrastructure with access to the many different
geographic regions that AWS offers 1 , along with the ability to utilize other scalable
services that Amazon offers such as Amazon Simple Storage Service (S3) 2 and AWS
Data Pipeline. 3 These capabilities of the AWS platform make it an extremely good fit for
solving big data problems. You can read about many customers that have implemented
successful big data analytics workloads on AWS on the AWS case studies web page. 4
Amazon Redshift
Amazon Redshift is a fast, fully-managed, petabyte-scale data warehouse service that
makes it simple and cost-effective to efficiently analyze all your data using your existing
business intelligence tools. 5 It is optimized for datasets ranging from a few hundred
gigabytes to a petabyte or more, and is designed to cost less than a tenth of the cost of
most traditional data warehousing solutions. Amazon Redshift delivers fast query and
I/O performance for virtually any size dataset by using columnar storage technology
while parallelizing and distributing queries across multiple nodes. As a managed service,
automation is provided for most of the common administrative tasks associated with
provisioning, configuring, monitoring, backing up, and securing a data warehouse,
making it very easy and inexpensive to manage and maintain. This automation allows
you to build a petabyte-scale data warehouse in minutes, a task that has traditionally
taken weeks, or months, to complete in an on-premises implementation.
Ideal Usage Pattern
Amazon Redshift is ideal for online analytical processing (OLAP) using your existing
business intelligence tools. Organizations are using Amazon Redshift to do the following:
needs without having to wait for additional hardware, or being required to over-invest to
provision enough capacity. For mission-critical applications on a more traditional
infrastructure, system designers have no choice but to over-provision, because a surge
in additional data due to an increase in business need must be something the system
can handle. By contrast, on AWS you can provision more capacity and compute in a
matter of minutes, meaning that your big data applications grow and shrink as demand
dictates, and your system runs as close to optimal efficiency as possible. In addition, you
get flexible computing on a world-class infrastructure with access to the many different
geographic regions that AWS offers 1 , along with the ability to utilize other scalable
services that Amazon offers such as Amazon Simple Storage Service (S3) 2 and AWS
Data Pipeline. 3 These capabilities of the AWS platform make it an extremely good fit for
solving big data problems. You can read about many customers that have implemented
successful big data analytics workloads on AWS on the AWS case studies web page. 4
Amazon Redshift
Amazon Redshift is a fast, fully-managed, petabyte-scale data warehouse service that
makes it simple and cost-effective to efficiently analyze all your data using your existing
business intelligence tools. 5 It is optimized for datasets ranging from a few hundred
gigabytes to a petabyte or more, and is designed to cost less than a tenth of the cost of
most traditional data warehousing solutions. Amazon Redshift delivers fast query and
I/O performance for virtually any size dataset by using columnar storage technology
while parallelizing and distributing queries across multiple nodes. As a managed service,
automation is provided for most of the common administrative tasks associated with
provisioning, configuring, monitoring, backing up, and securing a data warehouse,
making it very easy and inexpensive to manage and maintain. This automation allows
you to build a petabyte-scale data warehouse in minutes, a task that has traditionally
taken weeks, or months, to complete in an on-premises implementation.
Ideal Usage Pattern
Amazon Redshift is ideal for online analytical processing (OLAP) using your existing
business intelligence tools. Organizations are using Amazon Redshift to do the following:

Page 4 of 29
Analyze global sales data for multiple products
Store historical stock trade data
Analyze ad impressions and clicks
Aggregate gaming data
Analyze social trends
1 http://aws.amazon.com/about-aws/globalinfrastructure/
2 http://aws.amazon.com/s3/
3 http://aws.amazon.com/datapipeline/
4 http://aws.amazon.com/solutions/case-studies/big-data/

Page 4 of 29
Analyze global sales data for multiple products
Store historical stock trade data
Analyze ad impressions and clicks
Aggregate gaming data
Analyze social trends
1 http://aws.amazon.com/about-aws/globalinfrastructure/
2 http://aws.amazon.com/s3/
3 http://aws.amazon.com/datapipeline/
4 http://aws.amazon.com/solutions/case-studies/big-data/

needs without having to wait for additional hardware, or being required to over-invest to
provision enough capacity. For mission-critical applications on a more traditional
infrastructure, system designers have no choice but to over-provision, because a surge
in additional data due to an increase in business need must be something the system
can handle. By contrast, on AWS you can provision more capacity and compute in a
matter of minutes, meaning that your big data applications grow and shrink as demand
dictates, and your system runs as close to optimal efficiency as possible. In addition, you
get flexible computing on a world-class infrastructure with access to the many different
geographic regions that AWS offers 1 , along with the ability to utilize other scalable
services that Amazon offers such as Amazon Simple Storage Service (S3) 2 and AWS
Data Pipeline. 3 These capabilities of the AWS platform make it an extremely good fit for
solving big data problems. You can read about many customers that have implemented
successful big data analytics workloads on AWS on the AWS case studies web page. 4
Amazon Redshift
Amazon Redshift is a fast, fully-managed, petabyte-scale data warehouse service that
makes it simple and cost-effective to efficiently analyze all your data using your existing
business intelligence tools. 5 It is optimized for datasets ranging from a few hundred
gigabytes to a petabyte or more, and is designed to cost less than a tenth of the cost of
most traditional data warehousing solutions. Amazon Redshift delivers fast query and
I/O performance for virtually any size dataset by using columnar storage technology
while parallelizing and distributing queries across multiple nodes. As a managed service,
automation is provided for most of the common administrative tasks associated with
provisioning, configuring, monitoring, backing up, and securing a data warehouse,
making it very easy and inexpensive to manage and maintain. This automation allows
you to build a petabyte-scale data warehouse in minutes, a task that has traditionally
taken weeks, or months, to complete in an on-premises implementation.
Ideal Usage Pattern
Amazon Redshift is ideal for online analytical processing (OLAP) using your existing
business intelligence tools. Organizations are using Amazon Redshift to do the following:
needs without having to wait for additional hardware, or being required to over-invest to
provision enough capacity. For mission-critical applications on a more traditional
infrastructure, system designers have no choice but to over-provision, because a surge
in additional data due to an increase in business need must be something the system
can handle. By contrast, on AWS you can provision more capacity and compute in a
matter of minutes, meaning that your big data applications grow and shrink as demand
dictates, and your system runs as close to optimal efficiency as possible. In addition, you
get flexible computing on a world-class infrastructure with access to the many different
geographic regions that AWS offers 1 , along with the ability to utilize other scalable
services that Amazon offers such as Amazon Simple Storage Service (S3) 2 and AWS
Data Pipeline. 3 These capabilities of the AWS platform make it an extremely good fit for
solving big data problems. You can read about many customers that have implemented
successful big data analytics workloads on AWS on the AWS case studies web page. 4
Amazon Redshift
Amazon Redshift is a fast, fully-managed, petabyte-scale data warehouse service that
makes it simple and cost-effective to efficiently analyze all your data using your existing
business intelligence tools. 5 It is optimized for datasets ranging from a few hundred
gigabytes to a petabyte or more, and is designed to cost less than a tenth of the cost of
most traditional data warehousing solutions. Amazon Redshift delivers fast query and
I/O performance for virtually any size dataset by using columnar storage technology
while parallelizing and distributing queries across multiple nodes. As a managed service,
automation is provided for most of the common administrative tasks associated with
provisioning, configuring, monitoring, backing up, and securing a data warehouse,
making it very easy and inexpensive to manage and maintain. This automation allows
you to build a petabyte-scale data warehouse in minutes, a task that has traditionally
taken weeks, or months, to complete in an on-premises implementation.
Ideal Usage Pattern
Amazon Redshift is ideal for online analytical processing (OLAP) using your existing
business intelligence tools. Organizations are using Amazon Redshift to do the following:

Page 4 of 29
Analyze global sales data for multiple products
Store historical stock trade data
Analyze ad impressions and clicks
Aggregate gaming data
Analyze social trends
1 http://aws.amazon.com/about-aws/globalinfrastructure/
2 http://aws.amazon.com/s3/
3 http://aws.amazon.com/datapipeline/
4 http://aws.amazon.com/solutions/case-studies/big-data/

Page 4 of 29
Analyze global sales data for multiple products
Store historical stock trade data
Analyze ad impressions and clicks
Aggregate gaming data
Analyze social trends
1 http://aws.amazon.com/about-aws/globalinfrastructure/
2 http://aws.amazon.com/s3/
3 http://aws.amazon.com/datapipeline/
4 http://aws.amazon.com/solutions/case-studies/big-data/

